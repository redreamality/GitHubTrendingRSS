<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="data:text/xsl;base64,<?xml version="1.0" encoding="utf-8"?><xsl:stylesheet version="3.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform" xmlns:atom="http://www.w3.org/2005/Atom"><xsl:output method="html" version="1.0" encoding="UTF-8" indent="yes"/><xsl:template match="/"><xsl:variable name="title"><xsl:value-of select="/rss/channel/title"/></xsl:variable><xsl:variable name="description"><xsl:value-of select="/rss/channel/description"/></xsl:variable><xsl:variable name="link"><xsl:value-of select="/rss/channel/link"/></xsl:variable><html class="dark scroll-smooth"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="referrer" content="unsafe-url"/><title><xsl:value-of select="$title"/></title><style>*,:after,:before{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: ;--tw-contain-size: ;--tw-contain-layout: ;--tw-contain-paint: ;--tw-contain-style: }::backdrop{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: ;--tw-contain-size: ;--tw-contain-layout: ;--tw-contain-paint: ;--tw-contain-style: }
        
        /*! tailwindcss v3.4.17 | MIT License | https://tailwindcss.com*/*,:after,:before{box-sizing:border-box;border:0 solid #e7e7f0}:after,:before{--tw-content:""}:host,html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;-o-tab-size:4;tab-size:4;font-family:ui-sans-serif,system-ui,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;font-feature-settings:normal;font-variation-settings:normal;-webkit-tap-highlight-color:transparent}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-feature-settings:normal;font-variation-settings:normal;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit;border-collapse:collapse}button,input,optgroup,select,textarea{font-family:inherit;font-feature-settings:inherit;font-variation-settings:inherit;font-size:100%;font-weight:inherit;line-height:inherit;letter-spacing:inherit;color:inherit;margin:0;padding:0}button,select{text-transform:none}button,input:where([type=button]),input:where([type=reset]),input:where([type=submit]){-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}fieldset{margin:0}fieldset,legend{padding:0}menu,ol,ul{list-style:none;margin:0;padding:0}dialog{padding:0}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{opacity:1;color:#a8a8b8}input::placeholder,textarea::placeholder{opacity:1;color:#a8a8b8}[role=button],button{cursor:pointer}:disabled{cursor:default}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}[hidden]:where(:not([hidden=until-found])){display:none}:root{--card-radius:0.75rem;--btn-radius:var(--card-radius);--badge-radius:var(--btn-radius);--input-radius:var(--btn-radius);--avatar-radius:9999px;--annonce-radius:var(--avatar-radius);--ui-border-color:#1f1f31;--btn-border:#1f1f31;--badge-border:var(--btn-border);--input-border:var(--ui-border-color);--ui-disabled-border:#121220;--ui-error-border:#e11d48;--ui-success-border:#65a30d;--input-outline:#4f46e5;--ui-bg:rgb(18 18 32/var(--ui-bg-opacity));--ui-soft-bg:#1f1f31;--overlay-bg:rgba(2,2,13,.25);--input-bg:var(--ui-soft-bg);--ui-disabled-bg:#121220;--card-padding:1.5rem;--display-text-color:#fff;--title-text-color:var(--display-text-color);--body-text-color:#d6d6e1;--caption-text-color:#6e6e81;--placeholder-text-color:#4d4d5f;--ui-bg-opacity:1;color:var(--body-text-color)}*,.border{border-color:var(--ui-border-color)}button:disabled{border:none!important;background:var(--ui-disabled-bg)!important;background-image:none!important;box-shadow:none!important;color:var(--placeholder-text-color)!important;pointer-events:none!important}button:disabled:before{content:var(--tw-content);display:none}a:focus-visible,button:focus-visible{outline-width:2px;outline-offset:2px;outline-color:#4f46e5}a:focus-visible:focus-visible,button:focus-visible:focus-visible{outline-style:solid}input:user-invalid,select:user-invalid,textarea:user-invalid{--input-border:var(--ui-error-border);--ui-border-color:var(--ui-error-border);--input-outline:var(--ui-error-border);--title-text-color:#fb7185}[data-rounded=none]{--card-radius:0px;--avatar-radius:0px}[data-rounded=default]{--card-radius:0.25rem}[data-rounded=small]{--card-radius:0.125rem}[data-rounded=medium]{--card-radius:0.375rem}[data-rounded=large]{--card-radius:0.5rem}[data-rounded=xlarge]{--card-radius:0.75rem}[data-rounded="2xlarge"]{--card-radius:1rem;--input-radius:0.75rem}[data-rounded="3xlarge"]{--card-radius:1.5rem;--input-radius:0.75rem}[data-rounded=full]{--card-radius:1.5rem;--btn-radius:9999px;--input-radius:1rem}[data-shade=glassy]{--ui-bd-blur:40px;--ui-bg-opacity:0.75;--ui-bg:rgb(58 58 75/var(--ui-bg-opacity));--ui-border-color:rgba(250,250,254,.1);--ui-soft-bg:rgba(77,77,95,.5)}[data-shade="800"]{--ui-border-color:#3a3a4b;--ui-bg:#1f1f31;--ui-soft-bg:#121220}[data-shade="900"]{--ui-border-color:#1f1f31;--ui-bg:#121220;--ui-soft-bg:#1f1f31}[data-shade="950"]{--ui-border-color:#1f1f31;--ui-bg:#02020d;--ui-soft-bg:#1f1f31}.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}@media (min-width:1536px){.container{max-width:1536px}}.icon-\[tabler--rss\]{display:inline-block;width:1em;height:1em;background-color:currentColor;-webkit-mask-image:var(--svg);mask-image:var(--svg);-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;--svg:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24'%3E%3Cpath fill='none' stroke='%23000' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' d='M4 19a1 1 0 1 0 2 0 1 1 0 1 0-2 0M4 4a16 16 0 0 1 16 16M4 11a9 9 0 0 1 9 9'/%3E%3C/svg%3E")}.link{--tw-text-opacity:1;color:rgb(129 140 248/var(--tw-text-opacity,1));transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}.link.variant-ghost:hover,.link.variant-underlined{text-decoration-line:underline}.link.variant-animated{position:relative}.link.variant-animated:before{position:absolute;left:0;right:0;bottom:0;height:1px;transform-origin:right;--tw-scale-x:0;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);content:var(--tw-content);transition-duration:.2s}.link.variant-animated:hover:before{transform-origin:left;content:var(--tw-content);--tw-scale-x:1;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.link.intent-info{--tw-text-opacity:1;color:rgb(96 165 250/var(--tw-text-opacity,1))}.link.intent-neutral{--tw-text-opacity:1;color:rgb(255 255 255/var(--tw-text-opacity,1))}.link.variant-animated.intent-neutral:before{content:var(--tw-content);background-color:hsla(0,0%,100%,.5)}.link.variant-animated.intent-info:before{content:var(--tw-content);--tw-bg-opacity:1;background-color:rgb(37 99 235/var(--tw-bg-opacity,1))}.link.variant-animated.intent-primary:before{content:var(--tw-content);--tw-bg-opacity:1;background-color:rgb(79 70 229/var(--tw-bg-opacity,1))}.link.variant-ghost.intent-neutral,.link.variant-underlined.intent-neutral{text-decoration-color:hsla(0,0%,100%,.5)}.mx-auto{margin-left:auto;margin-right:auto}.my-2{margin-top:.5rem;margin-bottom:.5rem}.my-6{margin-top:1.5rem;margin-bottom:1.5rem}.mb-2{margin-bottom:.5rem}.mb-6{margin-bottom:1.5rem}.mb-8{margin-bottom:2rem}.ml-1{margin-left:.25rem}.ml-4{margin-left:1rem}.mr-2{margin-right:.5rem}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mt-3{margin-top:.75rem}.block{display:block}.inline-block{display:inline-block}.inline{display:inline}.flex{display:flex}.grid{display:grid}.hidden{display:none}.h-4{height:1rem}.h-8{height:2rem}.min-h-screen{min-height:100vh}.min-h-svh{min-height:100svh}.w-4{width:1rem}.w-8{width:2rem}.max-w-full{max-width:100%}.max-w-screen-lg{max-width:1024px}.flex-1{flex:1 1 0%}.cursor-pointer{cursor:pointer}.list-disc{list-style-type:disc}.grid-cols-1{grid-template-columns:repeat(1,minmax(0,1fr))}.flex-col{flex-direction:column}.items-center{align-items:center}.justify-between{justify-content:space-between}.gap-4{gap:1rem}.gap-6{gap:1.5rem}.gap-8{gap:2rem}.space-y-2>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(.5rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(.5rem*var(--tw-space-y-reverse))}.space-y-3>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(.75rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(.75rem*var(--tw-space-y-reverse))}.space-y-4>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(1rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(1rem*var(--tw-space-y-reverse))}.space-y-6>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(1.5rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(1.5rem*var(--tw-space-y-reverse))}.scroll-smooth{scroll-behavior:smooth}.truncate{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.bg-gray-925{--tw-bg-opacity:1;background-color:rgb(9 9 21/var(--tw-bg-opacity,1))}.bg-gradient-to-r{background-image:linear-gradient(to right,var(--tw-gradient-stops))}.from-primary-600{--tw-gradient-from:#4f46e5 var(--tw-gradient-from-position);--tw-gradient-to:rgba(79,70,229,0) var(--tw-gradient-to-position);--tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to)}.to-accent-400{--tw-gradient-to:#e879f9 var(--tw-gradient-to-position)}.bg-clip-text{-webkit-background-clip:text;background-clip:text}.p-1{padding:.25rem}.px-4{padding-left:1rem;padding-right:1rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.py-4{padding-top:1rem;padding-bottom:1rem}.py-6{padding-top:1.5rem;padding-bottom:1.5rem}.pl-5{padding-left:1.25rem}.pt-2{padding-top:.5rem}.text-center{text-align:center}.font-sans{font-family:ui-sans-serif,system-ui,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}.text-2xl{font-size:1.5rem;line-height:2rem}.text-lg{font-size:1.125rem;line-height:1.75rem}.text-sm{font-size:.875rem;line-height:1.25rem}.text-xs{font-size:.75rem;line-height:1rem}.font-bold{font-weight:700}.font-medium{font-weight:500}.font-semibold{font-weight:600}.leading-normal{line-height:1.5}.text-gray-400{--tw-text-opacity:1;color:rgb(168 168 184/var(--tw-text-opacity,1))}.text-gray-500{--tw-text-opacity:1;color:rgb(110 110 129/var(--tw-text-opacity,1))}.text-transparent{color:transparent}.antialiased{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.transition{transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}.text-title{color:var(--title-text-color)}.text-body{color:var(--body-text-color)}.\!text-caption{color:var(--caption-text-color)!important}.text-caption{color:var(--caption-text-color)}.dark{--display-text-color:#fff;--title-text-color:var(--display-text-color);--caption-text-color:#6e6e81;--body-text-color:#d6d6e1;--placeholder-text-color:#4d4d5f;--ui-border-color:#232323}[data-shade="900"]:where(.dark,.dark *),[data-shade="925"]:where(.dark,.dark *),[data-shade="950"]:where(.dark,.dark *){--ui-border-color:#383838}.hover\:text-gray-300:hover{--tw-text-opacity:1;color:rgb(214 214 225/var(--tw-text-opacity,1))}.group[open] .group-open\:rotate-180{--tw-rotate:180deg;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}@media (min-width:768px){.md\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.md\:p-4{padding:1rem}.md\:px-6{padding-left:1.5rem;padding-right:1.5rem}.md\:pt-6{padding-top:1.5rem}}@media (min-width:1024px){.lg\:grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}.lg\:dark\:bg-gray-900:is(.dark *){--tw-bg-opacity:1;background-color:rgb(18 18 32/var(--tw-bg-opacity,1))}}</style></head><body class="bg-gray-925 min-h-screen min-h-svh font-sans leading-normal antialiased lg:dark:bg-gray-900"><main class="min-w-screen container mx-auto flex min-h-screen max-w-screen-lg flex-col px-4 py-6 md:px-6"><header class="space-y-2 pt-2 md:pt-6"><a title="{$title}" href="{$link}" target="_blank" rel="noopener noreferrer"><h1 class="flex text-2xl"><span class="icon-[tabler--rss] mr-2 h-8 w-8"/><span class="lg2:text-3xl from-primary-600 to-accent-400 inline-block bg-gradient-to-r bg-clip-text font-bold text-transparent"><xsl:value-of select="$title" disable-output-escaping="yes"/></span></h1></a><p class="text-body pt-2 text-lg py-4"><xsl:value-of select="$description" disable-output-escaping="yes"/></p><p class="text-caption text-sm">
              This RSS feed for the
              <a class="link intent-neutral variant-animated !text-caption font-bold" title="{$title}" href="{$link}" target="_blank" rel="noopener noreferrer"><xsl:value-of select="$title"/></a>
              website.
            </p><p class="text-body text-sm hidden" id="subscribe-links">
              You can subscribe this RSS feed by
              <a class="link intent-neutral variant-animated font-bold" title="Feedly" data-href="https://feedly.com/i/subscription/feed/" target="_blank" rel="noopener noreferrer">Feedly</a>,
              <a class="link intent-neutral variant-animated font-bold" title="Inoreader" data-href="https://www.inoreader.com/feed/" target="_blank" rel="noopener noreferrer">Inoreader</a>,
              <a class="link intent-neutral variant-animated font-bold" title="Newsblur" data-href="https://www.newsblur.com/?url=" target="_blank" rel="noopener noreferrer">Newsblur</a>,
              <a class="link intent-neutral variant-animated font-bold" title="Follow" data-href="follow://add?url=" rel="noopener noreferrer">Follow</a>,
              <a class="link intent-neutral variant-animated font-bold" title="RSS Reader" data-href="feed:" data-raw="true" rel="noopener noreferrer">RSS Reader</a>
              or
              <a class="link intent-neutral variant-animated font-bold" title="{$title} 's feed source" data-href="" data-raw="true" rel="noopener noreferrer">View Source</a>.
            </p><script>
              document.addEventListener('DOMContentLoaded', function () {
                document.querySelectorAll('a[data-href]').forEach(function (a) {
                  const url = new URL(location.href)
                  const feed = url.searchParams.get('url') || location.href
                  const raw = a.getAttribute('data-raw')
                  if (raw) {
                    a.href = a.getAttribute('data-href') + feed
                  } else {
                    a.href = a.getAttribute('data-href') + encodeURIComponent(feed)
                  }
                })
                document.getElementById('subscribe-links').classList.remove('hidden')
              })
            </script></header><hr class="my-6"/><section class="flex-1 space-y-6 p-1 md:p-4"><xsl:choose><xsl:when test="/rss/channel/item"><xsl:for-each select="/rss/channel/item"><article class="space-y-2"><details><summary class="max-w-full truncate"><xsl:if test="title"><h2 class="text-title inline cursor-pointer text-lg font-semibold"><xsl:value-of select="title" disable-output-escaping="yes"/></h2></xsl:if><xsl:if test="pubDate"><time class="text-caption ml-4 mt-1 block text-sm"><xsl:value-of select="pubDate"/></time></xsl:if></summary><div class="text-body px-4 py-2"><p class="my-2"><xsl:choose><xsl:when test="description"><xsl:value-of select="description" disable-output-escaping="yes"/></xsl:when></xsl:choose></p><xsl:if test="link"><a class="link variant-animated intent-neutral font-bold" href="{link}" target="_blank" rel="noopener noreferrer">
                            Read More
                          </a></xsl:if></div></details></article></xsl:for-each></xsl:when><xsl:when test="/atom:feed/atom:entry"><xsl:for-each select="/atom:feed/atom:entry"><article class="space-y-2"><details><summary class="max-w-full truncate"><xsl:if test="atom:title"><h2 class="text-title inline cursor-pointer text-lg font-semibold"><xsl:value-of select="atom:title" disable-output-escaping="yes"/></h2></xsl:if><xsl:if test="atom:updated"><time class="text-caption ml-4 mt-1 block text-sm"><xsl:value-of select="atom:updated"/></time></xsl:if></summary><div class="text-body px-4 py-2"><p class="my-2"><xsl:choose><xsl:when test="atom:summary"><xsl:value-of select="atom:summary" disable-output-escaping="yes"/></xsl:when><xsl:when test="atom:content"><xsl:value-of select="atom:content" disable-output-escaping="yes"/></xsl:when></xsl:choose></p><xsl:if test="atom:link/@href"><a class="link variant-animated intent-neutral font-bold" href="{atom:link/@href}" target="_blank" rel="noopener noreferrer">
                            Read More
                          </a></xsl:if></div></details></article></xsl:for-each></xsl:when></xsl:choose></section><hr class="my-6"/><footer class="text-gray-400"><div class="container mx-auto px-4"><div class="mb-8"><h3 class="text-lg font-semibold text-title mb-6">Popular Feed Collections</h3><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6"><div class="space-y-3"><a href="https://redreamality.com/GitHubTrendingRSS/weekly/python.xml" class="block hover:text-gray-300"><div class="font-medium">🐍 Python TrendWatch</div><div class="text-xs text-gray-500">AI, ML &amp; Data Science Innovation Feed</div></a><a href="https://redreamality.com/GitHubTrendingRSS/weekly/cuda.xml" class="block hover:text-gray-300"><div class="font-medium">⚡ CUDA Accelerator</div><div class="text-xs text-gray-500">GPU Computing &amp; Deep Learning Updates</div></a><a href="https://redreamality.com/GitHubTrendingRSS/weekly/matlab.xml" class="block hover:text-gray-300"><div class="font-medium">🧠 MATLAB TrendPulse</div><div class="text-xs text-gray-500">MEG, EEG and iEEG Research Feed</div></a></div><div class="space-y-3"><a href="https://redreamality.com/GitHubTrendingRSS/weekly/rust.xml" class="block hover:text-gray-300"><div class="font-medium">🦀 Rust Systems Feed</div><div class="text-xs text-gray-500">High-Performance &amp; Safe Systems Programming</div></a><a href="https://redreamality.com/GitHubTrendingRSS/weekly/go.xml" class="block hover:text-gray-300"><div class="font-medium">🚀 Go Infrastructure</div><div class="text-xs text-gray-500">Cloud Native &amp; DevOps Excellence</div></a><a href="https://redreamality.com/GitHubTrendingRSS/weekly/typescript.xml" class="block hover:text-gray-300"><div class="font-medium">📱 TypeScript Ecosystem</div><div class="text-xs text-gray-500">Modern Web &amp; App Development</div></a></div><div class="space-y-3"><a href="https://redreamality.com/GitHubTrendingRSS/daily/adblock-filter-list.xml" class="block hover:text-gray-300"><div class="font-medium">🛡️ Privacy Shield</div><div class="text-xs text-gray-500">AdBlock &amp; Security Updates</div></a><a href="https://redreamality.com/GitHubTrendingRSS/daily/all.xml" class="block hover:text-gray-300"><div class="font-medium">🌟 Global TechRadar</div><div class="text-xs text-gray-500">Cross-Language Innovation Pulse, add it to your RSS reader rsshub://github/trending/monthly/any/zh</div></a></div></div></div><div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-8"><div class="space-y-4"><h3 class="text-lg font-semibold text-title">Getting Started</h3><div class="grid grid-cols-1 gap-4"><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">📖 Feed Integration Guide</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">1. Choose Your RSS Reader:</p><ul class="list-disc pl-5 space-y-2"><li>Feedly: Professional choice for cross-platform sync</li><li>Inoreader: Advanced filtering capabilities</li><li>NetNewsWire: Perfect for macOS/iOS users</li><li>FreshRSS: Self-hosted option with full control</li></ul><p class="mt-3 mb-2">2. Add Our Feeds:</p><ul class="list-disc pl-5 space-y-2"><li>Copy the feed URL (e.g., rsshub://github/trending/monthly/any/zh)</li><li>In your RSS reader, look for "Add Feed" or "Subscribe"</li><li>Paste the URL and customize update frequency</li></ul></div></details><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">🎯 Custom Feed Creation</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Create Your Perfect Feed:</p><ul class="list-disc pl-5 space-y-2"><li>Language-specific: /GitHubTrendingRSS/[frequency]/[language].xml</li><li>Topic-focused: Combine multiple language feeds</li><li>Custom time ranges: daily, weekly, or monthly updates</li><li>Regional feeds: Focus on specific developer communities</li></ul><p class="mt-3">Pro tip: Use tags in your RSS reader to organize feeds by topic, language, or priority.</p></div></details><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">⚡ Feed Management Tips</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Optimize Your Feed Reading:</p><ul class="list-disc pl-5 space-y-2"><li>Set update frequencies based on feed importance</li><li>Use folders to group related feeds (e.g., AI/ML, Web Dev)</li><li>Enable notifications only for high-priority feeds</li><li>Archive valuable resources for future reference</li></ul><p class="mt-3">Advanced Features:</p><ul class="list-disc pl-5 space-y-2"><li>Filter feeds using keywords to focus on specific topics</li><li>Set up IFTTT integrations for automated workflows</li><li>Export/backup your feed collection regularly</li></ul></div></details></div></div><div class="space-y-4"><h3 class="text-lg font-semibold text-title">Common Questions</h3><div class="grid grid-cols-1 gap-4"><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">🤔 About Github Radar</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Github Radar is your intelligent curator for:</p><ul class="list-disc pl-5 space-y-2"><li>Trending repositories across all programming languages</li><li>Language-specific innovation and updates</li><li>Regional development trends and patterns</li><li>Open source community movements</li></ul><p class="mt-3">Our mission is to help developers stay updated with minimal effort through smart feed curation and organization.</p></div></details><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">📊 Feed Frequency Options</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Choose Your Update Rhythm:</p><ul class="list-disc pl-5 space-y-2"><li>Daily: Perfect for fast-moving technologies and security updates</li><li>Weekly: Ideal for maintaining awareness without overwhelm</li><li>Monthly: Best for long-term trend analysis and strategic planning</li></ul><p class="mt-3">Customize by combining different frequencies for different topics based on your needs.</p></div></details><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">🔧 Technical Support</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Supported RSS Readers:</p><ul class="list-disc pl-5 space-y-2"><li>Desktop: NetNewsWire, Reeder, FeedReader</li><li>Mobile: Feedly, Inoreader, NewsBlur</li><li>Self-hosted: FreshRSS, Tiny Tiny RSS</li><li>Browser-based: Feedbro, RSS Feed Reader</li></ul><p class="mt-3">Common Issues:</p><ul class="list-disc pl-5 space-y-2"><li>Feed not updating? Check your reader's refresh settings</li><li>Missing content? Verify your internet connection</li><li>Format issues? Try re-subscribing to the feed</li></ul></div></details></div></div></div><div class="text-center text-sm"><p class="mt-2">Acknowledgement: Page decorated by <a href="https://github.com/ccbikai/RSS.Beauty"><svg class="inline-block w-4 h-4 ml-1" viewBox="0 0 16 16" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a> RSS.Beauty</p></div></div></footer></main></body></html></xsl:template></xsl:stylesheet>"?>
<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Sat, 29 Mar 2025 02:28:26 GMT</pubDate>
    <link>http://redreamality.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>odoo/odoo</title>
      <link>https://github.com/odoo/odoo</link>
      <description>&lt;p&gt;Odoo. Open Source Apps To Grow Your Business.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://runbot.odoo.com/runbot&quot;&gt;&lt;img src=&quot;https://runbot.odoo.com/runbot/badge/flat/1/master.svg?sanitize=true&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.odoo.com/documentation/master&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/master-docs-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F&quot; alt=&quot;Tech Doc&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.odoo.com/forum/help-1&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/master-help-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F&quot; alt=&quot;Help&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://nightly.odoo.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/master-nightly-875A7B.svg?style=flat&amp;amp;colorA=8F8F8F&quot; alt=&quot;Nightly Builds&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Odoo&lt;/h2&gt; 
&lt;p&gt;Odoo is a suite of web based open source business apps.&lt;/p&gt; 
&lt;p&gt;The main Odoo Apps include an &lt;a href=&quot;https://www.odoo.com/page/crm&quot;&gt;Open Source CRM&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/website&quot;&gt;Website Builder&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/ecommerce&quot;&gt;eCommerce&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/inventory&quot;&gt;Warehouse Management&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/project&quot;&gt;Project Management&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/accounting&quot;&gt;Billing &amp;amp; Accounting&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/point-of-sale-shop&quot;&gt;Point of Sale&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/employees&quot;&gt;Human Resources&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/social-marketing&quot;&gt;Marketing&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/app/manufacturing&quot;&gt;Manufacturing&lt;/a&gt;, &lt;a href=&quot;https://www.odoo.com/&quot;&gt;...&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Odoo Apps can be used as stand-alone applications, but they also integrate seamlessly so you get a full-featured &lt;a href=&quot;https://www.odoo.com&quot;&gt;Open Source ERP&lt;/a&gt; when you install several Apps.&lt;/p&gt; 
&lt;h2&gt;Getting started with Odoo&lt;/h2&gt; 
&lt;p&gt;For a standard installation please follow the &lt;a href=&quot;https://www.odoo.com/documentation/master/administration/install/install.html&quot;&gt;Setup instructions&lt;/a&gt; from the documentation.&lt;/p&gt; 
&lt;p&gt;To learn the software, we recommend the &lt;a href=&quot;https://www.odoo.com/slides&quot;&gt;Odoo eLearning&lt;/a&gt;, or &lt;a href=&quot;https://www.odoo.com/page/scale-up-business-game&quot;&gt;Scale-up&lt;/a&gt;, the &lt;a href=&quot;https://www.odoo.com/page/scale-up-business-game&quot;&gt;business game&lt;/a&gt;. Developers can start with &lt;a href=&quot;https://www.odoo.com/documentation/master/developer/howtos.html&quot;&gt;the developer tutorials&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mindsdb/mindsdb</title>
      <link>https://github.com/mindsdb/mindsdb</link>
      <description>&lt;p&gt;AI&#39;s query engine - Platform for building AI that can learn and answer questions over large scale federated data.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://pypi.org/project/MindsDB/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/MindsDB.svg?sanitize=true&quot; alt=&quot;MindsDB Release&quot;&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://www.python.org/downloads/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/python-3.9.x%7C%203.10.x%7C%203.11.x-brightgreen.svg?sanitize=true&quot; alt=&quot;Python supported&quot;&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://ossrank.com/p/630&quot;&gt;&lt;img src=&quot;https://shields.io/endpoint?url=https://ossrank.com/shield/630&quot;&gt;&lt;/a&gt; 
 &lt;img alt=&quot;PyPI - Downloads&quot; src=&quot;https://img.shields.io/pypi/dm/Mindsdb&quot;&gt; 
 &lt;a href=&quot;https://hub.docker.com/u/mindsdb&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/mindsdb/mindsdb&quot; alt=&quot;Docker pulls&quot;&gt;&lt;/a&gt; 
 &lt;br&gt; 
 &lt;br&gt; 
 &lt;a href=&quot;https://github.com/mindsdb/mindsdb&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/mindsdb/mindsdb/main/docs/assets/mindsdb_logo.png&quot; alt=&quot;MindsDB&quot; width=&quot;300&quot;&gt; &lt;/a&gt; 
 &lt;p align=&quot;center&quot;&gt; &lt;br&gt; &lt;a href=&quot;https://www.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&quot;&gt;Website&lt;/a&gt; · &lt;a href=&quot;https://docs.mindsdb.com?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&quot;&gt;Docs&lt;/a&gt; · &lt;a href=&quot;https://mdb.ai/register&quot;&gt;Demo&lt;/a&gt; · &lt;a href=&quot;https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&quot;&gt;Community Slack&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p&gt;MindsDB is the world&#39;s most effective solution for building AI applications that talk to messy enterprise data sources. Think of it as a librarian Marie Kondo.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/mindsdb/mindsdb/main/docs/assets/cloud/main_mdb.png&quot;&gt; &lt;/p&gt; 
&lt;p&gt;A federated query engine that tidies up your data-sprawl chaos while meticulously answering every single question you throw at it.&lt;/p&gt; 
&lt;h2&gt;Minds &lt;a href=&quot;https://mdb.ai/register&quot;&gt;Demo&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Play with &lt;a href=&quot;https://mdb.ai/register&quot;&gt;Minds demo&lt;/a&gt;, and see the power of MindsDB at answering questions from structured to unstructured data, whether it&#39;s scattered across SaaS applications, databases, or... hibernating in data warehouses like that $100 bill in your tuxedo pocket from prom night, lost, waiting to be discovered.&lt;/p&gt; 
&lt;h2&gt;Install MindsDB Server&lt;/h2&gt; 
&lt;p&gt;MindsDB is an open-source server that can be deployed anywhere - from your laptop to the cloud, and everywhere in between. And yes, you can customize it to your heart&#39;s content.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.mindsdb.com/setup/self-hosted/docker-desktop&quot;&gt;Using Docker Desktop&lt;/a&gt;. This is the fastest and recommended way to get started and have it all running.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.mindsdb.com/setup/self-hosted/docker&quot;&gt;Using Docker&lt;/a&gt;. This is also simple, but gives you more flexibility on how to further customize your server.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.mindsdb.com/contribute/install&quot;&gt;Using PyPI&lt;/a&gt;. This option enables you to contribute to MindsDB.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Connect Your Data&lt;/h2&gt; 
&lt;p&gt;You can connect to hundreds of &lt;a href=&quot;https://docs.mindsdb.com/integrations/data-overview&quot;&gt;data sources (learn more)&lt;/a&gt;. This is just an example of a Postgres database.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- Connect to demo postgres DB
CREATE DATABASE demo_postgres_db
WITH ENGINE = &quot;postgres&quot;,
PARAMETERS = {
  &quot;user&quot;: &quot;demo_user&quot;,
  &quot;password&quot;: &quot;demo_password&quot;,
  &quot;host&quot;: &quot;samples.mindsdb.com&quot;,
  &quot;port&quot;: &quot;5432&quot;,
  &quot;database&quot;: &quot;demo&quot;,
  &quot;schema&quot;: &quot;demo_data&quot;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once you&#39;ve connected your data sources, you can &lt;a href=&quot;https://docs.mindsdb.com/mindsdb_sql/sql/api/join-on&quot;&gt;combine&lt;/a&gt;, &lt;a href=&quot;https://docs.mindsdb.com/mindsdb_sql/sql/api/select&quot;&gt;slice it, dice it&lt;/a&gt;, and &lt;a href=&quot;https://docs.mindsdb.com/use-cases/data_enrichment/overview&quot;&gt;transform&lt;/a&gt; it however your heart desires using good ol&#39; standard SQL &lt;a href=&quot;https://docs.mindsdb.com/mindsdb_sql/overview&quot;&gt;(learn more)&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After you&#39;ve whipped your data into shape, it&#39;s time to build AI that actually learns!&lt;/p&gt; 
&lt;h2&gt;Build AI Knowledge&lt;/h2&gt; 
&lt;p&gt;Our Knowledge Bases are state-of-the-art autonomous RAG systems that can digest data from any source MindsDB supports. Whether your data is structured and neater than a Swiss watch factory or unstructured and messy as a teenager&#39;s bedroom, our Knowledge Base engine will figure out how to find the relevant information.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;In this example&lt;/strong&gt; we will create a knowledge base that knows everything about amazon reviews.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- first create a knowledge base
CREATE KNOWLEDGE_BASE mindsdb.reviews_kb;

-- now insert everything from the amazon reviews table into it, so it can learn it
INSERT INTO mindsdb.reviews_kb (
  SELECT review as content FROM demo_pg_db.amazon_reviews
);

-- check the status of your loads here
SELECT * FROM information_schema.knowledge_bases;

-- query the content of the knowledge base
SELECT * FROM mindsdb.reviews_kb;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the tinkerers and optimization enthusiasts out there, you can dive as deep as you want. &lt;a href=&quot;https://docs.mindsdb.com/mindsdb_sql/agents/knowledge-bases&quot;&gt;(Learn more about knowledge Bases)&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Want to &lt;a href=&quot;https://docs.mindsdb.com/mindsdb_sql/agents/knowledge-bases#knowledge-base-with-openai-embedding-model&quot;&gt;hand-pick your embedding model? Go for it&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;Have strong &lt;a href=&quot;https://docs.mindsdb.com/mindsdb_sql/agents/knowledge-bases#knowledge-base-with-custom-vector-store&quot;&gt;opinions about vector databases? We&#39;re here for it!&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;But if you&#39;d rather spend your time on other things (like finally building that billion-dollar AI App), that&#39;s perfectly fine too. By default, it&#39;s all handled automatically - you don&#39;t need to worry about the nitty-gritty details like data embedding, chunking, vector optimization, etc.&lt;/p&gt; 
&lt;h2&gt;Search&lt;/h2&gt; 
&lt;p&gt;Now that your knowledge base is loaded and ready. Let&#39;s hunt for some juicy info!&lt;/p&gt; 
&lt;h4&gt;Via SQL&lt;/h4&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;-- Find the reviews that about Iphone in beast of lights
SELECT *  FROM mindsdb.reviews_kb
WHERE content LIKE &#39;what are the best kindle reviews&#39;
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Via Python SDK&lt;/h4&gt; 
&lt;p&gt;Install MindsDB SDK&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install mindsdb_sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can call this AI knowledge base from your app with the following code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import mindsdb_sdk


# connects to the specified host and port
server = mindsdb_sdk.connect(&#39;http://127.0.0.1:47334&#39;)

wiki_kb = server.knowledge_bases.get(&#39;mindsdb.reviews_kb&#39;);
df = my_kb.find(&#39;what are the best kindle reviews&#39;).fetch()

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🤝 Contribute&lt;/h2&gt; 
&lt;p&gt;Interested in contributing to MindsDB? Follow our &lt;a href=&quot;https://docs.mindsdb.com/contribute/install?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&quot;&gt;installation guide for development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find our &lt;a href=&quot;https://docs.mindsdb.com/contribute/contribute?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&quot;&gt;contribution guide here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We welcome suggestions! Feel free to open new issues with your ideas, and we’ll guide you.&lt;/p&gt; 
&lt;p&gt;This project adheres to a &lt;a href=&quot;https://github.com/mindsdb/mindsdb/raw/main/CODE_OF_CONDUCT.md&quot;&gt;Contributor Code of Conduct&lt;/a&gt;. By participating, you agree to follow its terms.&lt;/p&gt; 
&lt;p&gt;Also, check out our &lt;a href=&quot;https://mindsdb.com/community?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&quot;&gt;community rewards and programs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🤍 Support&lt;/h2&gt; 
&lt;p&gt;If you find a bug, please submit an &lt;a href=&quot;https://github.com/mindsdb/mindsdb/issues/new/choose&quot;&gt;issue on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here’s how you can get community support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ask a question in our &lt;a href=&quot;https://mindsdb.com/joincommunity?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&quot;&gt;Slack Community&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href=&quot;https://github.com/mindsdb/mindsdb/discussions&quot;&gt;GitHub Discussions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Post on &lt;a href=&quot;https://stackoverflow.com/questions/tagged/mindsdb&quot;&gt;Stack Overflow&lt;/a&gt; with the MindsDB tag.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For commercial support, please &lt;a href=&quot;https://mindsdb.com/contact?utm_medium=community&amp;amp;utm_source=github&amp;amp;utm_campaign=mindsdb%20repo&quot;&gt;contact the MindsDB team&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;💚 Current Contributors&lt;/h2&gt; 
&lt;a href=&quot;https://github.com/mindsdb/mindsdb/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contributors-img.web.app/image?repo=mindsdb/mindsdb&quot;&gt; &lt;/a&gt; 
&lt;p&gt;Generated with &lt;a href=&quot;https://contributors-img.web.app&quot;&gt;contributors-img&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🔔 Subscribe for Updates&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href=&quot;https://mindsdb.com/joincommunity&quot;&gt;Slack community&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>khoj-ai/khoj</title>
      <link>https://github.com/khoj-ai/khoj</link>
      <description>&lt;p&gt;Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free.&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://assets.khoj.dev/khoj-logo-sideways-1200x540.png&quot; width=&quot;230&quot; alt=&quot;Khoj Logo&quot;&gt;&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/khoj-ai/khoj/actions/workflows/test.yml&quot;&gt;&lt;img src=&quot;https://github.com/khoj-ai/khoj/actions/workflows/test.yml/badge.svg?sanitize=true&quot; alt=&quot;test&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/khoj-ai/khoj/pkgs/container/khoj&quot;&gt;&lt;img src=&quot;https://github.com/khoj-ai/khoj/actions/workflows/dockerize.yml/badge.svg?sanitize=true&quot; alt=&quot;docker&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/khoj/&quot;&gt;&lt;img src=&quot;https://github.com/khoj-ai/khoj/actions/workflows/pypi.yml/badge.svg?sanitize=true&quot; alt=&quot;pypi&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/BDgyabRM6e&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1112065956647284756?style=plastic&amp;amp;label=discord&quot; alt=&quot;discord&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;b&gt;Your AI second brain&lt;/b&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://docs.khoj.dev&quot;&gt;📑 Docs&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href=&quot;https://khoj.dev&quot;&gt;🌐 Web&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href=&quot;https://app.khoj.dev&quot;&gt;🔥 App&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href=&quot;https://discord.gg/BDgyabRM6e&quot;&gt;💬 Discord&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href=&quot;https://blog.khoj.dev&quot;&gt;✍🏽 Blog&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h3&gt;🎁 New&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start any message with &lt;code&gt;/research&lt;/code&gt; to try out the experimental research mode with Khoj.&lt;/li&gt; 
 &lt;li&gt;Anyone can now &lt;a href=&quot;https://blog.khoj.dev/posts/create-agents-on-khoj/&quot;&gt;create custom agents&lt;/a&gt; with tunable personality, tools and knowledge bases.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.khoj.dev/posts/evaluate-khoj-quality/&quot;&gt;Read&lt;/a&gt; about Khoj&#39;s excellent performance on modern retrieval and reasoning benchmarks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://khoj.dev&quot;&gt;Khoj&lt;/a&gt; is a personal AI app to extend your capabilities. It smoothly scales up from an on-device personal AI to a cloud-scale enterprise AI.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chat with any local or online LLM (e.g llama3, qwen, gemma, mistral, gpt, claude, gemini).&lt;/li&gt; 
 &lt;li&gt;Get answers from the internet and your docs (including image, pdf, markdown, org-mode, word, notion files).&lt;/li&gt; 
 &lt;li&gt;Access it from your Browser, Obsidian, Emacs, Desktop, Phone or Whatsapp.&lt;/li&gt; 
 &lt;li&gt;Create agents with custom knowledge, persona, chat model and tools to take on any role.&lt;/li&gt; 
 &lt;li&gt;Automate away repetitive research. Get personal newsletters and smart notifications delivered to your inbox.&lt;/li&gt; 
 &lt;li&gt;Find relevant docs quickly and easily using our advanced semantic search.&lt;/li&gt; 
 &lt;li&gt;Generate images, talk out loud, play your messages.&lt;/li&gt; 
 &lt;li&gt;Khoj is open-source, self-hostable. Always.&lt;/li&gt; 
 &lt;li&gt;Run it privately on &lt;a href=&quot;https://docs.khoj.dev/get-started/setup&quot;&gt;your computer&lt;/a&gt; or try it on our &lt;a href=&quot;https://app.khoj.dev&quot;&gt;cloud app&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;See it in action&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/khoj-ai/khoj/raw/master/documentation/assets/img/quadratic_equation_khoj_web.gif?raw=true&quot; alt=&quot;demo_chat&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Go to &lt;a href=&quot;https://app.khoj.dev&quot;&gt;https://app.khoj.dev&lt;/a&gt; to see Khoj live.&lt;/p&gt; 
&lt;h2&gt;Full feature list&lt;/h2&gt; 
&lt;p&gt;You can see the full feature list &lt;a href=&quot;https://docs.khoj.dev/category/features&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Self-Host&lt;/h2&gt; 
&lt;p&gt;To get started with self-hosting Khoj, &lt;a href=&quot;https://docs.khoj.dev/get-started/setup&quot;&gt;read the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;Khoj is available as a cloud service, on-premises, or as a hybrid solution. To learn more about Khoj Enterprise, &lt;a href=&quot;https://khoj.dev/teams&quot;&gt;visit our website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Cheers to our awesome contributors! 🎉&lt;/p&gt; 
&lt;a href=&quot;https://github.com/khoj-ai/khoj/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contrib.rocks/image?repo=khoj-ai/khoj&quot;&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href=&quot;https://contrib.rocks&quot;&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Interested in Contributing?&lt;/h3&gt; 
&lt;p&gt;We are always looking for contributors to help us build new features, improve the project documentation, or fix bugs. If you&#39;re interested, please see our &lt;a href=&quot;https://docs.khoj.dev/contributing/development&quot;&gt;Contributing Guidelines&lt;/a&gt; and check out our &lt;a href=&quot;https://github.com/orgs/khoj-ai/projects/4&quot;&gt;Contributors Project Board&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Shubhamsaboo/awesome-llm-apps</title>
      <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
      <description>&lt;p&gt;Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;http://www.theunwindai.com&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/unwind_black.png&quot; width=&quot;900px&quot; alt=&quot;Unwind AI&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.linkedin.com/in/shubhamsaboo/&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;amp;style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://twitter.com/Saboo_Shubham_&quot;&gt; &lt;img src=&quot;https://img.shields.io/twitter/follow/Shubham_Saboo&quot; alt=&quot;Twitter&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;h1&gt;🌟 Awesome LLM Apps&lt;/h1&gt; 
&lt;p&gt;A curated collection of awesome LLM apps built with RAG and AI agents. This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://trendshift.io/repositories/9876&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://trendshift.io/api/badge/repositories/9876&quot; alt=&quot;Shubhamsaboo%2Fawesome-llm-apps | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;🤔 Why Awesome LLM Apps?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;💡 Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.&lt;/li&gt; 
 &lt;li&gt;🔥 Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with RAG and AI Agents.&lt;/li&gt; 
 &lt;li&gt;🎓 Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚨 Open Source AI Agent Hackathon! 🚨&lt;/h2&gt; 
&lt;p&gt;We&#39;re launching a Global AI Agent Hackathon in collaboration with AI Agent ecosystem partners — open to all developers, builders, and startups working on agents, RAG, tool use, or multi-agent systems.&lt;/p&gt; 
&lt;h3&gt;💰 Win up to $20,000 in cash by building Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🏅 10 winners: $300 each&lt;/li&gt; 
 &lt;li&gt;🥉 10 winners: $500 each&lt;/li&gt; 
 &lt;li&gt;🥈 5 winners: $1,000 each&lt;/li&gt; 
 &lt;li&gt;🥇 1 winner: $2,000&lt;/li&gt; 
 &lt;li&gt;🏆 GRAND PRIZE: $5,000 🏆&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🎁 Bonus&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Top 5 projects will be featured in the top trending &lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps&quot;&gt;Awesome LLM Apps&lt;/a&gt; repo.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤝 Partners&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.theunwindai.com&quot;&gt;Unwind AI&lt;/a&gt;, &lt;a href=&quot;https://www.agno.com&quot;&gt;Agno&lt;/a&gt; and more Agent ecosystem companies joining soon.&lt;/p&gt; 
&lt;h3&gt;📅 Here&#39;s the timeline:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;April 3rd - Final dates revealed&lt;/li&gt; 
 &lt;li&gt;April 10th - Prize and success criteria announced&lt;/li&gt; 
 &lt;li&gt;April 15th (tentative) - Hackathon starts&lt;/li&gt; 
 &lt;li&gt;May 30th (tentative) - Hackathon ends&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Join us for a month of building Agents!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Prizes will be distributed on an ongoing basis and continue till all prizes are awarded.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;⭐ Star this repo and follow along to stay updated.&lt;/p&gt; 
&lt;h3&gt;🤝 Want to join us as a partner or judge?&lt;/h3&gt; 
&lt;p&gt;If you&#39;re a company in the AI agent ecosystem or would like to judge the hackathon, reach out to &lt;a href=&quot;https://x.com/Saboo_Shubham_&quot;&gt;Shubham Saboo&lt;/a&gt; or &lt;a href=&quot;https://x.com/ashpreetbedi&quot;&gt;Ashpreet Bedi&lt;/a&gt; on X to partner. Let’s make this the biggest open source AI Agent hackathon.&lt;/p&gt; 
&lt;h2&gt;📂 Featured AI Projects&lt;/h2&gt; 
&lt;h3&gt;AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_customer_support_agent&quot;&gt;💼 AI Customer Support Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_investment_agent&quot;&gt;📈 AI Investment Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_legal_agent_team&quot;&gt;👨‍⚖️ AI Legal Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_recruitment_agent_team&quot;&gt;💼 AI Recruitment Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_services_agency&quot;&gt;👨‍💼 AI Services Agency&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_competitor_intelligence_agent_team&quot;&gt;🧲 AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_health_fitness_agent&quot;&gt;🏋️‍♂️ AI Health &amp;amp; Fitness Planner Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_startup_trend_analysis_agent&quot;&gt;📈 AI Startup Trend Analysis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_journalist_agent&quot;&gt;🗞️ AI Journalist Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_finance_agent_team&quot;&gt;💲 AI Finance Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_competitor_intelligence_agent_team&quot;&gt;🧲 AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_lead_generation_agent&quot;&gt;🎯 AI Lead Generation Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_personal_finance_agent&quot;&gt;💰 AI Personal Finance Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_medical_imaging_agent&quot;&gt;🩻 AI Medical Scan Diagnosis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_teaching_agent_team&quot;&gt;👨‍🏫 AI Teaching Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_travel_agent&quot;&gt;🛫 AI Travel Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_movie_production_agent&quot;&gt;🎬 AI Movie Production Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/multi_agent_researcher&quot;&gt;📰 Multi-Agent AI Researcher&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_coding_agent_o3-mini&quot;&gt;💻 Multimodal AI Coding Agent Team with o3-mini and Gemini&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_meeting_agent&quot;&gt;📑 AI Meeting Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_chess_agent&quot;&gt;♜ AI Chess Agent Game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_real_estate_agent&quot;&gt;🏠 AI Real Estate Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/local_news_agent_openai_swarm&quot;&gt;🌐 Local News Agent OpenAI Swarm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/xai_finance_agent&quot;&gt;📊 AI Finance Agent with xAI Grok&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_3dpygame_r1&quot;&gt;🎮 AI 3D PyGame Visualizer with DeepSeek R1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_reasoning_agent&quot;&gt;🧠 AI Reasoning Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/multimodal_ai_agent&quot;&gt;🧬 Multimodal AI Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RAG (Retrieval Augmented Generation)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/autonomous_rag&quot;&gt;🔍 Autonomous RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/agentic_rag&quot;&gt;🔗 Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/gemini_agentic_rag&quot;&gt;🤔 Agentic RAG with Gemini Flash Thinking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/deepseek_local_rag_agent&quot;&gt;🐋 Deepseek Local RAG Reasoning Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/llama3.1_local_rag&quot;&gt;🔄 Llama3.1 Local RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/rag-as-a-service&quot;&gt;🧩 RAG-as-a-Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/local_rag_agent&quot;&gt;🦙 Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/hybrid_search_rag&quot;&gt;👀 RAG App with Hybrid Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/local_hybrid_search_rag&quot;&gt;🖥️ Local RAG App with Hybrid Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/rag_database_routing&quot;&gt;📠 RAG Agent with Database Routing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/corrective_rag&quot;&gt;🔄 Corrective RAG Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MCP AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/mcp_ai_agents/github_mcp_agent&quot;&gt;🐙 MCP GitHub Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;LLM Apps with Memory&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory&quot;&gt;💾 AI Arxiv Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_apps_with_memory_tutorials/llm_app_personalized_memory&quot;&gt;📝 LLM App with Personalized Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_apps_with_memory_tutorials/ai_travel_agent_memory&quot;&gt;🛩️ AI Travel Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_apps_with_memory_tutorials/local_chatgpt_with_memory&quot;&gt;🗄️ Local ChatGPT with Memory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Chat with X&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_github&quot;&gt;💬 Chat with GitHub Repo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_gmail&quot;&gt;📨 Chat with Gmail&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_pdf&quot;&gt;📄 Chat with PDF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_research_papers&quot;&gt;📚 Chat with Research Papers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_substack&quot;&gt;📝 Chat with Substack Newsletter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_youtube_videos&quot;&gt;📽️ Chat with YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;LLM Finetuning&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_finetuning_tutorials/llama3.2_finetuning&quot;&gt;🌐 Llama3.2 Finetuning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Tools and Frameworks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/gemini_multimodal_chatbot&quot;&gt;🧪 Gemini Multimodal Chatbot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/mixture_of_agents&quot;&gt;🔄 Mixture of Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/multillm_chat_playground&quot;&gt;🌐 MultiLLM Chat Playground&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/llm_router_app&quot;&gt;🔗 LLM Router App&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/local_chatgpt_clone&quot;&gt;💬 Local ChatGPT Clone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/web_scrapping_ai_agent&quot;&gt;🌍 Web Scraping AI Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/web_search_ai_assistant&quot;&gt;🔍 Web Search AI Assistant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/cursor_ai_experiments&quot;&gt;🧪 Cursor AI Experiments&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd awesome-llm-apps/chat_with_X_tutorials/chat_with_gmail
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow the project-specific instructions&lt;/strong&gt; in each project&#39;s &lt;code&gt;README.md&lt;/code&gt; file to set up and run the app.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🤝 Contributing to Open Source&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new &lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/issues&quot;&gt;GitHub Issue&lt;/a&gt; or submit a pull request. Make sure to follow the existing project structure and include a detailed &lt;code&gt;README.md&lt;/code&gt; for each new app.&lt;/p&gt; 
&lt;h3&gt;Thank You, Community, for the Support! 🙏&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;amp;Date&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🌟 &lt;strong&gt;Don’t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>huggingface/accelerate</title>
      <link>https://github.com/huggingface/accelerate</link>
      <description>&lt;p&gt;🚀 A simple way to launch, train, and use PyTorch models on almost any device and distributed configuration, automatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;br&gt; &lt;img src=&quot;https://raw.githubusercontent.com/huggingface/accelerate/main/docs/source/imgs/accelerate_logo.png&quot; width=&quot;400&quot;&gt; &lt;br&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align=&quot;center&quot;&gt; 
 &lt;!-- Uncomment when CircleCI is set up
    &lt;a href=&quot;https://circleci.com/gh/huggingface/accelerate&quot;&gt;&lt;img alt=&quot;Build&quot; src=&quot;https://img.shields.io/circleci/build/github/huggingface/transformers/master&quot;&gt;&lt;/a&gt;
    --&gt; &lt;a href=&quot;https://github.com/huggingface/accelerate/raw/main/LICENSE&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/github/license/huggingface/accelerate.svg?color=blue&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://huggingface.co/docs/accelerate/index.html&quot;&gt;&lt;img alt=&quot;Documentation&quot; src=&quot;https://img.shields.io/website/http/huggingface.co/docs/accelerate/index.html.svg?down_color=red&amp;amp;down_message=offline&amp;amp;up_message=online&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/accelerate/releases&quot;&gt;&lt;img alt=&quot;GitHub release&quot; src=&quot;https://img.shields.io/github/release/huggingface/accelerate.svg?sanitize=true&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/accelerate/raw/main/CODE_OF_CONDUCT.md&quot;&gt;&lt;img alt=&quot;Contributor Covenant&quot; src=&quot;https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg?sanitize=true&quot;&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h3 align=&quot;center&quot;&gt; &lt;p&gt;Run your *raw* PyTorch training script on any kind of device &lt;/p&gt;&lt;/h3&gt; 
&lt;h3 align=&quot;center&quot;&gt; &lt;a href=&quot;https://hf.co/course&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/accelerate/main/docs/source/imgs/course_banner.png&quot;&gt;&lt;/a&gt; &lt;/h3&gt; 
&lt;h2&gt;Easy to integrate&lt;/h2&gt; 
&lt;p&gt;🤗 Accelerate was created for PyTorch users who like to write the training loop of PyTorch models but are reluctant to write and maintain the boilerplate code needed to use multi-GPUs/TPU/fp16.&lt;/p&gt; 
&lt;p&gt;🤗 Accelerate abstracts exactly and only the boilerplate code related to multi-GPUs/TPU/fp16 and leaves the rest of your code unchanged.&lt;/p&gt; 
&lt;p&gt;Here is an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-diff&quot;&gt;  import torch
  import torch.nn.functional as F
  from datasets import load_dataset
+ from accelerate import Accelerator

+ accelerator = Accelerator()
- device = &#39;cpu&#39;
+ device = accelerator.device

  model = torch.nn.Transformer().to(device)
  optimizer = torch.optim.Adam(model.parameters())

  dataset = load_dataset(&#39;my_dataset&#39;)
  data = torch.utils.data.DataLoader(dataset, shuffle=True)

+ model, optimizer, data = accelerator.prepare(model, optimizer, data)

  model.train()
  for epoch in range(10):
      for source, targets in data:
          source = source.to(device)
          targets = targets.to(device)

          optimizer.zero_grad()

          output = model(source)
          loss = F.cross_entropy(output, targets)

-         loss.backward()
+         accelerator.backward(loss)

          optimizer.step()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As you can see in this example, by adding 5-lines to any standard PyTorch training script you can now run on any kind of single or distributed node setting (single CPU, single GPU, multi-GPUs and TPUs) as well as with or without mixed precision (fp8, fp16, bf16).&lt;/p&gt; 
&lt;p&gt;In particular, the same code can then be run without modification on your local machine for debugging or your training environment.&lt;/p&gt; 
&lt;p&gt;🤗 Accelerate even handles the device placement for you (which requires a few more changes to your code, but is safer in general), so you can even simplify your training loop further:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-diff&quot;&gt;  import torch
  import torch.nn.functional as F
  from datasets import load_dataset
+ from accelerate import Accelerator

- device = &#39;cpu&#39;
+ accelerator = Accelerator()

- model = torch.nn.Transformer().to(device)
+ model = torch.nn.Transformer()
  optimizer = torch.optim.Adam(model.parameters())

  dataset = load_dataset(&#39;my_dataset&#39;)
  data = torch.utils.data.DataLoader(dataset, shuffle=True)

+ model, optimizer, data = accelerator.prepare(model, optimizer, data)

  model.train()
  for epoch in range(10):
      for source, targets in data:
-         source = source.to(device)
-         targets = targets.to(device)

          optimizer.zero_grad()

          output = model(source)
          loss = F.cross_entropy(output, targets)

-         loss.backward()
+         accelerator.backward(loss)

          optimizer.step()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Want to learn more? Check out the &lt;a href=&quot;https://huggingface.co/docs/accelerate&quot;&gt;documentation&lt;/a&gt; or have a look at our &lt;a href=&quot;https://github.com/huggingface/accelerate/tree/main/examples&quot;&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Launching script&lt;/h2&gt; 
&lt;p&gt;🤗 Accelerate also provides an optional CLI tool that allows you to quickly configure and test your training environment before launching the scripts. No need to remember how to use &lt;code&gt;torch.distributed.run&lt;/code&gt; or to write a specific launcher for TPU training! On your machine(s) just run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;accelerate config
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and answer the questions asked. This will generate a config file that will be used automatically to properly set the default options when doing&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;accelerate launch my_script.py --args_to_my_script
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For instance, here is how you would run the GLUE example on the MRPC task (from the root of the repo):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;accelerate launch examples/nlp_example.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This CLI tool is &lt;strong&gt;optional&lt;/strong&gt;, and you can still use &lt;code&gt;python my_script.py&lt;/code&gt; or &lt;code&gt;python -m torchrun my_script.py&lt;/code&gt; at your convenience.&lt;/p&gt; 
&lt;p&gt;You can also directly pass in the arguments you would to &lt;code&gt;torchrun&lt;/code&gt; as arguments to &lt;code&gt;accelerate launch&lt;/code&gt; if you wish to not run&lt;code&gt; accelerate config&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, here is how to launch on two GPUs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;accelerate launch --multi_gpu --num_processes 2 examples/nlp_example.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To learn more, check the CLI documentation available &lt;a href=&quot;https://huggingface.co/docs/accelerate/package_reference/cli&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Or view the configuration zoo &lt;a href=&quot;https://github.com/huggingface/accelerate/raw/main/examples/config_yaml_templates/&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Launching multi-CPU run using MPI&lt;/h2&gt; 
&lt;p&gt;🤗 Here is another way to launch multi-CPU run using MPI. You can learn how to install Open MPI on &lt;a href=&quot;https://www.open-mpi.org/faq/?category=building#easy-build&quot;&gt;this page&lt;/a&gt;. You can use Intel MPI or MVAPICH as well. Once you have MPI setup on your cluster, just run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;accelerate config
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Answer the questions that are asked, selecting to run using multi-CPU, and answer &quot;yes&quot; when asked if you want accelerate to launch mpirun. Then, use &lt;code&gt;accelerate launch&lt;/code&gt; with your script like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;accelerate launch examples/nlp_example.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can use mpirun directly, without using the CLI like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mpirun -np 2 python examples/nlp_example.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Launching training using DeepSpeed&lt;/h2&gt; 
&lt;p&gt;🤗 Accelerate supports training on single/multiple GPUs using DeepSpeed. To use it, you don&#39;t need to change anything in your training code; you can set everything using just &lt;code&gt;accelerate config&lt;/code&gt;. However, if you desire to tweak your DeepSpeed related args from your Python script, we provide you the &lt;code&gt;DeepSpeedPlugin&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from accelerate import Accelerator, DeepSpeedPlugin

# deepspeed needs to know your gradient accumulation steps beforehand, so don&#39;t forget to pass it
# Remember you still need to do gradient accumulation by yourself, just like you would have done without deepspeed
deepspeed_plugin = DeepSpeedPlugin(zero_stage=2, gradient_accumulation_steps=2)
accelerator = Accelerator(mixed_precision=&#39;fp16&#39;, deepspeed_plugin=deepspeed_plugin)

# How to save your 🤗 Transformer?
accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(save_dir, save_function=accelerator.save, state_dict=accelerator.get_state_dict(model))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: DeepSpeed support is experimental for now. In case you get into some problem, please open an issue.&lt;/p&gt; 
&lt;h2&gt;Launching your training from a notebook&lt;/h2&gt; 
&lt;p&gt;🤗 Accelerate also provides a &lt;code&gt;notebook_launcher&lt;/code&gt; function you can use in a notebook to launch a distributed training. This is especially useful for Colab or Kaggle notebooks with a TPU backend. Just define your training loop in a &lt;code&gt;training_function&lt;/code&gt; then in your last cell, add:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from accelerate import notebook_launcher

notebook_launcher(training_function)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An example can be found in &lt;a href=&quot;https://github.com/huggingface/notebooks/raw/main/examples/accelerate_examples/simple_nlp_example.ipynb&quot;&gt;this notebook&lt;/a&gt;. &lt;a href=&quot;https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/accelerate_examples/simple_nlp_example.ipynb&quot;&gt;&lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Open In Colab&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why should I use 🤗 Accelerate?&lt;/h2&gt; 
&lt;p&gt;You should use 🤗 Accelerate when you want to easily run your training scripts in a distributed environment without having to renounce full control over your training loop. This is not a high-level framework above PyTorch, just a thin wrapper so you don&#39;t have to learn a new library. In fact, the whole API of 🤗 Accelerate is in one class, the &lt;code&gt;Accelerator&lt;/code&gt; object.&lt;/p&gt; 
&lt;h2&gt;Why shouldn&#39;t I use 🤗 Accelerate?&lt;/h2&gt; 
&lt;p&gt;You shouldn&#39;t use 🤗 Accelerate if you don&#39;t want to write a training loop yourself. There are plenty of high-level libraries above PyTorch that will offer you that, 🤗 Accelerate is not one of them.&lt;/p&gt; 
&lt;h2&gt;Frameworks using 🤗 Accelerate&lt;/h2&gt; 
&lt;p&gt;If you like the simplicity of 🤗 Accelerate but would prefer a higher-level abstraction around its capabilities, some frameworks and libraries that are built on top of 🤗 Accelerate are listed below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/open-mmlab/Amphion&quot;&gt;Amphion&lt;/a&gt; is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Scitator/animus&quot;&gt;Animus&lt;/a&gt; is a minimalistic framework to run machine learning experiments. Animus highlights common &quot;breakpoints&quot; in ML experiments and provides a unified interface for them within &lt;a href=&quot;https://github.com/Scitator/animus/raw/main/animus/core.py#L76&quot;&gt;IExperiment&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/catalyst-team/catalyst#getting-started&quot;&gt;Catalyst&lt;/a&gt; is a PyTorch framework for Deep Learning Research and Development. It focuses on reproducibility, rapid experimentation, and codebase reuse so you can create something new rather than write yet another train loop. Catalyst provides a &lt;a href=&quot;https://catalyst-team.github.io/catalyst/api/core.html#runner&quot;&gt;Runner&lt;/a&gt; to connect all parts of the experiment: hardware backend, data transformations, model training, and inference logic.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/fastai/fastai#installing&quot;&gt;fastai&lt;/a&gt; is a PyTorch framework for Deep Learning that simplifies training fast and accurate neural nets using modern best practices. fastai provides a &lt;a href=&quot;https://docs.fast.ai/learner.html#Learner&quot;&gt;Learner&lt;/a&gt; to handle the training, fine-tuning, and inference of deep learning algorithms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jina-ai/finetuner&quot;&gt;Finetuner&lt;/a&gt; is a service that enables models to create higher-quality embeddings for semantic search, visual similarity search, cross-modal text&amp;lt;-&amp;gt;image search, recommendation systems, clustering, duplication detection, anomaly detection, or other uses.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/invoke-ai/InvokeAI&quot;&gt;InvokeAI&lt;/a&gt; is a creative engine for Stable Diffusion models, offering industry-leading WebUI, terminal usage support, and serves as the foundation for many commercial products.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://kornia.readthedocs.io/en/latest/get-started/introduction.html&quot;&gt;Kornia&lt;/a&gt; is a differentiable library that allows classical computer vision to be integrated into deep learning models. Kornia provides a &lt;a href=&quot;https://kornia.readthedocs.io/en/latest/x.html#kornia.x.Trainer&quot;&gt;Trainer&lt;/a&gt; with the specific purpose to train and fine-tune the supported deep learning algorithms within the library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://projects.laion.ai/Open-Assistant/&quot;&gt;Open Assistant&lt;/a&gt; is a chat-based assistant that understands tasks, can interact with their party systems, and retrieve information dynamically to do so.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Chris-hughes10/pytorch-accelerated&quot;&gt;pytorch-accelerated&lt;/a&gt; is a lightweight training library, with a streamlined feature set centered around a general-purpose &lt;a href=&quot;https://pytorch-accelerated.readthedocs.io/en/latest/trainer.html&quot;&gt;Trainer&lt;/a&gt;, that places a huge emphasis on simplicity and transparency; enabling users to understand exactly what is going on under the hood, but without having to write and maintain the boilerplate themselves!&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/AUTOMATIC1111/stable-diffusion-webui&quot;&gt;Stable Diffusion web UI&lt;/a&gt; is an open-source browser-based easy-to-use interface based on the Gradio library for Stable Diffusion.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/lyhue1991/torchkeras&quot;&gt;torchkeras&lt;/a&gt; is a simple tool for training pytorch model just in a keras style, a dynamic and beautiful plot is provided in notebook to monitor your loss or metric.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/huggingface/transformers&quot;&gt;transformers&lt;/a&gt; as a tool for helping train state-of-the-art machine learning models in PyTorch, Tensorflow, and JAX. (Accelerate is the backend for the PyTorch side).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;This repository is tested on Python 3.8+ and PyTorch 1.10.0+&lt;/p&gt; 
&lt;p&gt;You should install 🤗 Accelerate in a &lt;a href=&quot;https://docs.python.org/3/library/venv.html&quot;&gt;virtual environment&lt;/a&gt;. If you&#39;re unfamiliar with Python virtual environments, check out the &lt;a href=&quot;https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/&quot;&gt;user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;First, create a virtual environment with the version of Python you&#39;re going to use and activate it.&lt;/p&gt; 
&lt;p&gt;Then, you will need to install PyTorch: refer to the &lt;a href=&quot;https://pytorch.org/get-started/locally/#start-locally&quot;&gt;official installation page&lt;/a&gt; regarding the specific install command for your platform. Then 🤗 Accelerate can be installed using pip as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install accelerate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported integrations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU only&lt;/li&gt; 
 &lt;li&gt;multi-CPU on one node (machine)&lt;/li&gt; 
 &lt;li&gt;multi-CPU on several nodes (machines)&lt;/li&gt; 
 &lt;li&gt;single GPU&lt;/li&gt; 
 &lt;li&gt;multi-GPU on one node (machine)&lt;/li&gt; 
 &lt;li&gt;multi-GPU on several nodes (machines)&lt;/li&gt; 
 &lt;li&gt;TPU&lt;/li&gt; 
 &lt;li&gt;FP16/BFloat16 mixed precision&lt;/li&gt; 
 &lt;li&gt;FP8 mixed precision with &lt;a href=&quot;https://github.com/NVIDIA/TransformerEngine&quot;&gt;Transformer Engine&lt;/a&gt; or &lt;a href=&quot;https://github.com/Azure/MS-AMP/&quot;&gt;MS-AMP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DeepSpeed support (Experimental)&lt;/li&gt; 
 &lt;li&gt;PyTorch Fully Sharded Data Parallel (FSDP) support (Experimental)&lt;/li&gt; 
 &lt;li&gt;Megatron-LM support (Experimental)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citing 🤗 Accelerate&lt;/h2&gt; 
&lt;p&gt;If you use 🤗 Accelerate in your publication, please cite it by using the following BibTeX entry.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@Misc{accelerate,
  title =        {Accelerate: Training and inference at scale made simple, efficient and adaptable.},
  author =       {Sylvain Gugger and Lysandre Debut and Thomas Wolf and Philipp Schmid and Zachary Mueller and Sourab Mangrulkar and Marc Sun and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/accelerate}},
  year =         {2022}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>agno-agi/agno</title>
      <link>https://github.com/agno-agi/agno</link>
      <description>&lt;p&gt;Agno is a lightweight library for building Multimodal Agents. Use it to give LLMs superpowers like memory, knowledge, tools and reasoning.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot; id=&quot;top&quot;&gt; 
 &lt;a href=&quot;https://docs.agno.com&quot;&gt; 
  &lt;picture&gt; 
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-dark.svg&quot;&gt; 
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-light.svg&quot;&gt; 
   &lt;img src=&quot;https://agno-public.s3.us-east-1.amazonaws.com/assets/logo-light.svg?sanitize=true&quot; alt=&quot;Agno&quot;&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://docs.agno.com&quot;&gt;📚 Documentation&lt;/a&gt; &amp;nbsp;|&amp;nbsp; 
 &lt;a href=&quot;https://docs.agno.com/examples/introduction&quot;&gt;💡 Examples&lt;/a&gt; &amp;nbsp;|&amp;nbsp; 
 &lt;a href=&quot;https://github.com/agno-agi/agno/stargazers&quot;&gt;🌟 Star Us&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://docs.agno.com&quot;&gt;Agno&lt;/a&gt; is a lightweight library for building Multimodal Agents. It exposes LLMs as a unified API and gives them superpowers like memory, knowledge, tools and reasoning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Build lightning-fast Agents that can generate text, image, audio and video.&lt;/li&gt; 
 &lt;li&gt;Add memory, knowledge, tools and reasoning as needed.&lt;/li&gt; 
 &lt;li&gt;Run anywhere, Agno is open-source.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here&#39;s an Agent that can search the web:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id=&quot;gpt-4o&quot;),
    tools=[DuckDuckGoTools()],
    markdown=True
)
agent.print_response(&quot;What&#39;s happening in New York?&quot;, stream=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🚨 Open Source AI Agent Hackathon! 🚨&lt;/h2&gt; 
&lt;p&gt;We&#39;re launching a Global AI Agent Hackathon in collaboration with AI Agent ecosystem partners — open to all developers, builders, and startups working on agents, RAG, tool use, or multi-agent systems.&lt;/p&gt; 
&lt;h3&gt;💰 Win up to $20,000 in cash by building Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🏅 10 winners: $300 each&lt;/li&gt; 
 &lt;li&gt;🥉 10 winners: $500 each&lt;/li&gt; 
 &lt;li&gt;🥈 5 winners: $1,000 each&lt;/li&gt; 
 &lt;li&gt;🥇 1 winner: $2,000&lt;/li&gt; 
 &lt;li&gt;🏆 GRAND PRIZE: $5,000 🏆&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🎁 Bonus&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Top 5 projects will be featured in the top trending &lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps&quot;&gt;Awesome LLM Apps&lt;/a&gt; repo.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤝 Partners&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.agno.com&quot;&gt;Agno&lt;/a&gt;, &lt;a href=&quot;https://www.theunwindai.com&quot;&gt;Unwind AI&lt;/a&gt; and more Agent ecosystem companies joining soon.&lt;/p&gt; 
&lt;h3&gt;📅 Here&#39;s the timeline:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;April 3rd - Final dates revealed&lt;/li&gt; 
 &lt;li&gt;April 10th - Prize and success criteria announced&lt;/li&gt; 
 &lt;li&gt;April 15th (tentative) - Hackathon starts&lt;/li&gt; 
 &lt;li&gt;May 30th (tentative) - Hackathon ends&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Join us for a month of building Agents!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Prizes will be distributed on an ongoing basis and continue till all prizes are awarded.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;⭐ Star this repo and follow along to stay updated.&lt;/p&gt; 
&lt;h3&gt;🤝 Want to join us as a partner or judge?&lt;/h3&gt; 
&lt;p&gt;If you&#39;re a company in the AI agent ecosystem or would like to judge the hackathon, reach out to &lt;a href=&quot;https://x.com/Saboo_Shubham_&quot;&gt;Shubham Saboo&lt;/a&gt; or &lt;a href=&quot;https://x.com/ashpreetbedi&quot;&gt;Ashpreet Bedi&lt;/a&gt; on X to partner. Let’s make this the biggest open source AI Agent hackathon.&lt;/p&gt; 
&lt;h2&gt;Key features&lt;/h2&gt; 
&lt;p&gt;Agno is simple, fast and model agnostic. Here are some key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightning Fast&lt;/strong&gt;: Agent creation is 10,000x faster than LangGraph (see &lt;a href=&quot;https://raw.githubusercontent.com/agno-agi/agno/main/#performance&quot;&gt;performance&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Agnostic&lt;/strong&gt;: Use any model, any provider, no lock-in.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi Modal&lt;/strong&gt;: Native support for text, image, audio and video.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi Agent&lt;/strong&gt;: Build teams of specialized agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory Management&lt;/strong&gt;: Store agent sessions and state in a database.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Knowledge Stores&lt;/strong&gt;: Use vector databases for RAG or dynamic few-shot learning.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Structured Outputs&lt;/strong&gt;: Make Agents respond in a structured format.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: Track agent sessions and performance in real-time on &lt;a href=&quot;https://app.agno.com&quot;&gt;agno.com&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start by &lt;a href=&quot;https://docs.agno.com/introduction/agents&quot;&gt;building your first Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href=&quot;https://docs.agno.com/examples/introduction&quot;&gt;examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href=&quot;https://docs.agno.com&quot;&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install -U agno
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What are Agents?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Agents&lt;/strong&gt; are intelligent programs that solve problems autonomously.&lt;/p&gt; 
&lt;p&gt;Agents have memory, domain knowledge and the ability to use tools (like searching the web, querying a database, making API calls). Unlike traditional programs that follow a predefined execution path, Agents dynamically adapt their approach based on the context and tool results.&lt;/p&gt; 
&lt;p&gt;Instead of a rigid binary definition, let&#39;s think of Agents in terms of agency and autonomy.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Level 0&lt;/strong&gt;: Agents with no tools (basic inference tasks).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Level 1&lt;/strong&gt;: Agents with tools for autonomous task execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Level 2&lt;/strong&gt;: Agents with knowledge, combining memory and reasoning.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Level 3&lt;/strong&gt;: Teams of specialized agents collaborating on complex workflows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Example - Basic Agent&lt;/h2&gt; 
&lt;p&gt;The simplest Agent is just an inference task, no tools, no memory, no knowledge.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id=&quot;gpt-4o&quot;),
    description=&quot;You are an enthusiastic news reporter with a flair for storytelling!&quot;,
    markdown=True
)
agent.print_response(&quot;Tell me about a breaking news story from New York.&quot;, stream=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the agent, install dependencies and export your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install agno openai

export OPENAI_API_KEY=sk-xxxx

python basic_agent.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/01_basic_agent.py&quot;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example - Agent with tools&lt;/h2&gt; 
&lt;p&gt;This basic agent will obviously make up a story, lets give it a tool to search the web.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id=&quot;gpt-4o&quot;),
    description=&quot;You are an enthusiastic news reporter with a flair for storytelling!&quot;,
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True
)
agent.print_response(&quot;Tell me about a breaking news story from New York.&quot;, stream=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies and run the Agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install duckduckgo-search

python agent_with_tools.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you should see a much more relevant result.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/02_agent_with_tools.py&quot;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example - Agent with knowledge&lt;/h2&gt; 
&lt;p&gt;Agents can store knowledge in a vector database and use it for RAG or dynamic few-shot learning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agno agents use Agentic RAG&lt;/strong&gt; by default, which means they will search their knowledge base for the specific information they need to achieve their task.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.embedder.openai import OpenAIEmbedder
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.lancedb import LanceDb, SearchType

agent = Agent(
    model=OpenAIChat(id=&quot;gpt-4o&quot;),
    description=&quot;You are a Thai cuisine expert!&quot;,
    instructions=[
        &quot;Search your knowledge base for Thai recipes.&quot;,
        &quot;If the question is better suited for the web, search the web to fill in gaps.&quot;,
        &quot;Prefer the information in your knowledge base over the web results.&quot;
    ],
    knowledge=PDFUrlKnowledgeBase(
        urls=[&quot;https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf&quot;],
        vector_db=LanceDb(
            uri=&quot;tmp/lancedb&quot;,
            table_name=&quot;recipes&quot;,
            search_type=SearchType.hybrid,
            embedder=OpenAIEmbedder(id=&quot;text-embedding-3-small&quot;),
        ),
    ),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True
)

# Comment out after the knowledge base is loaded
if agent.knowledge is not None:
    agent.knowledge.load()

agent.print_response(&quot;How do I make chicken and galangal in coconut milk soup&quot;, stream=True)
agent.print_response(&quot;What is the history of Thai curry?&quot;, stream=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies and run the Agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install lancedb tantivy pypdf duckduckgo-search

python agent_with_knowledge.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/03_agent_with_knowledge.py&quot;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example - Multi Agent Teams&lt;/h2&gt; 
&lt;p&gt;Agents work best when they have a singular purpose, a narrow scope and a small number of tools. When the number of tools grows beyond what the language model can handle or the tools belong to different categories, use a team of agents to spread the load.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools
from agno.team import Team

web_agent = Agent(
    name=&quot;Web Agent&quot;,
    role=&quot;Search the web for information&quot;,
    model=OpenAIChat(id=&quot;gpt-4o&quot;),
    tools=[DuckDuckGoTools()],
    instructions=&quot;Always include sources&quot;,
    show_tool_calls=True,
    markdown=True,
)

finance_agent = Agent(
    name=&quot;Finance Agent&quot;,
    role=&quot;Get financial data&quot;,
    model=OpenAIChat(id=&quot;gpt-4o&quot;),
    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],
    instructions=&quot;Use tables to display data&quot;,
    show_tool_calls=True,
    markdown=True,
)

agent_team = Team(
    mode=&quot;coordinate&quot;,
    members=[web_agent, finance_agent],
    model=OpenAIChat(id=&quot;gpt-4o&quot;),
    success_criteria=&quot;A comprehensive financial news report with clear sections and data-driven insights.&quot;,
    instructions=[&quot;Always include sources&quot;, &quot;Use tables to display data&quot;],
    show_tool_calls=True,
    markdown=True,
)

agent_team.print_response(&quot;What&#39;s the market outlook and financial performance of AI semiconductor companies?&quot;, stream=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies and run the Agent team:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;pip install duckduckgo-search yfinance

python agent_team.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/agno-agi/agno/main/cookbook/getting_started/05_agent_team.py&quot;&gt;View this example in the cookbook&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;At Agno, we&#39;re obsessed with performance. Why? because even simple AI workflows can spawn thousands of Agents to achieve their goals. Scale that to a modest number of users and performance becomes a bottleneck. Agno is designed to power high performance agentic systems:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Agent instantiation: ~2μs on average (~10,000x faster than LangGraph).&lt;/li&gt; 
 &lt;li&gt;Memory footprint: ~3.75Kib on average (~50x less memory than LangGraph).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tested on an Apple M4 Mackbook Pro.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;While an Agent&#39;s run-time is bottlenecked by inference, we must do everything possible to minimize execution time, reduce memory usage, and parallelize tool calls. These numbers may seem trivial at first, but our experience shows that they add up even at a reasonably small scale.&lt;/p&gt; 
&lt;h3&gt;Instantiation time&lt;/h3&gt; 
&lt;p&gt;Let&#39;s measure the time it takes for an Agent with 1 tool to start up. We&#39;ll run the evaluation 1000 times to get a baseline measurement.&lt;/p&gt; 
&lt;p&gt;You should run the evaluation yourself on your own machine, please, do not take these results at face value.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;# Setup virtual environment
./scripts/perf_setup.sh
source .venvs/perfenv/bin/activate
# OR Install dependencies manually
# pip install openai agno langgraph langchain_openai

# Agno
python evals/performance/instantiation_with_tool.py

# LangGraph
python evals/performance/other/langgraph_instantiation.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following evaluation is run on an Apple M4 Mackbook Pro. It also runs as a Github action on this repo.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;LangGraph is on the right, &lt;strong&gt;let&#39;s start it first and give it a head start&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Agno is on the left, notice how it finishes before LangGraph gets 1/2 way through the runtime measurement, and hasn&#39;t even started the memory measurement. That&#39;s how fast Agno is.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/ba466d45-75dd-45ac-917b-0a56c5742e23&quot;&gt;https://github.com/user-attachments/assets/ba466d45-75dd-45ac-917b-0a56c5742e23&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Dividing the average time of a Langgraph Agent by the average time of an Agno Agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;0.020526s / 0.000002s ~ 10,263
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this particular run, &lt;strong&gt;Agno Agents startup is roughly 10,000 times faster than Langgraph Agents&lt;/strong&gt;. The numbers continue to favor Agno as the number of tools grow, and we add memory and knowledge stores.&lt;/p&gt; 
&lt;h3&gt;Memory usage&lt;/h3&gt; 
&lt;p&gt;To measure memory usage, we use the &lt;code&gt;tracemalloc&lt;/code&gt; library. We first calculate a baseline memory usage by running an empty function, then run the Agent 1000x times and calculate the difference. This gives a (reasonably) isolated measurement of the memory usage of the Agent.&lt;/p&gt; 
&lt;p&gt;We recommend running the evaluation yourself on your own machine, and digging into the code to see how it works. If we&#39;ve made a mistake, please let us know.&lt;/p&gt; 
&lt;p&gt;Dividing the average memory usage of a Langgraph Agent by the average memory usage of an Agno Agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;0.137273/0.002528 ~ 54.3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Langgraph Agents use ~50x more memory than Agno Agents&lt;/strong&gt;. In our opinion, memory usage is a much more important metric than instantiation time. As we start running thousands of Agents in production, these numbers directly start affecting the cost of running the Agents.&lt;/p&gt; 
&lt;h3&gt;Conclusion&lt;/h3&gt; 
&lt;p&gt;Agno agents are designed for performance and while we do share some benchmarks against other frameworks, we should be mindful that accuracy and reliability are more important than speed.&lt;/p&gt; 
&lt;p&gt;We&#39;ll be publishing accuracy and reliability benchmarks running on Github actions in the coming weeks. Given that each framework is different and we won&#39;t be able to tune their performance like we do with Agno, for future benchmarks we&#39;ll only be comparing against ourselves.&lt;/p&gt; 
&lt;h2&gt;Cursor Setup&lt;/h2&gt; 
&lt;p&gt;When building Agno agents, using Agno documentation as a source in Cursor is a great way to speed up your development.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;In Cursor, go to the settings or preferences section.&lt;/li&gt; 
 &lt;li&gt;Find the section to manage documentation sources.&lt;/li&gt; 
 &lt;li&gt;Add &lt;code&gt;https://docs.agno.com&lt;/code&gt; to the list of documentation URLs.&lt;/li&gt; 
 &lt;li&gt;Save the changes.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Now, Cursor will have access to the Agno documentation.&lt;/p&gt; 
&lt;h2&gt;Documentation, Community &amp;amp; More examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docs: &lt;a href=&quot;https://docs.agno.com&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs.agno.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Getting Started Examples: &lt;a href=&quot;https://github.com/agno-agi/agno/tree/main/cookbook/getting_started&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Getting Started Cookbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All Examples: &lt;a href=&quot;https://github.com/agno-agi/agno/tree/main/cookbook&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Cookbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community forum: &lt;a href=&quot;https://community.agno.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;community.agno.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chat: &lt;a href=&quot;https://discord.gg/4MtYHHrgA8&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;We welcome contributions, read our &lt;a href=&quot;https://github.com/agno-agi/agno/raw/main/CONTRIBUTING.md&quot;&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;Agno logs which model an agent used so we can prioritize updates to the most popular providers. You can disable this by setting &lt;code&gt;AGNO_TELEMETRY=false&lt;/code&gt; in your environment.&lt;/p&gt; 
&lt;p align=&quot;left&quot;&gt; &lt;a href=&quot;https://raw.githubusercontent.com/agno-agi/agno/main/#top&quot;&gt;⬆️ Back to Top&lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>networkx/networkx</title>
      <link>https://github.com/networkx/networkx</link>
      <description>&lt;p&gt;Network Analysis in Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NetworkX&lt;/h1&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://github.com/networkx/networkx/workflows/test/badge.svg?branch=main&quot;&gt;https://github.com/networkx/networkx/workflows/test/badge.svg?branch=main&lt;/a&gt; :target: &lt;a href=&quot;https://github.com/networkx/networkx/actions?query=workflow%3Atest&quot;&gt;https://github.com/networkx/networkx/actions?query=workflow%3Atest&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://codecov.io/gh/networkx/networkx/branch/main/graph/badge.svg&quot;&gt;https://codecov.io/gh/networkx/networkx/branch/main/graph/badge.svg&lt;/a&gt;? :target: &lt;a href=&quot;https://app.codecov.io/gh/networkx/networkx/branch/main&quot;&gt;https://app.codecov.io/gh/networkx/networkx/branch/main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://img.shields.io/pypi/v/networkx.svg&quot;&gt;https://img.shields.io/pypi/v/networkx.svg&lt;/a&gt;? :target: &lt;a href=&quot;https://pypi.python.org/pypi/networkx&quot;&gt;https://pypi.python.org/pypi/networkx&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://img.shields.io/pypi/l/networkx.svg&quot;&gt;https://img.shields.io/pypi/l/networkx.svg&lt;/a&gt;? :target: &lt;a href=&quot;https://github.com/networkx/networkx/raw/main/LICENSE.txt&quot;&gt;https://github.com/networkx/networkx/blob/main/LICENSE.txt&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://img.shields.io/pypi/pyversions/networkx.svg&quot;&gt;https://img.shields.io/pypi/pyversions/networkx.svg&lt;/a&gt;? :target: &lt;a href=&quot;https://pypi.python.org/pypi/networkx&quot;&gt;https://pypi.python.org/pypi/networkx&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href=&quot;https://img.shields.io/github/labels/networkx/networkx/good%20first%20issue?color=green&amp;amp;label=contribute&quot;&gt;https://img.shields.io/github/labels/networkx/networkx/good%20first%20issue?color=green&amp;amp;label=contribute&lt;/a&gt; :target: &lt;a href=&quot;https://github.com/networkx/networkx/contribute&quot;&gt;https://github.com/networkx/networkx/contribute&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Website (including documentation):&lt;/strong&gt; &lt;a href=&quot;https://networkx.org&quot;&gt;https://networkx.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mailing list:&lt;/strong&gt; &lt;a href=&quot;https://groups.google.com/forum/#!forum/networkx-discuss&quot;&gt;https://groups.google.com/forum/#!forum/networkx-discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href=&quot;https://github.com/networkx/networkx&quot;&gt;https://github.com/networkx/networkx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug reports:&lt;/strong&gt; &lt;a href=&quot;https://github.com/networkx/networkx/issues&quot;&gt;https://github.com/networkx/networkx/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Report a security vulnerability:&lt;/strong&gt; &lt;a href=&quot;https://tidelift.com/security&quot;&gt;https://tidelift.com/security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tutorial:&lt;/strong&gt; &lt;a href=&quot;https://networkx.org/documentation/latest/tutorial.html&quot;&gt;https://networkx.org/documentation/latest/tutorial.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions:&lt;/strong&gt; &lt;a href=&quot;https://github.com/networkx/networkx/discussions&quot;&gt;https://github.com/networkx/networkx/discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord (Scientific Python) invite link:&lt;/strong&gt; &lt;a href=&quot;https://discord.com/invite/vur45CbwMz&quot;&gt;https://discord.com/invite/vur45CbwMz&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NetworkX meetings calendar (open to all):&lt;/strong&gt; &lt;a href=&quot;https://scientific-python.org/calendars/networkx.ics&quot;&gt;https://scientific-python.org/calendars/networkx.ics&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Simple example&lt;/h2&gt; 
&lt;p&gt;Find the shortest path between two nodes in an undirected graph:&lt;/p&gt; 
&lt;p&gt;.. code:: pycon&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import networkx as nx
&amp;gt;&amp;gt;&amp;gt; G = nx.Graph()
&amp;gt;&amp;gt;&amp;gt; G.add_edge(&quot;A&quot;, &quot;B&quot;, weight=4)
&amp;gt;&amp;gt;&amp;gt; G.add_edge(&quot;B&quot;, &quot;D&quot;, weight=2)
&amp;gt;&amp;gt;&amp;gt; G.add_edge(&quot;A&quot;, &quot;C&quot;, weight=3)
&amp;gt;&amp;gt;&amp;gt; G.add_edge(&quot;C&quot;, &quot;D&quot;, weight=4)
&amp;gt;&amp;gt;&amp;gt; nx.shortest_path(G, &quot;A&quot;, &quot;D&quot;, weight=&quot;weight&quot;)
[&#39;A&#39;, &#39;B&#39;, &#39;D&#39;]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;Install the latest released version of NetworkX:&lt;/p&gt; 
&lt;p&gt;.. code:: shell&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install networkx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install with all optional dependencies:&lt;/p&gt; 
&lt;p&gt;.. code:: shell&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install networkx[default]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional details, please see the &lt;code&gt;installation guide &amp;lt;https://networkx.org/documentation/stable/install.html&amp;gt;&lt;/code&gt;_.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;Please report any bugs that you find &lt;code&gt;here &amp;lt;https://github.com/networkx/networkx/issues&amp;gt;&lt;/code&gt;&lt;em&gt;. Or, even better, fork the repository on &lt;code&gt;GitHub &amp;lt;https://github.com/networkx/networkx&amp;gt;&lt;/code&gt;&lt;/em&gt; and create a pull request (PR). We welcome all changes, big or small, and we will help you make the PR if you are new to &lt;code&gt;git&lt;/code&gt; (just ask on the issue and/or see the &lt;code&gt;contributor guide &amp;lt;https://networkx.org/documentation/latest/developer/contribute.html&amp;gt;&lt;/code&gt;_).&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Released under the &lt;code&gt;3-Clause BSD license &amp;lt;https://github.com/networkx/networkx/blob/main/LICENSE.txt&amp;gt;&lt;/code&gt;_::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (C) 2004-2024 NetworkX Developers
Aric Hagberg &amp;lt;hagberg@lanl.gov&amp;gt;
Dan Schult &amp;lt;dschult@colgate.edu&amp;gt;
Pieter Swart &amp;lt;swart@lanl.gov&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>RasaHQ/rasa</title>
      <link>https://github.com/RasaHQ/rasa</link>
      <description>&lt;p&gt;💬 Open source machine learning framework to automate text- and voice-based conversations: NLU, dialogue management, connect to Slack, Facebook, and more - Create chatbots and voice assistants&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&quot;center&quot;&gt;Rasa Open Source&lt;/h1&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://forum.rasa.com/?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/forum-join%20discussions-brightgreen.svg?sanitize=true&quot; alt=&quot;Join the chat on Rasa Community Forum&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://badge.fury.io/py/rasa&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/rasa.svg?sanitize=true&quot; alt=&quot;PyPI version&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.python.org/pypi/rasa&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/rasa.svg?sanitize=true&quot; alt=&quot;Supported Python Versions&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RasaHQ/rasa/actions&quot;&gt;&lt;img src=&quot;https://github.com/RasaHQ/rasa/workflows/Continuous%20Integration/badge.svg?sanitize=true&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://codeclimate.com/github/RasaHQ/rasa/&quot;&gt;&lt;img src=&quot;https://api.codeclimate.com/v1/badges/756dc6fea1d5d3e127f7/test_coverage&quot; alt=&quot;Coverage Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://rasa.com/docs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-stable-brightgreen.svg?sanitize=true&quot; alt=&quot;Documentation Status&quot;&gt;&lt;/a&gt; &lt;img src=&quot;https://img.shields.io/netlify/d2e447e4-5a5e-4dc7-be5d-7c04ae7ff706?label=Documentation%20Build&quot; alt=&quot;Documentation Build&quot;&gt; &lt;a href=&quot;https://app.fossa.com/projects/custom%2B8141%2Fgit%40github.com%3ARasaHQ%2Frasa.git?ref=badge_shield&quot;&gt;&lt;img src=&quot;https://app.fossa.com/api/projects/custom%2B8141%2Fgit%40github.com%3ARasaHQ%2Frasa.git.svg?type=shield&quot; alt=&quot;FOSSA Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/orgs/RasaHQ/projects/23&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p&gt;💡 &lt;strong&gt;We&#39;re migrating issues to Jira&lt;/strong&gt; 💡&lt;/p&gt; 
&lt;p&gt;Starting January 2023, issues for Rasa Open Source are located in &lt;a href=&quot;https://rasa-open-source.atlassian.net/browse/OSS&quot;&gt;this Jira board&lt;/a&gt;. You can browse issues without being logged in; if you want to create issues, you&#39;ll need to create a Jira account.&lt;/p&gt; 
&lt;hr&gt; 
&lt;img align=&quot;right&quot; height=&quot;255&quot; src=&quot;https://www.rasa.com/assets/img/sara/sara-open-source-2.0.png&quot; alt=&quot;An image of Sara, the Rasa mascot bird, holding a flag that reads Open Source with one wing, and a wrench in the other&quot; title=&quot;Rasa Open Source&quot;&gt; 
&lt;p&gt;Rasa is an open source machine learning framework to automate text and voice-based conversations. With Rasa, you can build contextual assistants on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Facebook Messenger&lt;/li&gt; 
 &lt;li&gt;Slack&lt;/li&gt; 
 &lt;li&gt;Google Hangouts&lt;/li&gt; 
 &lt;li&gt;Webex Teams&lt;/li&gt; 
 &lt;li&gt;Microsoft Bot Framework&lt;/li&gt; 
 &lt;li&gt;Rocket.Chat&lt;/li&gt; 
 &lt;li&gt;Mattermost&lt;/li&gt; 
 &lt;li&gt;Telegram&lt;/li&gt; 
 &lt;li&gt;Twilio&lt;/li&gt; 
 &lt;li&gt;Your own custom conversational channels&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or voice assistants as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Alexa Skills&lt;/li&gt; 
 &lt;li&gt;Google Home Actions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Rasa helps you build contextual assistants capable of having layered conversations with lots of back-and-forth. In order for a human to have a meaningful exchange with a contextual assistant, the assistant needs to be able to use context to build on things that were previously discussed – Rasa enables you to build assistants that can do this in a scalable way.&lt;/p&gt; 
&lt;p&gt;There&#39;s a lot more background information in this &lt;a href=&quot;https://medium.com/rasa-blog/a-new-approach-to-conversational-software-2e64a5d05f2a&quot;&gt;blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;🤔 &lt;a href=&quot;https://rasa.community/&quot;&gt;Learn more about Rasa&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🤓 &lt;a href=&quot;https://rasa.com/docs/rasa/&quot;&gt;Read The Docs&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;😁 &lt;a href=&quot;https://rasa.com/docs/rasa/installation/environment-set-up&quot;&gt;Install Rasa&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🚀 &lt;a href=&quot;https://learning.rasa.com/&quot;&gt;Dive deeper in the learning center&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🤗 &lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/#how-to-contribute&quot;&gt;Contribute&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;❓ &lt;a href=&quot;https://rasa.com/support/&quot;&gt;Get enterprise-grade support&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;🏢 &lt;a href=&quot;https://rasa.com/product/rasa-platform/&quot;&gt;Explore the features of our commercial platform&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;📚 &lt;a href=&quot;https://scholar.google.com/scholar?oi=bibs&amp;amp;hl=en&amp;amp;authuser=1&amp;amp;cites=16243802403383697687,353275993797024115,14567308604105196228,9067977709825839723,9855847065463746011&amp;amp;as_sdt=5&quot;&gt;Learn more about research papers that leverage Rasa&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Where to get help&lt;/h2&gt; 
&lt;p&gt;There is extensive documentation in the &lt;a href=&quot;https://rasa.com/docs/rasa&quot;&gt;Rasa Docs&lt;/a&gt;. Make sure to select the correct version so you are looking at the docs for the version you installed.&lt;/p&gt; 
&lt;p&gt;Please use &lt;a href=&quot;https://forum.rasa.com&quot;&gt;Rasa Community Forum&lt;/a&gt; for quick answers to questions.&lt;/p&gt; 
&lt;h3&gt;README Contents:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/#how-to-contribute&quot;&gt;How to contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/#development-internals&quot;&gt;Development Internals&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/#releases&quot;&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How to contribute&lt;/h3&gt; 
&lt;p&gt;We are very happy to receive and merge your contributions into this repository!&lt;/p&gt; 
&lt;p&gt;To contribute via pull request, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create an issue describing the feature you want to work on (or have a look at the &lt;a href=&quot;https://github.com/orgs/RasaHQ/projects/23&quot;&gt;contributor board&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Write your code, tests and documentation, and format them with &lt;code&gt;black&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create a pull request describing your changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For more detailed instructions on how to contribute code, check out these &lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/CONTRIBUTING.md&quot;&gt;code contributor guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find more information about how to contribute to Rasa (in lots of different ways!) &lt;a href=&quot;http://rasa.community&quot;&gt;on our website.&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your pull request will be reviewed by a maintainer, who will get back to you about any necessary changes or questions. You will also be asked to sign a &lt;a href=&quot;https://cla-assistant.io/RasaHQ/rasa&quot;&gt;Contributor License Agreement&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development Internals&lt;/h2&gt; 
&lt;h3&gt;Installing Poetry&lt;/h3&gt; 
&lt;p&gt;Rasa uses Poetry for packaging and dependency management. If you want to build it from source, you have to install Poetry first. Please follow &lt;a href=&quot;https://python-poetry.org/docs/#installation&quot;&gt;the official guide&lt;/a&gt; to see all possible options.&lt;/p&gt; 
&lt;p&gt;To update an existing poetry version to the &lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/.github/poetry_version.txt&quot;&gt;version&lt;/a&gt;, currently used in rasa, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;    poetry self update &amp;lt;version&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Managing environments&lt;/h3&gt; 
&lt;p&gt;The official &lt;a href=&quot;https://python-poetry.org/docs/managing-environments/&quot;&gt;Poetry guide&lt;/a&gt; suggests to use &lt;a href=&quot;https://github.com/pyenv/pyenv&quot;&gt;pyenv&lt;/a&gt; or any other similar tool to easily switch between Python versions. This is how it can be done:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pyenv install 3.10.10
pyenv local 3.10.10  # Activate Python 3.10.10 for the current project
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: If you have trouble installing a specific version of python on your system it might be worth trying other supported versions.&lt;/p&gt; 
&lt;p&gt;By default, Poetry will try to use the currently activated Python version to create the virtual environment for the current project automatically. You can also create and activate a virtual environment manually — in this case, Poetry should pick it up and use it to install the dependencies. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can make sure that the environment is picked up by executing&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry env info
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Building from source&lt;/h3&gt; 
&lt;p&gt;To install dependencies and &lt;code&gt;rasa&lt;/code&gt; itself in editable mode execute&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Note for macOS users&lt;/em&gt;: under macOS Big Sur we&#39;ve seen some compiler issues for dependencies. Using &lt;code&gt;export SYSTEM_VERSION_COMPAT=1&lt;/code&gt; before the installation helped.&lt;/p&gt; 
&lt;h4&gt;Installing optional dependencies&lt;/h4&gt; 
&lt;p&gt;In order to install rasa&#39;s optional dependencies, you need to run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make install-full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Note for macOS users&lt;/em&gt;: The command &lt;code&gt;make install-full&lt;/code&gt; could result in a failure while installing &lt;code&gt;tokenizers&lt;/code&gt; (issue described in depth &lt;a href=&quot;https://github.com/huggingface/tokenizers/issues/1050&quot;&gt;here&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;In order to resolve it, you must follow these steps to install a Rust compiler:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;brew install rustup
rustup-init
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After initialising the Rust compiler, you should restart the console and check its installation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;rustc --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In case the PATH variable had not been automatically setup, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;export PATH=&quot;$HOME/.cargo/bin:$PATH&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running and changing the documentation&lt;/h3&gt; 
&lt;p&gt;First of all, install all the required dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make install install-docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After the installation has finished, you can run and view the documentation locally using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make livedocs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It should open a new tab with the local version of the docs in your browser; if not, visit &lt;a href=&quot;http://localhost:3000&quot;&gt;http://localhost:3000&lt;/a&gt; in your browser. You can now change the docs locally and the web page will automatically reload and apply your changes.&lt;/p&gt; 
&lt;h3&gt;Running the Tests&lt;/h3&gt; 
&lt;p&gt;In order to run the tests, make sure that you have the development requirements installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make prepare-tests-ubuntu # Only on Ubuntu and Debian based systems
make prepare-tests-macos  # Only on macOS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;They can also be run at multiple jobs to save some time:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;JOBS=[n] make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Where &lt;code&gt;[n]&lt;/code&gt; is the number of jobs desired. If omitted, &lt;code&gt;[n]&lt;/code&gt; will be automatically chosen by pytest.&lt;/p&gt; 
&lt;h3&gt;Running the Integration Tests&lt;/h3&gt; 
&lt;p&gt;In order to run the integration tests, make sure that you have the development requirements installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make prepare-tests-ubuntu # Only on Ubuntu and Debian based systems
make prepare-tests-macos  # Only on macOS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, you&#39;ll need to start services with the following command which uses &lt;a href=&quot;https://docs.docker.com/compose/install/&quot;&gt;Docker Compose&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make run-integration-containers
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, you can run the integration tests like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make test-integration
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Resolving merge conflicts&lt;/h3&gt; 
&lt;p&gt;Poetry doesn&#39;t include any solution that can help to resolve merge conflicts in the lock file &lt;code&gt;poetry.lock&lt;/code&gt; by default. However, there is a great tool called &lt;a href=&quot;https://poetry-merge-lock.readthedocs.io/en/latest/&quot;&gt;poetry-merge-lock&lt;/a&gt;. Here is how you can install it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install poetry-merge-lock
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Just execute this command to resolve merge conflicts in &lt;code&gt;poetry.lock&lt;/code&gt; automatically:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;poetry-merge-lock
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build a Docker image locally&lt;/h3&gt; 
&lt;p&gt;In order to build a Docker image on your local machine execute the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;make build-docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Docker image is available on your local machine as &lt;code&gt;rasa:localdev&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Code Style&lt;/h3&gt; 
&lt;p&gt;To ensure a standardized code style we use the formatter &lt;a href=&quot;https://github.com/ambv/black&quot;&gt;black&lt;/a&gt;. To ensure our type annotations are correct we use the type checker &lt;a href=&quot;https://github.com/google/pytype&quot;&gt;pytype&lt;/a&gt;. If your code is not formatted properly or doesn&#39;t type check, GitHub will fail to build.&lt;/p&gt; 
&lt;h4&gt;Formatting&lt;/h4&gt; 
&lt;p&gt;If you want to automatically format your code on every commit, you can use &lt;a href=&quot;https://pre-commit.com/&quot;&gt;pre-commit&lt;/a&gt;. Just install it via &lt;code&gt;pip install pre-commit&lt;/code&gt; and execute &lt;code&gt;pre-commit install&lt;/code&gt; in the root folder. This will add a hook to the repository, which reformats files on every commit.&lt;/p&gt; 
&lt;p&gt;If you want to set it up manually, install black via &lt;code&gt;poetry install&lt;/code&gt;. To reformat files execute&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make formatter
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Type Checking&lt;/h4&gt; 
&lt;p&gt;If you want to check types on the codebase, install &lt;code&gt;mypy&lt;/code&gt; using &lt;code&gt;poetry install&lt;/code&gt;. To check the types execute&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make types
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Deploying documentation updates&lt;/h3&gt; 
&lt;p&gt;We use &lt;code&gt;Docusaurus v2&lt;/code&gt; to build docs for tagged versions and for the &lt;code&gt;main&lt;/code&gt; branch. To run Docusaurus, install &lt;code&gt;Node.js 12.x&lt;/code&gt;. The static site that gets built is pushed to the &lt;code&gt;documentation&lt;/code&gt; branch of this repo.&lt;/p&gt; 
&lt;p&gt;We host the site on netlify. On &lt;code&gt;main&lt;/code&gt; branch builds (see &lt;code&gt;.github/workflows/documentation.yml&lt;/code&gt;), we push the built docs to the &lt;code&gt;documentation&lt;/code&gt; branch. Netlify automatically re-deploys the docs pages whenever there is a change to that branch.&lt;/p&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;Rasa has implemented robust policies governing version naming, as well as release pace for major, minor, and patch releases.&lt;/p&gt; 
&lt;p&gt;The values for a given version number (MAJOR.MINOR.PATCH) are incremented as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MAJOR version for incompatible API changes or other breaking changes.&lt;/li&gt; 
 &lt;li&gt;MINOR version for functionality added in a backward compatible manner.&lt;/li&gt; 
 &lt;li&gt;PATCH version for backward compatible bug fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following table describes the version types and their expected &lt;em&gt;release cadence&lt;/em&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Version Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Target Cadence&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Major&lt;/td&gt; 
   &lt;td&gt;For significant changes, or when any backward-incompatible changes are introduced to the API or data model.&lt;/td&gt; 
   &lt;td&gt;Every 1 - 2 yrs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Minor&lt;/td&gt; 
   &lt;td&gt;For when new backward-compatible functionality is introduced, a minor feature is introduced, or when a set of smaller features is rolled out.&lt;/td&gt; 
   &lt;td&gt;+/- Quarterly&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Patch&lt;/td&gt; 
   &lt;td&gt;For backward-compatible bug fixes that fix incorrect behavior.&lt;/td&gt; 
   &lt;td&gt;As needed&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;While this table represents our target release frequency, we reserve the right to modify it based on changing market conditions and technical requirements.&lt;/p&gt; 
&lt;h3&gt;Maintenance Policy&lt;/h3&gt; 
&lt;p&gt;Our End of Life policy defines how long a given release is considered supported, as well as how long a release is considered to be still in active development or maintenance.&lt;/p&gt; 
&lt;p&gt;The maintentance duration and end of life for every release are shown on our website as part of the &lt;a href=&quot;https://rasa.com/rasa-product-release-and-maintenance-policy/&quot;&gt;Product Release and Maintenance Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Cutting a Major / Minor release&lt;/h3&gt; 
&lt;h4&gt;A week before release day&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Make sure the &lt;a href=&quot;https://github.com/RasaHQ/rasa/milestones&quot;&gt;milestone&lt;/a&gt; already exists and is scheduled for the correct date.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Take a look at the issues &amp;amp; PRs that are in the milestone&lt;/strong&gt;: does it look about right for the release highlights we are planning to ship? Does it look like anything is missing? Don&#39;t worry about being aware of every PR that should be in, but it&#39;s useful to take a moment to evaluate what&#39;s assigned to the milestone.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Post a message on the engineering Slack channel&lt;/strong&gt;, letting the team know you&#39;ll be the one cutting the upcoming release, as well as: 
  &lt;ol&gt; 
   &lt;li&gt;Providing the link to the appropriate milestone&lt;/li&gt; 
   &lt;li&gt;Reminding everyone to go over their issues and PRs and please assign them to the milestone&lt;/li&gt; 
   &lt;li&gt;Reminding everyone of the scheduled date for the release&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;A day before release day&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Go over the milestone and evaluate the status of any PR merging that&#39;s happening. Follow up with people on their bugs and fixes.&lt;/strong&gt; If the release introduces new bugs or regressions that can&#39;t be fixed in time, we should discuss on Slack about this and take a decision on how to move forward. If the issue is not ready to be merged in time, we remove the issue / PR from the milestone and notify the PR owner and the product manager on Slack about it. The PR / issue owners are responsible for communicating any issues which might be release relevant. Postponing the release should be considered as an edge case scenario.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Release day! 🚀&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;At the start of the day, post a small message on slack announcing release day!&lt;/strong&gt; Communicate you&#39;ll be handling the release, and the time you&#39;re aiming to start releasing (again, no later than 4pm, as issues may arise and cause delays). This message should be posted early in the morning and before moving forward with any of the steps of the release, in order to give enough time to people to check their PRs and issues. That way they can plan any remaining work. A template of the slack message can be found &lt;a href=&quot;https://rasa-hq.slack.com/archives/C36SS4N8M/p1613032208137500?thread_ts=1612876410.068400&amp;amp;cid=C36SS4N8M&quot;&gt;here&lt;/a&gt;. The release time should be communicated transparently so that others can plan potentially necessary steps accordingly. If there are bigger changes this should be communicated.&lt;/li&gt; 
 &lt;li&gt;Make sure the milestone is empty (everything has been either merged or moved to the next milestone)&lt;/li&gt; 
 &lt;li&gt;Once everything in the milestone is taken care of, post a small message on Slack communicating you are about to start the release process (in case anything is missing).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;You may now do the release by following the instructions outlined in the &lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/#steps-to-release-a-new-version&quot;&gt;Rasa Open Source README&lt;/a&gt; !&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;After a Major release&lt;/h4&gt; 
&lt;p&gt;After a Major release has been completed, please follow &lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/docs/README.md#manual-steps-after-a-new-version&quot;&gt;these instructions to complete the documentation update&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Steps to release a new version&lt;/h3&gt; 
&lt;p&gt;Releasing a new version is quite simple, as the packages are build and distributed by GitHub Actions.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Release steps&lt;/em&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure all dependencies are up to date (&lt;strong&gt;especially Rasa SDK&lt;/strong&gt;) 
  &lt;ul&gt; 
   &lt;li&gt;For Rasa SDK, except in the case of a patch release, that means first creating a &lt;a href=&quot;https://github.com/RasaHQ/rasa-sdk#steps-to-release-a-new-version&quot;&gt;new Rasa SDK release&lt;/a&gt; (make sure the version numbers between the new Rasa and Rasa SDK releases match)&lt;/li&gt; 
   &lt;li&gt;Once the tag with the new Rasa SDK release is pushed and the package appears on &lt;a href=&quot;https://pypi.org/project/rasa-sdk/&quot;&gt;pypi&lt;/a&gt;, the dependency in the rasa repository can be resolved (see below).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If this is a minor / major release: Make sure all fixes from currently supported minor versions have been merged from their respective release branches (e.g. 3.3.x) back into main.&lt;/li&gt; 
 &lt;li&gt;In case of a minor release, create a new branch that corresponds to the new release, e.g. &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt; git checkout -b 1.2.x
 git push origin 1.2.x
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Switch to the branch you want to cut the release from (&lt;code&gt;main&lt;/code&gt; in case of a major, the &lt;code&gt;&amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;.x&lt;/code&gt; branch for minors and patches) 
  &lt;ul&gt; 
   &lt;li&gt;Update the &lt;code&gt;rasa-sdk&lt;/code&gt; entry in &lt;code&gt;pyproject.toml&lt;/code&gt; with the new release version and run &lt;code&gt;poetry update&lt;/code&gt;. This creates a new &lt;code&gt;poetry.lock&lt;/code&gt; file with all dependencies resolved.&lt;/li&gt; 
   &lt;li&gt;Commit the changes with &lt;code&gt;git commit -am &quot;bump rasa-sdk dependency&quot;&lt;/code&gt; but do not push them. They will be automatically picked up by the following step.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If this is a major release, update the list of actively maintained versions &lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/#actively-maintained-versions&quot;&gt;in the README&lt;/a&gt; and in &lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/docs/docs/actively-maintained-versions.mdx&quot;&gt;the docs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;make release&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create a PR against the release branch (e.g. &lt;code&gt;1.2.x&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Once your PR is merged, tag a new release (this SHOULD always happen on the release branch), e.g. using &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git checkout 1.2.x
git pull origin 1.2.x
git tag 1.2.0 -m &quot;next release&quot;
git push origin 1.2.0 --tags
&lt;/code&gt;&lt;/pre&gt; GitHub will build this tag and publish the build artifacts.&lt;/li&gt; 
 &lt;li&gt;After all the steps are completed and if everything goes well then we should see a message automatically posted in the company&#39;s Slack (&lt;code&gt;product&lt;/code&gt; channel) like this &lt;a href=&quot;https://rasa-hq.slack.com/archives/C7B08Q5FX/p1614354499046600&quot;&gt;one&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;If no message appears in the channel then you can do the following checks: 
  &lt;ul&gt; 
   &lt;li&gt;Check the workflows in &lt;a href=&quot;https://github.com/RasaHQ/rasa/actions&quot;&gt;Github Actions&lt;/a&gt; and make sure that the merged PR of the current release is completed successfully. To easily find your PR you can use the filters &lt;code&gt;event: push&lt;/code&gt; and &lt;code&gt;branch: &amp;lt;version number&amp;gt;&lt;/code&gt; (example on release 2.4 you can see &lt;a href=&quot;https://github.com/RasaHQ/rasa/actions/runs/643344876&quot;&gt;here&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;If the workflow is not completed, then try to re run the workflow in case that solves the problem&lt;/li&gt; 
   &lt;li&gt;If the problem persists, check also the log files and try to find the root cause of the issue&lt;/li&gt; 
   &lt;li&gt;If you still cannot resolve the error, contact the infrastructure team by providing any helpful information from your investigation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;After the message is posted correctly in the &lt;code&gt;product&lt;/code&gt; channel, check also in the &lt;code&gt;product-engineering-alerts&lt;/code&gt; channel if there are any alerts related to the Rasa Open Source release like this &lt;a href=&quot;https://rasa-hq.slack.com/archives/C01585AN2NP/p1615486087001000&quot;&gt;one&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Cutting a Patch release&lt;/h3&gt; 
&lt;p&gt;Patch releases are simpler to cut, since they are meant to contain only bugfixes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The only things you need to do to cut a patch release are:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Notify the engineering team on Slack that you are planning to cut a patch, in case someone has an important fix to add.&lt;/li&gt; 
 &lt;li&gt;Make sure the bugfix(es) are in the release branch you will use (p.e if you are cutting a &lt;code&gt;2.0.4&lt;/code&gt; patch, you will need your fixes to be on the &lt;code&gt;2.0.x&lt;/code&gt; release branch). All patch releases must come from a &lt;code&gt;.x&lt;/code&gt; branch!&lt;/li&gt; 
 &lt;li&gt;Once you&#39;re ready to release the Rasa Open Source patch, checkout the branch, run &lt;code&gt;make release&lt;/code&gt; and follow the steps + get the PR merged.&lt;/li&gt; 
 &lt;li&gt;Once the PR is in, pull the &lt;code&gt;.x&lt;/code&gt; branch again and push the tag!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Additional Release Tasks&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Note: This is only required if the released version is the highest version available. For instance, perform the following steps when version &amp;gt; &lt;a href=&quot;https://github.com/RasaHQ/rasa/raw/main/rasa/version.py&quot;&gt;version&lt;/a&gt; on main.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In order to check compatibility between the new released Rasa version to the latest version of Rasa X/Enterprise, we perform the following steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Following a new Rasa release, an automated pull request is created in &lt;a href=&quot;https://github.com/RasaHQ/rasa-x-demo/pulls&quot;&gt;Rasa-X-Demo&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Once the above PR is merged, follow instructions &lt;a href=&quot;https://github.com/RasaHQ/rasa-x-demo/raw/master/.github/VERSION_BUMPER_PR_COMMENT.md&quot;&gt;here&lt;/a&gt;, to release a version.&lt;/li&gt; 
 &lt;li&gt;Update the new version in the Rasa X/Enterprise &lt;a href=&quot;https://github.com/RasaHQ/rasa-x/raw/main/.env&quot;&gt;env file&lt;/a&gt;. The &lt;a href=&quot;https://github.com/RasaHQ/rasa-x-demo&quot;&gt;Rasa-X-Demo&lt;/a&gt; project uses the new updated Rasa version to train and test a model which in turn is used by our CI to run tests in the Rasa X/Enterprise repository, thus validating compatibility between Rasa and Rasa X/Enterprise.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Actively maintained versions&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href=&quot;https://rasa.com/rasa-product-release-and-maintenance-policy/&quot;&gt;Rasa Product Release and Maintenance Policy&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0. Copyright 2022 Rasa Technologies GmbH. &lt;a href=&quot;https://raw.githubusercontent.com/RasaHQ/rasa/3.6.x/LICENSE.txt&quot;&gt;Copy of the license&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;A list of the Licenses of the dependencies of the project can be found at the bottom of the &lt;a href=&quot;https://libraries.io/github/RasaHQ/rasa&quot;&gt;Libraries Summary&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Agenta-AI/agenta</title>
      <link>https://github.com/Agenta-AI/agenta</link>
      <description>&lt;p&gt;The open-source LLMOps platform: prompt playground, prompt management, LLM evaluation, and LLM Observability all in one place.&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt; 
  &lt;picture&gt; 
   &lt;source width=&quot;275&quot; media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/Agenta-AI/agenta/assets/4510758/cdddf5ad-2352-4920-b1d9-ae7f8d9d7735&quot;&gt; 
   &lt;source width=&quot;275&quot; media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/Agenta-AI/agenta/assets/4510758/ab75cbac-b807-496f-aab3-57463a33f726&quot;&gt; 
   &lt;img alt=&quot;Shows the logo of agenta&quot; src=&quot;https://github.com/Agenta-AI/agenta/assets/4510758/68e055d4-d7b8-4943-992f-761558c64253&quot;&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://docs.agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;Documentation&lt;/a&gt; | &lt;a href=&quot;https://agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;Website&lt;/a&gt; | &lt;a href=&quot;https://join.slack.com/t/agenta-hq/shared_invite/zt-2yewk6o2b-DmhyA4h_lkKwecDtIsj1AQ&quot;&gt;Slack&lt;/a&gt; &lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;strong&gt; &lt;h1&gt; The Open source LLMOps Platform &lt;/h1&gt;&lt;/strong&gt; Prompt playground, prompt management, evaluation, and observability 
&lt;/div&gt; 
&lt;br&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&quot; alt=&quot;MIT license.&quot;&gt; &lt;a href=&quot;https://docs.agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/Doc-online-green&quot; alt=&quot;Doc&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/raw/main/CONTRIBUTING.md&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/PRs-Welcome-brightgreen&quot; alt=&quot;PRs welcome&quot;&gt; &lt;/a&gt; &lt;img src=&quot;https://img.shields.io/github/contributors/Agenta-AI/agenta&quot; alt=&quot;Contributors&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/last-commit/Agenta-AI/agenta&quot; alt=&quot;Last Commit&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/commit-activity/m/agenta-ai/agenta&quot; alt=&quot;Commits per month&quot;&gt; &lt;a href=&quot;https://pypi.org/project/agenta/&quot;&gt; &lt;img src=&quot;https://img.shields.io/pypi/dm/agenta&quot; alt=&quot;PyPI - Downloads&quot;&gt; &lt;/a&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://join.slack.com/t/agenta-hq/shared_invite/zt-2yewk6o2b-DmhyA4h_lkKwecDtIsj1AQ&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/JOIN%20US%20ON%20SLACK-4A154B?style=for-the-badge&amp;amp;logo=slack&amp;amp;logoColor=white&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://www.linkedin.com/company/agenta-ai/&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://twitter.com/agenta_ai&quot;&gt; &lt;img src=&quot;https://img.shields.io/twitter/follow/agenta_ai?style=social&quot; height=&quot;28&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt; 
  &lt;picture&gt; 
   &lt;source width=&quot;275&quot; media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/b8912ecb-c7a0-47bd-8507-29b12382fef6&quot;&gt; 
   &lt;source width=&quot;275&quot; media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/f133dd08-04a3-4b20-b047-22f8f841cfbb&quot;&gt; 
   &lt;img alt=&quot;Try Agenta Live Demo&quot; src=&quot;https://github.com/Agenta-AI/agenta/assets/4510758/68e055d4-d7b8-4943-992f-761558c64253&quot;&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt; 
  &lt;picture&gt; 
   &lt;img width=&quot;800&quot; alt=&quot;Screenshot Agenta&quot; src=&quot;https://github.com/user-attachments/assets/32e95ddb-e001-4462-b92e-72bf4cc78597&quot;&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;  
&lt;br&gt; 
&lt;br&gt; 
&lt;hr&gt; 
&lt;h3 align=&quot;center&quot;&gt; &lt;a href=&quot;https://docs.agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; • &lt;a href=&quot;https://docs.agenta.ai/changelog/main?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;&lt;b&gt;Changelog&lt;/b&gt;&lt;/a&gt; • &lt;a href=&quot;https://agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; • &lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;&lt;b&gt;Agenta Cloud&lt;/b&gt;&lt;/a&gt; &lt;/h3&gt; 
&lt;hr&gt; 
&lt;h2&gt;What is Agenta?&lt;/h2&gt; 
&lt;p&gt;Agenta is a platform for building production-grade LLM applications. It helps &lt;strong&gt;engineering and product teams&lt;/strong&gt; create reliable LLM apps faster.&lt;/p&gt; 
&lt;p&gt;Agenta provides end-to-end tools for the entire LLMOps workflow: building (&lt;strong&gt;LLM playground&lt;/strong&gt;, &lt;strong&gt;evaluation&lt;/strong&gt;), deploying (&lt;strong&gt;prompt and configuration management&lt;/strong&gt;), and monitoring (&lt;strong&gt;LLM observability and tracing&lt;/strong&gt;).&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt Playground&lt;/strong&gt;: Experiment, iterate on prompts, and compare outputs from over 50 LLM models side by side (&lt;a href=&quot;https://docs.agenta.ai/prompt-management/using-the-playground?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Workflows&lt;/strong&gt;: Build a playground for any custom LLM workflow, such as RAG or agents. Enable all the team to easily iterate on its parameters and evaluate it from the web UI.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM evaluation&lt;/strong&gt;: Run evaluation suite from the webUI using predefined evaluators like LLM-as-a-judge, RAG evaluators, or custom code evaluators. (&lt;a href=&quot;https://docs.agenta.ai/evaluation/overview?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human evaluation&lt;/strong&gt;: Collaborate with subject matter experts for human annotation evaluation, including A/B testing and annotating golden test sets.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt Management&lt;/strong&gt;: Version your prompts and manage them across different environments (&lt;a href=&quot;https://docs.agenta.ai/prompt-management/overview?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;docs&lt;/a&gt;, &lt;a href=&quot;https://docs.agenta.ai/prompt-management/quick-start?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;quick start&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Tracing&lt;/strong&gt;: Observe and debug your apps with integrations to most providers and frameworks (&lt;a href=&quot;https://docs.agenta.ai/observability/overview?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;docs&lt;/a&gt;, &lt;a href=&quot;https://docs.agenta.ai/observability/quickstart?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;quick start&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Monitoring&lt;/strong&gt;: Track cost and latency and compare different deployments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Agenta Cloud:&lt;/h3&gt; 
&lt;p&gt;The easiest way to get started is through Agenta Cloud. It is free to signup, and comes with a generous free-tier.&lt;/p&gt; 
&lt;a href=&quot;https://cloud.agenta.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt; 
 &lt;picture&gt; 
  &lt;source width=&quot;160&quot; media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/759422d8-01bc-4503-bf3c-b5871c99359a&quot;&gt; 
  &lt;source width=&quot;160&quot; media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/ffa9af5f-0981-4e95-9272-cb35eedb6780&quot;&gt; 
  &lt;img alt=&quot;Get Started with Agenta Cloud&quot; src=&quot;https://github.com/user-attachments/assets/ffa9af5f-0981-4e95-9272-cb35eedb6780&quot;&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h3&gt;Self-hosting Agenta&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone Agenta:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/Agenta-AI/agenta &amp;amp;&amp;amp; cd agenta
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt; &lt;p&gt;Edit &lt;code&gt;hosting/docker-compose/oss/.env.oss.gh&lt;/code&gt; and add your LLM provider API keys.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start Agenta services:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker compose -f hosting/docker-compose/oss/docker-compose.gh.yml --env-file hosting/docker-compose/oss/.env.oss.gh --profile with-web up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start=&quot;4&quot;&gt; 
 &lt;li&gt;Access Agenta at &lt;code&gt;http://localhost&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For deploying on a remote host, or using different ports refers to our &lt;a href=&quot;https://docs.agenta.ai/self-host/host-locally?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;self-hosting&lt;/a&gt; and &lt;a href=&quot;https://docs.agenta.ai/self-host/host-remotely?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;remote deployment documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Disabling Anonymized Tracking&lt;/h2&gt; 
&lt;p&gt;By default, Agenta automatically reports anonymized basic usage statistics. This helps us understand how Agenta is used and track its overall usage and growth. This data does not include any sensitive information. To disable anonymized telemetry set &lt;code&gt;TELEMETRY_ENABLED&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt; in your &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We warmly welcome contributions to Agenta. Feel free to submit issues, fork the repository, and send pull requests.&lt;/p&gt; 
&lt;p&gt;We are usually hanging in our Slack. Feel free to &lt;a href=&quot;https://join.slack.com/t/agenta-hq/shared_invite/zt-2yewk6o2b-DmhyA4h_lkKwecDtIsj1AQ&quot;&gt;join our Slack and ask us anything&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out our &lt;a href=&quot;https://docs.agenta.ai/misc/contributing/getting-started?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme&quot;&gt;Contributing Guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Contributors ✨&lt;/h3&gt; 
&lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#contributors-&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/all_contributors-49-orange.svg?style=flat-square&quot; alt=&quot;All Contributors&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt; 
&lt;p&gt;Thanks goes to these wonderful people (&lt;a href=&quot;https://allcontributors.org/docs/en/emoji-key&quot;&gt;emoji key&lt;/a&gt;):&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/SamMethnani&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/57623556?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Sameh Methnani&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Sameh Methnani&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=SamMethnani&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=SamMethnani&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/suadsuljovic&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/8658374?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Suad Suljovic&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Suad Suljovic&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=suadsuljovic&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#design-suadsuljovic&quot; title=&quot;Design&quot;&gt;🎨&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#mentoring-suadsuljovic&quot; title=&quot;Mentoring&quot;&gt;🧑‍🏫&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/pulls?q=is%3Apr+reviewed-by%3Asuadsuljovic&quot; title=&quot;Reviewed Pull Requests&quot;&gt;👀&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/burtenshaw&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/19620375?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;burtenshaw&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;burtenshaw&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=burtenshaw&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://abram.tech&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/55067204?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Abram&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Abram&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=aybruhm&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=aybruhm&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://israelabebe.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/7479824?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Israel Abebe&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Israel Abebe&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Avernu&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#design-vernu&quot; title=&quot;Design&quot;&gt;🎨&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=vernu&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/SohaibAnwaar&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/29427728?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Master X&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Master X&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=SohaibAnwaar&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://main-portfolio-26wv6oglp-witehound.vercel.app/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/26417477?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;corinthian&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;corinthian&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=witehound&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#design-witehound&quot; title=&quot;Design&quot;&gt;🎨&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Pajko97&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/25198892?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Pavle Janjusevic&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Pavle Janjusevic&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#infra-Pajko97&quot; title=&quot;Infrastructure (Hosting, Build-Tools, etc)&quot;&gt;🚇&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://kaosiso-ezealigo.netlify.app&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/99529776?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kaosi Ezealigo&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Kaosi Ezealigo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Abekossy&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=bekossy&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/albnunes&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/46302915?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Alberto Nunes&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Alberto Nunes&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Aalbnunes&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.linkedin.com/in/mohammed-maaz-6290b0116/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/17180132?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Maaz Bin Khawar&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Maaz Bin Khawar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=MohammedMaaz&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/pulls?q=is%3Apr+reviewed-by%3AMohammedMaaz&quot; title=&quot;Reviewed Pull Requests&quot;&gt;👀&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#mentoring-MohammedMaaz&quot; title=&quot;Mentoring&quot;&gt;🧑‍🏫&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/devgenix&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/56418363?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Nehemiah Onyekachukwu Emmanuel&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Nehemiah Onyekachukwu Emmanuel&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=devgenix&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#example-devgenix&quot; title=&quot;Examples&quot;&gt;💡&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=devgenix&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/philipokiokio&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/55271518?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Philip Okiokio&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Philip Okiokio&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=philipokiokio&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://sweetdevil144.github.io/My-Website/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/117591942?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Abhinav Pandey&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Abhinav Pandey&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=Sweetdevil144&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/RamchandraWarang9822&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/92023869?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ramchandra Warang&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Ramchandra Warang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=RamchandraWarang9822&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3ARamchandraWarang9822&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/lazyfuhrer&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/64888892?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Biswarghya Biswas&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Biswarghya Biswas&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=lazyfuhrer&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/okieLoki&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/96105929?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Uddeepta Raaj Kashyap&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Uddeepta Raaj Kashyap&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=okieLoki&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://www.linkedin.com/in/nayeem-abdullah-317098141&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/32274108?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Nayeem Abdullah&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Nayeem Abdullah&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=nayeem01&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/kangsuhyun-yanolja&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/124246127?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kang Suhyun&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Kang Suhyun&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=kangsuhyun-yanolja&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/yeokyeong-yanolja&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/128676129?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Yoon&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Yoon&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=yeokyeong-yanolja&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://mrkirthi24.netlify.app/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/53830546?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Kirthi Bagrecha Jain&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Kirthi Bagrecha Jain&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=mrkirthi-24&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/navdeep1840&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/80774259?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Navdeep&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Navdeep&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=navdeep1840&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://www.linkedin.com/in/rhythm-sharma-708a421a8/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/64489317?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Rhythm Sharma&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Rhythm Sharma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=Rhythm-08&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://osinachi.me&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/40396070?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Osinachi Chukwujama &quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Osinachi Chukwujama &lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=vicradon&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://liduos.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47264881?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;莫尔索&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;莫尔索&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=morsoli&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://luccithedev.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/22600781?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Agunbiade Adedeji&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Agunbiade Adedeji&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=dejongbaba&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://techemmy.github.io/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/43725109?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Emmanuel Oloyede&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Emmanuel Oloyede&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=techemmy&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=techemmy&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Dhaneshwarguiyan&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/116065351?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Dhaneshwarguiyan&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Dhaneshwarguiyan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=Dhaneshwarguiyan&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/PentesterPriyanshu&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/98478305?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Priyanshu Prajapati&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Priyanshu Prajapati&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=PentesterPriyanshu&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://venkataravitejagullapudi.github.io/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/70102577?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Raviteja&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Raviteja&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=VenkataRavitejaGullapudi&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/ArijitCloud&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/81144422?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Arijit&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Arijit&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=ArijitCloud&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Yachika9925&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/147185379?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Yachika9925&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Yachika9925&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=Yachika9925&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Dhoni77&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/53973174?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Aldrin&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Aldrin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=Dhoni77&quot; title=&quot;Tests&quot;&gt;⚠️&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/seungduk-yanolja&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/115020208?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;seungduk.kim.2304&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;seungduk.kim.2304&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=seungduk-yanolja&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://dandrei.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/59015981?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Andrei Dragomir&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Andrei Dragomir&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=andreiwebdev&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://diegolikescode.me/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/57499868?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;diego&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;diego&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=diegolikescode&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/brockWith&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/105627491?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;brockWith&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;brockWith&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=brockWith&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://denniszelada.wordpress.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/219311?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Dennis Zelada&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Dennis Zelada&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=denniszelada&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/romainrbr&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10381609?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Romain Brucker&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Romain Brucker&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=romainrbr&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://heonheo.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/76820291?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Heon Heo&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Heon Heo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=HeonHeo23&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Drewski2222&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/39228951?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Drew Reisner&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Drew Reisner&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=Drewski2222&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://speakerdeck.com/eltociear&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/22633385?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ikko Eltociear Ashimine&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Ikko Eltociear Ashimine&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=eltociear&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/vishalvanpariya&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/27823328?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Vishal Vanpariya&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Vishal Vanpariya&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=vishalvanpariya&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/youcefs21&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/34604972?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Youcef Boumar&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Youcef Boumar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=youcefs21&quot; title=&quot;Documentation&quot;&gt;📖&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/LucasTrg&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47852577?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;LucasTrg&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;LucasTrg&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=LucasTrg&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3ALucasTrg&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://ashrafchowdury.me&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/87828904?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Ashraf Chowdury&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Ashraf Chowdury&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Aashrafchowdury&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=ashrafchowdury&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/jp-agenta&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/174311389?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;jp-agenta&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;jp-agenta&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/commits?author=jp-agenta&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt; &lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Ajp-agenta&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://mrunhap.github.io&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/24653356?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Mr Unhappy&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Mr Unhappy&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Amrunhap&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/Agenta-AI/agenta/main/#infra-mrunhap&quot; title=&quot;Infrastructure (Hosting, Build-Tools, etc)&quot;&gt;🚇&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/morenobonaventura&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/2118854?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Moreno Bonaventura&quot;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Moreno Bonaventura&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/Agenta-AI/agenta/issues?q=author%3Amorenobonaventura&quot; title=&quot;Bug reports&quot;&gt;🐛&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;p&gt;This project follows the &lt;a href=&quot;https://github.com/all-contributors/all-contributors&quot;&gt;all-contributors&lt;/a&gt; specification. Contributions of any kind are welcome!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Akkudoktor-EOS/EOS</title>
      <link>https://github.com/Akkudoktor-EOS/EOS</link>
      <description>&lt;p&gt;This repository features an Energy Optimization System (EOS) that optimizes energy distribution, usage for batteries, heat pumps&amp; household devices. It includes predictive models for electricity prices (planned), load forecasting&amp; dynamic optimization to maximize energy efficiency &amp; minimize costs. Founder Dr. Andreas Schmitz (YouTube @akkudoktor)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Energy System Simulation and Optimization&lt;/h1&gt; 
&lt;p&gt;This project provides a comprehensive solution for simulating and optimizing an energy system based on renewable energy sources. With a focus on photovoltaic (PV) systems, battery storage (batteries), load management (consumer requirements), heat pumps, electric vehicles, and consideration of electricity price data, this system enables forecasting and optimization of energy flow and costs over a specified period.&lt;/p&gt; 
&lt;p&gt;Documentation can be found at &lt;a href=&quot;https://akkudoktor-eos.readthedocs.io/en/latest/&quot;&gt;Akkudoktor-EOS&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Involved&lt;/h2&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/Akkudoktor-EOS/EOS/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;System requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python &amp;gt;= 3.11, &amp;lt; 3.13&lt;/li&gt; 
 &lt;li&gt;Architecture: amd64, aarch64 (armv8)&lt;/li&gt; 
 &lt;li&gt;OS: Linux, Windows, macOS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: For Python 3.13 some dependencies (e.g. &lt;a href=&quot;https://github.com/python-pendulum/Pendulum&quot;&gt;Pendulum&lt;/a&gt;) are not yet available on &lt;a href=&quot;https://pypi.org&quot;&gt;https://pypi.org&lt;/a&gt; and have to be manually compiled (a recent &lt;a href=&quot;https://www.rust-lang.org/tools/install&quot;&gt;Rust&lt;/a&gt; installation is required).&lt;/p&gt; 
&lt;p&gt;Other architectures (e.g. armv6, armv7) are unsupported for now, because a multitude of dependencies are not available on &lt;a href=&quot;https://piwheels.org&quot;&gt;https://piwheels.org&lt;/a&gt; and have to be built manually (a recent Rust installation and &lt;a href=&quot;https://gcc.gnu.org/&quot;&gt;GCC&lt;/a&gt; are required, Python 3.11 is recommended).&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Docker images (amd64/aarch64) can be found at &lt;a href=&quot;https://hub.docker.com/r/akkudoktor/eos&quot;&gt;akkudoktor/eos&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Following sections describe how to locally start the EOS server on &lt;code&gt;http://localhost:8503&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Run from source&lt;/h3&gt; 
&lt;p&gt;Install dependencies in virtual environment:&lt;/p&gt; 
&lt;p&gt;Linux:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python -m venv .venv
.venv/bin/pip install -r requirements.txt
.venv/bin/pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Windows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-cmd&quot;&gt;python -m venv .venv
 .venv\Scripts\pip install -r requirements.txt
 .venv\Scripts\pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, start the EOS server to access it at &lt;code&gt;http://localhost:8503&lt;/code&gt; (API docs at &lt;code&gt;http://localhost:8503/docs&lt;/code&gt;):&lt;/p&gt; 
&lt;p&gt;Linux:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;.venv/bin/python src/akkudoktoreos/server/eos.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Windows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-cmd&quot;&gt;.venv\Scripts\python src/akkudoktoreos/server/eos.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Start EOS with following command to access it at &lt;code&gt;http://localhost:8503&lt;/code&gt; (API docs at &lt;code&gt;http://localhost:8503/docs&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;This project uses the &lt;code&gt;EOS.config.json&lt;/code&gt; file to manage configuration settings.&lt;/p&gt; 
&lt;h3&gt;Default Configuration&lt;/h3&gt; 
&lt;p&gt;A default configuration file &lt;code&gt;default.config.json&lt;/code&gt; is provided. This file contains all the necessary configuration keys with their default values.&lt;/p&gt; 
&lt;h3&gt;Custom Configuration&lt;/h3&gt; 
&lt;p&gt;Users can specify a custom configuration directory by setting the environment variable &lt;code&gt;EOS_DIR&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If the directory specified by &lt;code&gt;EOS_DIR&lt;/code&gt; contains an existing &lt;code&gt;config.json&lt;/code&gt; file, the application will use this configuration file.&lt;/li&gt; 
 &lt;li&gt;If the &lt;code&gt;EOS.config.json&lt;/code&gt; file does not exist in the specified directory, the &lt;code&gt;default.config.json&lt;/code&gt; file will be copied to the directory as &lt;code&gt;EOS.config.json&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configuration Updates&lt;/h3&gt; 
&lt;p&gt;If the configuration keys in the &lt;code&gt;EOS.config.json&lt;/code&gt; file are missing or different from those in &lt;code&gt;default.config.json&lt;/code&gt;, they will be automatically updated to match the default settings, ensuring that all required keys are present.&lt;/p&gt; 
&lt;h2&gt;Classes and Functionalities&lt;/h2&gt; 
&lt;p&gt;This project uses various classes to simulate and optimize the components of an energy system. Each class represents a specific aspect of the system, as described below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Battery&lt;/code&gt;: Simulates a battery storage system, including capacity, state of charge, and now charge and discharge losses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;PVForecast&lt;/code&gt;: Provides forecast data for photovoltaic generation, based on weather data and historical generation data.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Load&lt;/code&gt;: Models the load requirements of a household or business, enabling the prediction of future energy demand.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Heatpump&lt;/code&gt;: Simulates a heat pump, including its energy consumption and efficiency under various operating conditions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Strompreis&lt;/code&gt;: Provides information on electricity prices, enabling optimization of energy consumption and generation based on tariff information.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;EMS&lt;/code&gt;: The Energy Management System (EMS) coordinates the interaction between the various components, performs optimization, and simulates the operation of the entire energy system.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These classes work together to enable a detailed simulation and optimization of the energy system. For each class, specific parameters and settings can be adjusted to test different scenarios and strategies.&lt;/p&gt; 
&lt;h3&gt;Customization and Extension&lt;/h3&gt; 
&lt;p&gt;Each class is designed to be easily customized and extended to integrate additional functions or improvements. For example, new methods can be added for more accurate modeling of PV system or battery behavior. Developers are invited to modify and extend the system according to their needs.&lt;/p&gt; 
&lt;h2&gt;Server API&lt;/h2&gt; 
&lt;p&gt;See the Swagger API documentation for detailed information: &lt;a href=&quot;https://petstore3.swagger.io/?url=https://raw.githubusercontent.com/Akkudoktor-EOS/EOS/refs/heads/main/openapi.json&quot;&gt;EOS OpenAPI Spec&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Further resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://meintechblog.de/2024/09/05/andreas-schmitz-joerg-installiert-mein-energieoptimierungssystem/&quot;&gt;Installation guide (de)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>mlflow/mlflow</title>
      <link>https://github.com/mlflow/mlflow</link>
      <description>&lt;p&gt;Open source platform for the machine learning lifecycle&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MLflow: A Machine Learning Lifecycle Platform&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://mlflow.org/docs/latest/index.html&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-latest-success.svg?style=for-the-badge&quot; alt=&quot;Latest Docs&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/mlflow/mlflow/raw/master/LICENSE.txt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202-brightgreen.svg?style=for-the-badge&amp;amp;logo=apache&quot; alt=&quot;Apache 2 License&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pepy.tech/project/mlflow&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/dw/mlflow?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&quot; alt=&quot;Total Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://mlflow.org/community/#slack&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/slack-@mlflow--users-CF0E5B.svg?logo=slack&amp;amp;logoColor=white&amp;amp;labelColor=3F0E40&amp;amp;style=for-the-badge&quot; alt=&quot;Slack&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/MLflow&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/MLflow?style=for-the-badge&amp;amp;labelColor=00ACEE&amp;amp;logo=twitter&amp;amp;logoColor=white&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for machine learning projects, ensuring that each phase is manageable, traceable, and reproducible&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;The core components of MLflow are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://mlflow.org/docs/latest/tracking.html&quot;&gt;Experiment Tracking&lt;/a&gt; 📝: A set of APIs to log models, params, and results in ML experiments and compare them using an interactive UI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://mlflow.org/docs/latest/models.html&quot;&gt;Model Packaging&lt;/a&gt; 📦: A standard format for packaging a model and its metadata, such as dependency versions, ensuring reliable deployment and strong reproducibility.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://mlflow.org/docs/latest/model-registry.html&quot;&gt;Model Registry&lt;/a&gt; 💾: A centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of MLflow Models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://mlflow.org/docs/latest/deployment/index.html&quot;&gt;Serving&lt;/a&gt; 🚀: Tools for seamless model deployment to batch and real-time scoring on platforms like Docker, Kubernetes, Azure ML, and AWS SageMaker.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://mlflow.org/docs/latest/model-evaluation/index.html&quot;&gt;Evaluation&lt;/a&gt; 📊: A suite of automated model evaluation tools, seamlessly integrated with experiment tracking to record model performance and visually compare results across multiple models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://mlflow.org/docs/latest/llms/tracing/index.html&quot;&gt;Observability&lt;/a&gt; 🔍: Tracing integrations with various GenAI libraries and a Python SDK for manual instrumentation, offering smoother debugging experience and supporting online monitoring.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src=&quot;https://mlflow.org/img/hero.png&quot; alt=&quot;MLflow Hero&quot; width=&quot;100%&quot;&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install the MLflow Python package, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install mlflow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install MLflow from on different package hosting platforms:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PyPI&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://pypi.org/project/mlflow/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/mlflow.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;label=mlflow&quot; alt=&quot;PyPI - mlflow&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/mlflow-skinny/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/mlflow-skinny.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;label=mlflow-skinny&quot; alt=&quot;PyPI - mlflow-skinny&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;conda-forge&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://anaconda.org/conda-forge/mlflow&quot;&gt;&lt;img src=&quot;https://img.shields.io/conda/vn/conda-forge/mlflow.svg?style=for-the-badge&amp;amp;logo=anaconda&amp;amp;label=mlflow&quot; alt=&quot;Conda - mlflow&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://anaconda.org/conda-forge/mlflow-skinny&quot;&gt;&lt;img src=&quot;https://img.shields.io/conda/vn/conda-forge/mlflow.svg?style=for-the-badge&amp;amp;logo=anaconda&amp;amp;label=mlflow-skinny&quot; alt=&quot;Conda - mlflow-skinny&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CRAN&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://cran.r-project.org/package=mlflow&quot;&gt;&lt;img src=&quot;https://img.shields.io/cran/v/mlflow.svg?style=for-the-badge&amp;amp;logo=r&amp;amp;label=mlflow&quot; alt=&quot;CRAN - mlflow&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Maven Central&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://mvnrepository.com/artifact/org.mlflow/mlflow-client&quot;&gt;&lt;img src=&quot;https://img.shields.io/maven-central/v/org.mlflow/mlflow-client.svg?style=for-the-badge&amp;amp;logo=apache-maven&amp;amp;label=mlflow-client&quot; alt=&quot;Maven Central - mlflow-client&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://mvnrepository.com/artifact/org.mlflow/mlflow-parent&quot;&gt;&lt;img src=&quot;https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg?style=for-the-badge&amp;amp;logo=apache-maven&amp;amp;label=mlflow-parent&quot; alt=&quot;Maven Central - mlflow-parent&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://mvnrepository.com/artifact/org.mlflow/mlflow-scoring&quot;&gt;&lt;img src=&quot;https://img.shields.io/maven-central/v/org.mlflow/mlflow-scoring.svg?style=for-the-badge&amp;amp;logo=apache-maven&amp;amp;label=mlflow-scoring&quot; alt=&quot;Maven Central - mlflow-scoring&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://mvnrepository.com/artifact/org.mlflow/mlflow-spark&quot;&gt;&lt;img src=&quot;https://img.shields.io/maven-central/v/org.mlflow/mlflow-spark.svg?style=for-the-badge&amp;amp;logo=apache-maven&amp;amp;label=mlflow-spark&quot; alt=&quot;Maven Central - mlflow-spark&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Documentation 📘&lt;/h2&gt; 
&lt;p&gt;Official documentation for MLflow can be found at &lt;a href=&quot;https://mlflow.org/docs/latest/index.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running Anywhere 🌐&lt;/h2&gt; 
&lt;p&gt;You can run MLflow on many different environments, including local development, Amazon SageMaker, AzureML, and Databricks. Please refer to &lt;a href=&quot;https://mlflow.org/docs/latest/index.html#running-mlflow-anywhere&quot;&gt;this guidance&lt;/a&gt; for how to setup MLflow on your environment.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Experiment Tracking (&lt;a href=&quot;https://mlflow.org/docs/latest/tracking.html&quot;&gt;Doc&lt;/a&gt;)&lt;/h3&gt; 
&lt;p&gt;The following examples trains a simple regression model with scikit-learn, while enabling MLflow&#39;s &lt;a href=&quot;https://mlflow.org/docs/latest/tracking/autolog.html&quot;&gt;autologging&lt;/a&gt; feature for experiment tracking.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import mlflow

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor

# Enable MLflow&#39;s automatic experiment tracking for scikit-learn
mlflow.sklearn.autolog()

# Load the training dataset
db = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)

rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)
# MLflow triggers logging automatically upon model fitting
rf.fit(X_train, y_train)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the above code finishes, run the following command in a separate terminal and access the MLflow UI via the printed URL. An MLflow &lt;strong&gt;Run&lt;/strong&gt; should be automatically created, which tracks the training dataset, hyper parameters, performance metrics, the trained model, dependencies, and even more.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mlflow ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Serving Models (&lt;a href=&quot;https://mlflow.org/docs/latest/deployment/index.html&quot;&gt;Doc&lt;/a&gt;)&lt;/h3&gt; 
&lt;p&gt;You can deploy the logged model to a local inference server by a one-line command using the MLflow CLI. Visit the documentation for how to deploy models to other hosting platforms.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mlflow models serve --model-uri runs:/&amp;lt;run-id&amp;gt;/model
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Evaluating Models (&lt;a href=&quot;https://mlflow.org/docs/latest/model-evaluation/index.html&quot;&gt;Doc&lt;/a&gt;)&lt;/h3&gt; 
&lt;p&gt;The following example runs automatic evaluation for question-answering tasks with several built-in metrics.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import mlflow
import pandas as pd

# Evaluation set contains (1) input question (2) model outputs (3) ground truth
df = pd.DataFrame(
    {
        &quot;inputs&quot;: [&quot;What is MLflow?&quot;, &quot;What is Spark?&quot;],
        &quot;outputs&quot;: [
            &quot;MLflow is an innovative fully self-driving airship powered by AI.&quot;,
            &quot;Sparks is an American pop and rock duo formed in Los Angeles.&quot;,
        ],
        &quot;ground_truth&quot;: [
            &quot;MLflow is an open-source platform for managing the end-to-end machine learning (ML) &quot;
            &quot;lifecycle.&quot;,
            &quot;Apache Spark is an open-source, distributed computing system designed for big data &quot;
            &quot;processing and analytics.&quot;,
        ],
    }
)
eval_dataset = mlflow.data.from_pandas(
    df, predictions=&quot;outputs&quot;, targets=&quot;ground_truth&quot;
)

# Start an MLflow Run to record the evaluation results to
with mlflow.start_run(run_name=&quot;evaluate_qa&quot;):
    # Run automatic evaluation with a set of built-in metrics for question-answering models
    results = mlflow.evaluate(
        data=eval_dataset,
        model_type=&quot;question-answering&quot;,
    )

print(results.tables[&quot;eval_results_table&quot;])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Observability (&lt;a href=&quot;https://mlflow.org/docs/latest/llms/tracing/index.html&quot;&gt;Doc&lt;/a&gt;)&lt;/h3&gt; 
&lt;p&gt;MLflow Tracing provides LLM observability for various GenAI libraries such as OpenAI, LangChain, LlamaIndex, DSPy, AutoGen, and more. To enable auto-tracing, call &lt;code&gt;mlflow.xyz.autolog()&lt;/code&gt; before running your models. Refer to the documentation for customization and manual instrumentation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import mlflow
from openai import OpenAI

# Enable tracing for OpenAI
mlflow.openai.autolog()

# Query OpenAI LLM normally
response = OpenAI().chat.completions.create(
    model=&quot;gpt-4o-mini&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi!&quot;}],
    temperature=0.1,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to the &quot;Traces&quot; tab in the MLflow UI to find the trace records OpenAI query.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For help or questions about MLflow usage (e.g. &quot;how do I do X?&quot;) visit the &lt;a href=&quot;https://mlflow.org/docs/latest/index.html&quot;&gt;docs&lt;/a&gt; or &lt;a href=&quot;https://stackoverflow.com/questions/tagged/mlflow&quot;&gt;Stack Overflow&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Alternatively, you can ask the question to our AI-powered chat bot. Visit the doc website and click on the &lt;strong&gt;&quot;Ask AI&quot;&lt;/strong&gt; button at the right bottom to start chatting with the bot.&lt;/li&gt; 
 &lt;li&gt;To report a bug, file a documentation issue, or submit a feature request, please &lt;a href=&quot;https://github.com/mlflow/mlflow/issues/new/choose&quot;&gt;open a GitHub issue&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For release announcements and other discussions, please subscribe to our mailing list (&lt;a href=&quot;mailto:mlflow-users@googlegroups.com&quot;&gt;mlflow-users@googlegroups.com&lt;/a&gt;) or join us on &lt;a href=&quot;https://mlflow.org/slack&quot;&gt;Slack&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We happily welcome contributions to MLflow! We are also seeking contributions to items on the &lt;a href=&quot;https://github.com/mlflow/mlflow/milestone/3&quot;&gt;MLflow Roadmap&lt;/a&gt;. Please see our &lt;a href=&quot;https://raw.githubusercontent.com/mlflow/mlflow/master/CONTRIBUTING.md&quot;&gt;contribution guide&lt;/a&gt; to learn more about contributing to MLflow.&lt;/p&gt; 
&lt;h2&gt;Core Members&lt;/h2&gt; 
&lt;p&gt;MLflow is currently maintained by the following core members with significant contributions from hundreds of exceptionally talented community members.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/BenWilson2&quot;&gt;Ben Wilson&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/dbczumar&quot;&gt;Corey Zumar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/daniellok-db&quot;&gt;Daniel Lok&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/gabrielfu&quot;&gt;Gabriel Fu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/harupy&quot;&gt;Harutaka Kawamura&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/serena-ruan&quot;&gt;Serena Ruan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/WeichenXu123&quot;&gt;Weichen Xu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/B-Step62&quot;&gt;Yuki Watanabe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/TomeHirata&quot;&gt;Tomu Hirata&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>getsentry/sentry</title>
      <link>https://github.com/getsentry/sentry</link>
      <description>&lt;p&gt;Developer-first error tracking and performance monitoring&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;/p&gt;
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://sentry.io/?utm_source=github&amp;amp;utm_medium=logo&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://sentry-brand.storage.googleapis.com/sentry-wordmark-dark-280x84.png&quot; alt=&quot;Sentry&quot; width=&quot;280&quot; height=&quot;84&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; Users and logs provide clues. Sentry provides answers. &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;What&#39;s Sentry?&lt;/h1&gt; 
&lt;p&gt;Sentry is a developer-first error tracking and performance monitoring platform that helps developers see what actually matters, solve quicker, and learn continuously about their applications.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/projects.png&quot; width=&quot;270&quot;&gt; &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/issue-details.png&quot; width=&quot;270&quot;&gt; &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/transaction-summary.png&quot; width=&quot;270&quot;&gt; &lt;img src=&quot;https://github.com/getsentry/sentry/raw/master/.github/screenshots/releases.png&quot; width=&quot;270&quot;&gt; &lt;/p&gt; 
&lt;h2&gt;Official Sentry SDKs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-javascript&quot;&gt;JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-electron/&quot;&gt;Electron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-react-native&quot;&gt;React-Native&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-python&quot;&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-ruby&quot;&gt;Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-php&quot;&gt;PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-laravel&quot;&gt;Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-go&quot;&gt;Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-rust&quot;&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-java&quot;&gt;Java/Kotlin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-cocoa&quot;&gt;Objective-C/Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-dotnet&quot;&gt;C#/F#&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-native&quot;&gt;C/C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-dart&quot;&gt;Dart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/perl-raven&quot;&gt;Perl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-clj/&quot;&gt;Clojure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-elixir&quot;&gt;Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-unity&quot;&gt;Unity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-unreal&quot;&gt;Unreal Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry-powershell&quot;&gt;PowerShell&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.sentry.io/&quot;&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry/discussions&quot;&gt;Discussions&lt;/a&gt; (Bugs, feature requests, general questions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://discord.gg/PXa5Apfe7K&quot;&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.sentry.io/internal/contributing/&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry/issues&quot;&gt;Bug Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/getsentry/sentry&quot;&gt;Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.transifex.com/getsentry/sentry/&quot;&gt;Transifex&lt;/a&gt; (Translate Sentry!)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>huggingface/lerobot</title>
      <link>https://github.com/huggingface/lerobot</link>
      <description>&lt;p&gt;🤗 LeRobot: Making AI for Robotics more accessible with end-to-end learning&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;media/lerobot-logo-thumbnail.png&quot;&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;media/lerobot-logo-thumbnail.png&quot;&gt; 
  &lt;img alt=&quot;LeRobot, Hugging Face Robotics Library&quot; src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/lerobot-logo-thumbnail.png&quot; style=&quot;max-width: 100%;&quot;&gt; 
 &lt;/picture&gt; &lt;br&gt; &lt;br&gt; &lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml?query=branch%3Amain&quot;&gt;&lt;img src=&quot;https://github.com/huggingface/lerobot/actions/workflows/nightly-tests.yml/badge.svg?branch=main&quot; alt=&quot;Tests&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/huggingface/lerobot&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/huggingface/lerobot/branch/main/graph/badge.svg?token=TODO&quot; alt=&quot;Coverage&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.python.org/downloads/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/lerobot&quot; alt=&quot;Python versions&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&quot; alt=&quot;License&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/lerobot/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/status/lerobot&quot; alt=&quot;Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/lerobot/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/lerobot&quot; alt=&quot;Version&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/lerobot/tree/main/examples&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Examples-green.svg?sanitize=true&quot; alt=&quot;Examples&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/CODE_OF_CONDUCT.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Contributor%20Covenant-v2.1%20adopted-ff69b4.svg?sanitize=true&quot; alt=&quot;Contributor Covenant&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/s3KuuzsPFb&quot;&gt;&lt;img src=&quot;https://dcbadge.vercel.app/api/server/C5P34WJ68S?style=flat&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2 align=&quot;center&quot;&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/examples/10_use_so100.md&quot;&gt; Build Your Own SO-100 Robot!&lt;/a&gt;&lt;/p&gt; &lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/so100/leader_follower.webp?raw=true&quot; alt=&quot;SO-100 leader and follower arms&quot; title=&quot;SO-100 leader and follower arms&quot; width=&quot;50%&quot;&gt; 
 &lt;p&gt;&lt;strong&gt;Meet the SO-100 – Just $110 per arm!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Train it in minutes with a few simple moves on your laptop.&lt;/p&gt; 
 &lt;p&gt;Then sit back and watch your creation act autonomously! 🤯&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/examples/10_use_so100.md&quot;&gt; Get the full SO-100 tutorial here.&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Want to take it to the next level? Make your SO-100 mobile by building LeKiwi!&lt;/p&gt; 
 &lt;p&gt;Check out the &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/examples/11_use_lekiwi.md&quot;&gt;LeKiwi tutorial&lt;/a&gt; and bring your robot to life on wheels.&lt;/p&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/lekiwi/kiwi.webp?raw=true&quot; alt=&quot;LeKiwi mobile robot&quot; title=&quot;LeKiwi mobile robot&quot; width=&quot;50%&quot;&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;h3 align=&quot;center&quot;&gt; &lt;p&gt;LeRobot: State-of-the-art AI for real-world robotics&lt;/p&gt; &lt;/h3&gt; 
&lt;hr&gt; 
&lt;p&gt;🤗 LeRobot aims to provide models, datasets, and tools for real-world robotics in PyTorch. The goal is to lower the barrier to entry to robotics so that everyone can contribute and benefit from sharing datasets and pretrained models.&lt;/p&gt; 
&lt;p&gt;🤗 LeRobot contains state-of-the-art approaches that have been shown to transfer to the real-world with a focus on imitation learning and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;🤗 LeRobot already provides a set of pretrained models, datasets with human collected demonstrations, and simulation environments to get started without assembling a robot. In the coming weeks, the plan is to add more and more support for real-world robotics on the most affordable and capable robots out there.&lt;/p&gt; 
&lt;p&gt;🤗 LeRobot hosts pretrained models and datasets on this Hugging Face community page: &lt;a href=&quot;https://huggingface.co/lerobot&quot;&gt;huggingface.co/lerobot&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Examples of pretrained models on simulation environments&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/aloha_act.gif&quot; width=&quot;100%&quot; alt=&quot;ACT policy on ALOHA env&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/simxarm_tdmpc.gif&quot; width=&quot;100%&quot; alt=&quot;TDMPC policy on SimXArm env&quot;&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/pusht_diffusion.gif&quot; width=&quot;100%&quot; alt=&quot;Diffusion policy on PushT env&quot;&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt;ACT policy on ALOHA env&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;TDMPC policy on SimXArm env&lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt;Diffusion policy on PushT env&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Acknowledgment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to Tony Zhao, Zipeng Fu and colleagues for open sourcing ACT policy, ALOHA environments and datasets. Ours are adapted from &lt;a href=&quot;https://tonyzhaozh.github.io/aloha&quot;&gt;ALOHA&lt;/a&gt; and &lt;a href=&quot;https://mobile-aloha.github.io&quot;&gt;Mobile ALOHA&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Cheng Chi, Zhenjia Xu and colleagues for open sourcing Diffusion policy, Pusht environment and datasets, as well as UMI datasets. Ours are adapted from &lt;a href=&quot;https://diffusion-policy.cs.columbia.edu&quot;&gt;Diffusion Policy&lt;/a&gt; and &lt;a href=&quot;https://umi-gripper.github.io&quot;&gt;UMI Gripper&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Nicklas Hansen, Yunhai Feng and colleagues for open sourcing TDMPC policy, Simxarm environments and datasets. Ours are adapted from &lt;a href=&quot;https://github.com/nicklashansen/tdmpc&quot;&gt;TDMPC&lt;/a&gt; and &lt;a href=&quot;https://www.yunhaifeng.com/FOWM&quot;&gt;FOWM&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Antonio Loquercio and Ashish Kumar for their early support.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href=&quot;https://sjlee.cc/&quot;&gt;Seungjae (Jay) Lee&lt;/a&gt;, &lt;a href=&quot;https://mahis.life/&quot;&gt;Mahi Shafiullah&lt;/a&gt; and colleagues for open sourcing &lt;a href=&quot;https://sjlee.cc/vq-bet/&quot;&gt;VQ-BeT&lt;/a&gt; policy and helping us adapt the codebase to our repository. The policy is adapted from &lt;a href=&quot;https://github.com/jayLEE0301/vq_bet_official&quot;&gt;VQ-BeT repo&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Download our source code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/huggingface/lerobot.git
cd lerobot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment with Python 3.10 and activate it, e.g. with &lt;a href=&quot;https://docs.anaconda.com/free/miniconda/index.html&quot;&gt;&lt;code&gt;miniconda&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;conda create -y -n lerobot python=3.10
conda activate lerobot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When using &lt;code&gt;miniconda&lt;/code&gt;, if you don&#39;t have &lt;code&gt;ffmpeg&lt;/code&gt; in your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;conda install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install 🤗 LeRobot:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install --no-binary=av -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; If you encounter build errors, you may need to install additional dependencies (&lt;code&gt;cmake&lt;/code&gt;, &lt;code&gt;build-essential&lt;/code&gt;, and &lt;code&gt;ffmpeg libs&lt;/code&gt;). On Linux, run: &lt;code&gt;sudo apt-get install cmake build-essential python-dev pkg-config libavformat-dev libavcodec-dev libavdevice-dev libavutil-dev libswscale-dev libswresample-dev libavfilter-dev pkg-config&lt;/code&gt;. For other systems, see: &lt;a href=&quot;https://pyav.org/docs/develop/overview/installation.html#bring-your-own-ffmpeg&quot;&gt;Compiling PyAV&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For simulations, 🤗 LeRobot comes with gymnasium environments that can be installed as extras:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/huggingface/gym-aloha&quot;&gt;aloha&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/huggingface/gym-xarm&quot;&gt;xarm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/huggingface/gym-pusht&quot;&gt;pusht&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For instance, to install 🤗 LeRobot with aloha and pusht, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install --no-binary=av -e &quot;.[aloha, pusht]&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use &lt;a href=&quot;https://docs.wandb.ai/quickstart&quot;&gt;Weights and Biases&lt;/a&gt; for experiment tracking, log in with&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;wandb login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(note: you will also need to enable WandB in the configuration. See below.)&lt;/p&gt; 
&lt;h2&gt;Walkthrough&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;.
├── examples             # contains demonstration examples, start here to learn about LeRobot
|   └── advanced         # contains even more examples for those who have mastered the basics
├── lerobot
|   ├── configs          # contains config classes with all options that you can override in the command line
|   ├── common           # contains classes and utilities
|   |   ├── datasets       # various datasets of human demonstrations: aloha, pusht, xarm
|   |   ├── envs           # various sim environments: aloha, pusht, xarm
|   |   ├── policies       # various policies: act, diffusion, tdmpc
|   |   ├── robot_devices  # various real devices: dynamixel motors, opencv cameras, koch robots
|   |   └── utils          # various utilities
|   └── scripts          # contains functions to execute via command line
|       ├── eval.py                 # load policy and evaluate it on an environment
|       ├── train.py                # train a policy via imitation learning and/or reinforcement learning
|       ├── control_robot.py        # teleoperate a real robot, record data, run a policy
|       ├── push_dataset_to_hub.py  # convert your dataset into LeRobot dataset format and upload it to the Hugging Face hub
|       └── visualize_dataset.py    # load a dataset and render its demonstrations
├── outputs               # contains results of scripts execution: logs, videos, model checkpoints
└── tests                 # contains pytest utilities for continuous integration
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Visualize datasets&lt;/h3&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/1_load_lerobot_dataset.py&quot;&gt;example 1&lt;/a&gt; that illustrates how to use our dataset class which automatically downloads data from the Hugging Face hub.&lt;/p&gt; 
&lt;p&gt;You can also locally visualize episodes from a dataset on the hub by executing our script from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/visualize_dataset.py \
    --repo-id lerobot/pusht \
    --episode-index 0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or from a dataset in a local folder with the &lt;code&gt;root&lt;/code&gt; option and the &lt;code&gt;--local-files-only&lt;/code&gt; (in the following case the dataset will be searched for in &lt;code&gt;./my_local_data_dir/lerobot/pusht&lt;/code&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/visualize_dataset.py \
    --repo-id lerobot/pusht \
    --root ./my_local_data_dir \
    --local-files-only 1 \
    --episode-index 0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will open &lt;code&gt;rerun.io&lt;/code&gt; and display the camera streams, robot states and actions, like this:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20240505T172924Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;amp;X-Amz-SignedHeaders=host&amp;amp;actor_id=24889239&amp;amp;key_id=0&amp;amp;repo_id=748713144&quot;&gt;https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20240505T172924Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;amp;X-Amz-SignedHeaders=host&amp;amp;actor_id=24889239&amp;amp;key_id=0&amp;amp;repo_id=748713144&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Our script can also visualize datasets stored on a distant server. See &lt;code&gt;python lerobot/scripts/visualize_dataset.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; 
&lt;h3&gt;The &lt;code&gt;LeRobotDataset&lt;/code&gt; format&lt;/h3&gt; 
&lt;p&gt;A dataset in &lt;code&gt;LeRobotDataset&lt;/code&gt; format is very simple to use. It can be loaded from a repository on the Hugging Face hub or a local folder simply with e.g. &lt;code&gt;dataset = LeRobotDataset(&quot;lerobot/aloha_static_coffee&quot;)&lt;/code&gt; and can be indexed into like any Hugging Face and PyTorch dataset. For instance &lt;code&gt;dataset[0]&lt;/code&gt; will retrieve a single temporal frame from the dataset containing observation(s) and an action as PyTorch tensors ready to be fed to a model.&lt;/p&gt; 
&lt;p&gt;A specificity of &lt;code&gt;LeRobotDataset&lt;/code&gt; is that, rather than retrieving a single frame by its index, we can retrieve several frames based on their temporal relationship with the indexed frame, by setting &lt;code&gt;delta_timestamps&lt;/code&gt; to a list of relative times with respect to the indexed frame. For example, with &lt;code&gt;delta_timestamps = {&quot;observation.image&quot;: [-1, -0.5, -0.2, 0]}&lt;/code&gt; one can retrieve, for a given index, 4 frames: 3 &quot;previous&quot; frames 1 second, 0.5 seconds, and 0.2 seconds before the indexed frame, and the indexed frame itself (corresponding to the 0 entry). See example &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/1_load_lerobot_dataset.py&quot;&gt;1_load_lerobot_dataset.py&lt;/a&gt; for more details on &lt;code&gt;delta_timestamps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Under the hood, the &lt;code&gt;LeRobotDataset&lt;/code&gt; format makes use of several ways to serialize data which can be useful to understand if you plan to work more closely with this format. We tried to make a flexible yet simple dataset format that would cover most type of features and specificities present in reinforcement learning and robotics, in simulation and in real-world, with a focus on cameras and robot states but easily extended to other types of sensory inputs as long as they can be represented by a tensor.&lt;/p&gt; 
&lt;p&gt;Here are the important details and internal structure organization of a typical &lt;code&gt;LeRobotDataset&lt;/code&gt; instantiated with &lt;code&gt;dataset = LeRobotDataset(&quot;lerobot/aloha_static_coffee&quot;)&lt;/code&gt;. The exact features will change from dataset to dataset but not the main aspects:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;dataset attributes:
  ├ hf_dataset: a Hugging Face dataset (backed by Arrow/parquet). Typical features example:
  │  ├ observation.images.cam_high (VideoFrame):
  │  │   VideoFrame = {&#39;path&#39;: path to a mp4 video, &#39;timestamp&#39; (float32): timestamp in the video}
  │  ├ observation.state (list of float32): position of an arm joints (for instance)
  │  ... (more observations)
  │  ├ action (list of float32): goal position of an arm joints (for instance)
  │  ├ episode_index (int64): index of the episode for this sample
  │  ├ frame_index (int64): index of the frame for this sample in the episode ; starts at 0 for each episode
  │  ├ timestamp (float32): timestamp in the episode
  │  ├ next.done (bool): indicates the end of en episode ; True for the last frame in each episode
  │  └ index (int64): general index in the whole dataset
  ├ episode_data_index: contains 2 tensors with the start and end indices of each episode
  │  ├ from (1D int64 tensor): first frame index for each episode — shape (num episodes,) starts with 0
  │  └ to: (1D int64 tensor): last frame index for each episode — shape (num episodes,)
  ├ stats: a dictionary of statistics (max, mean, min, std) for each feature in the dataset, for instance
  │  ├ observation.images.cam_high: {&#39;max&#39;: tensor with same number of dimensions (e.g. `(c, 1, 1)` for images, `(c,)` for states), etc.}
  │  ...
  ├ info: a dictionary of metadata on the dataset
  │  ├ codebase_version (str): this is to keep track of the codebase version the dataset was created with
  │  ├ fps (float): frame per second the dataset is recorded/synchronized to
  │  ├ video (bool): indicates if frames are encoded in mp4 video files to save space or stored as png files
  │  └ encoding (dict): if video, this documents the main options that were used with ffmpeg to encode the videos
  ├ videos_dir (Path): where the mp4 videos or png images are stored/accessed
  └ camera_keys (list of string): the keys to access camera features in the item returned by the dataset (e.g. `[&quot;observation.images.cam_high&quot;, ...]`)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A &lt;code&gt;LeRobotDataset&lt;/code&gt; is serialised using several widespread file formats for each of its parts, namely:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;hf_dataset stored using Hugging Face datasets library serialization to parquet&lt;/li&gt; 
 &lt;li&gt;videos are stored in mp4 format to save space&lt;/li&gt; 
 &lt;li&gt;metadata are stored in plain json/jsonl files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Dataset can be uploaded/downloaded from the HuggingFace hub seamlessly. To work on a local dataset, you can specify its location with the &lt;code&gt;root&lt;/code&gt; argument if it&#39;s not in the default &lt;code&gt;~/.cache/huggingface/lerobot&lt;/code&gt; location.&lt;/p&gt; 
&lt;h3&gt;Evaluate a pretrained policy&lt;/h3&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/2_evaluate_pretrained_policy.py&quot;&gt;example 2&lt;/a&gt; that illustrates how to download a pretrained policy from Hugging Face hub, and run an evaluation on its corresponding environment.&lt;/p&gt; 
&lt;p&gt;We also provide a more capable script to parallelize the evaluation over multiple environments during the same rollout. Here is an example with a pretrained model hosted on &lt;a href=&quot;https://huggingface.co/lerobot/diffusion_pusht&quot;&gt;lerobot/diffusion_pusht&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/eval.py \
    --policy.path=lerobot/diffusion_pusht \
    --env.type=pusht \
    --eval.batch_size=10 \
    --eval.n_episodes=10 \
    --policy.use_amp=false \
    --policy.device=cuda
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: After training your own policy, you can re-evaluate the checkpoints with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/eval.py --policy.path={OUTPUT_DIR}/checkpoints/last/pretrained_model
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;python lerobot/scripts/eval.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; 
&lt;h3&gt;Train your own policy&lt;/h3&gt; 
&lt;p&gt;Check out &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/3_train_policy.py&quot;&gt;example 3&lt;/a&gt; that illustrate how to train a model using our core library in python, and &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/4_train_policy_with_script.md&quot;&gt;example 4&lt;/a&gt; that shows how to use our training script from command line.&lt;/p&gt; 
&lt;p&gt;To use wandb for logging training and evaluation curves, make sure you&#39;ve run &lt;code&gt;wandb login&lt;/code&gt; as a one-time setup step. Then, when running the training command above, enable WandB in the configuration by adding &lt;code&gt;--wandb.enable=true&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;A link to the wandb logs for the run will also show up in yellow in your terminal. Here is an example of what they look like in your browser. Please also check &lt;a href=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/examples/4_train_policy_with_script.md#typical-logs-and-metrics&quot;&gt;here&lt;/a&gt; for the explanation of some commonly used metrics in logs.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/huggingface/lerobot/main/media/wandb.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Note: For efficiency, during training every checkpoint is evaluated on a low number of episodes. You may use &lt;code&gt;--eval.n_episodes=500&lt;/code&gt; to evaluate on more episodes than the default. Or, after training, you may want to re-evaluate your best checkpoints on more episodes or change the evaluation settings. See &lt;code&gt;python lerobot/scripts/eval.py --help&lt;/code&gt; for more instructions.&lt;/p&gt; 
&lt;h4&gt;Reproduce state-of-the-art (SOTA)&lt;/h4&gt; 
&lt;p&gt;We provide some pretrained policies on our &lt;a href=&quot;https://huggingface.co/lerobot&quot;&gt;hub page&lt;/a&gt; that can achieve state-of-the-art performances. You can reproduce their training by loading the config from their run. Simply running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python lerobot/scripts/train.py --config_path=lerobot/diffusion_pusht
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;reproduces SOTA results for Diffusion Policy on the PushT task.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;If you would like to contribute to 🤗 LeRobot, please check out our &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/CONTRIBUTING.md&quot;&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ### Add a new dataset

To add a dataset to the hub, you need to login using a write-access token, which can be generated from the [Hugging Face settings](https://huggingface.co/settings/tokens):
```bash
huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential
```

Then point to your raw dataset folder (e.g. `data/aloha_static_pingpong_test_raw`), and push your dataset to the hub with:
```bash
python lerobot/scripts/push_dataset_to_hub.py \
--raw-dir data/aloha_static_pingpong_test_raw \
--out-dir data \
--repo-id lerobot/aloha_static_pingpong_test \
--raw-format aloha_hdf5
```

See `python lerobot/scripts/push_dataset_to_hub.py --help` for more instructions.

If your dataset format is not supported, implement your own in `lerobot/common/datasets/push_dataset_to_hub/${raw_format}_format.py` by copying examples like [pusht_zarr](https://github.com/huggingface/lerobot/blob/main/lerobot/common/datasets/push_dataset_to_hub/pusht_zarr_format.py), [umi_zarr](https://github.com/huggingface/lerobot/blob/main/lerobot/common/datasets/push_dataset_to_hub/umi_zarr_format.py), [aloha_hdf5](https://github.com/huggingface/lerobot/blob/main/lerobot/common/datasets/push_dataset_to_hub/aloha_hdf5_format.py), or [xarm_pkl](https://github.com/huggingface/lerobot/blob/main/lerobot/common/datasets/push_dataset_to_hub/xarm_pkl_format.py). --&gt; 
&lt;h3&gt;Add a pretrained policy&lt;/h3&gt; 
&lt;p&gt;Once you have trained a policy you may upload it to the Hugging Face hub using a hub id that looks like &lt;code&gt;${hf_user}/${repo_name}&lt;/code&gt; (e.g. &lt;a href=&quot;https://huggingface.co/lerobot/diffusion_pusht&quot;&gt;lerobot/diffusion_pusht&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;You first need to find the checkpoint folder located inside your experiment directory (e.g. &lt;code&gt;outputs/train/2024-05-05/20-21-12_aloha_act_default/checkpoints/002500&lt;/code&gt;). Within that there is a &lt;code&gt;pretrained_model&lt;/code&gt; directory which should contain:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;config.json&lt;/code&gt;: A serialized version of the policy configuration (following the policy&#39;s dataclass config).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;model.safetensors&lt;/code&gt;: A set of &lt;code&gt;torch.nn.Module&lt;/code&gt; parameters, saved in &lt;a href=&quot;https://huggingface.co/docs/safetensors/index&quot;&gt;Hugging Face Safetensors&lt;/a&gt; format.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;train_config.json&lt;/code&gt;: A consolidated configuration containing all parameter userd for training. The policy configuration should match &lt;code&gt;config.json&lt;/code&gt; exactly. Thisis useful for anyone who wants to evaluate your policy or for reproducibility.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To upload these to the hub, run the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;huggingface-cli upload ${hf_user}/${repo_name} path/to/pretrained_model
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href=&quot;https://github.com/huggingface/lerobot/raw/main/lerobot/scripts/eval.py&quot;&gt;eval.py&lt;/a&gt; for an example of how other people may use your policy.&lt;/p&gt; 
&lt;h3&gt;Improve your code with profiling&lt;/h3&gt; 
&lt;p&gt;An example of a code snippet to profile the evaluation of a policy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from torch.profiler import profile, record_function, ProfilerActivity

def trace_handler(prof):
    prof.export_chrome_trace(f&quot;tmp/trace_schedule_{prof.step_num}.json&quot;)

with profile(
    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    schedule=torch.profiler.schedule(
        wait=2,
        warmup=2,
        active=3,
    ),
    on_trace_ready=trace_handler
) as prof:
    with record_function(&quot;eval_policy&quot;):
        for i in range(num_episodes):
            prof.step()
            # insert code to profile, potentially whole body of eval_policy function
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want, you can cite this work with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@misc{cadene2024lerobot,
    author = {Cadene, Remi and Alibert, Simon and Soare, Alexander and Gallouedec, Quentin and Zouitine, Adil and Wolf, Thomas},
    title = {LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch},
    howpublished = &quot;\url{https://github.com/huggingface/lerobot}&quot;,
    year = {2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, if you are using any of the particular policy architecture, pretrained models, or datasets, it is recommended to cite the original authors of the work as they appear below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://diffusion-policy.cs.columbia.edu&quot;&gt;Diffusion Policy&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@article{chi2024diffusionpolicy,
	author = {Cheng Chi and Zhenjia Xu and Siyuan Feng and Eric Cousineau and Yilun Du and Benjamin Burchfiel and Russ Tedrake and Shuran Song},
	title ={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	journal = {The International Journal of Robotics Research},
	year = {2024},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tonyzhaozh.github.io/aloha&quot;&gt;ACT or ALOHA&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nicklashansen.com/td-mpc/&quot;&gt;TDMPC&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@inproceedings{Hansen2022tdmpc,
	title={Temporal Difference Learning for Model Predictive Control},
	author={Nicklas Hansen and Xiaolong Wang and Hao Su},
	booktitle={ICML},
	year={2022}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://sjlee.cc/vq-bet/&quot;&gt;VQ-BeT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bibtex&quot;&gt;@article{lee2024behavior,
  title={Behavior generation with latent actions},
  author={Lee, Seungjae and Wang, Yibin and Etukuru, Haritheja and Kim, H Jin and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2403.03181},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#huggingface/lerobot&amp;amp;Timeline&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=huggingface/lerobot&amp;amp;type=Timeline&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ansible/ansible</title>
      <link>https://github.com/ansible/ansible</link>
      <description>&lt;p&gt;Ansible is a radically simple IT automation platform that makes your applications and systems easier to deploy and maintain. Automate everything from code deployment to network configuration to cloud management, in a language that approaches plain English, using SSH, with no agents to install on remote systems. https://docs.ansible.com.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&quot;https://pypi.org/project/ansible-core&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/ansible-core.svg?sanitize=true&quot; alt=&quot;PyPI version&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://docs.ansible.com/ansible/latest/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-latest-brightgreen.svg?sanitize=true&quot; alt=&quot;Docs badge&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://docs.ansible.com/ansible/devel/community/communication.html&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/chat-IRC-brightgreen.svg?sanitize=true&quot; alt=&quot;Chat badge&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://dev.azure.com/ansible/ansible/_build/latest?definitionId=20&amp;amp;branchName=devel&quot;&gt;&lt;img src=&quot;https://dev.azure.com/ansible/ansible/_apis/build/status/CI?branchName=devel&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://docs.ansible.com/ansible/devel/community/code_of_conduct.html&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/code%20of%20conduct-Ansible-silver.svg?sanitize=true&quot; alt=&quot;Ansible Code of Conduct&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://docs.ansible.com/ansible/devel/community/communication.html#mailing-list-information&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/mailing%20lists-Ansible-orange.svg?sanitize=true&quot; alt=&quot;Ansible mailing lists&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/ansible/ansible/devel/COPYING&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-GPL%20v3.0-brightgreen.svg?sanitize=true&quot; alt=&quot;Repository License&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/2372&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/2372/badge&quot; alt=&quot;Ansible CII Best Practices certification&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Ansible&lt;/h1&gt; 
&lt;p&gt;Ansible is a radically simple IT automation system. It handles configuration management, application deployment, cloud provisioning, ad-hoc task execution, network automation, and multi-node orchestration. Ansible makes complex changes like zero-downtime rolling updates with load balancers easy. More information on the Ansible &lt;a href=&quot;https://ansible.com/&quot;&gt;website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Design Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have an extremely simple setup process with a minimal learning curve.&lt;/li&gt; 
 &lt;li&gt;Manage machines quickly and in parallel.&lt;/li&gt; 
 &lt;li&gt;Avoid custom-agents and additional open ports, be agentless by leveraging the existing SSH daemon.&lt;/li&gt; 
 &lt;li&gt;Describe infrastructure in a language that is both machine and human friendly.&lt;/li&gt; 
 &lt;li&gt;Focus on security and easy auditability/review/rewriting of content.&lt;/li&gt; 
 &lt;li&gt;Manage new remote machines instantly, without bootstrapping any software.&lt;/li&gt; 
 &lt;li&gt;Allow module development in any dynamic language, not just Python.&lt;/li&gt; 
 &lt;li&gt;Be usable as non-root.&lt;/li&gt; 
 &lt;li&gt;Be the easiest IT automation system to use, ever.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Use Ansible&lt;/h2&gt; 
&lt;p&gt;You can install a released version of Ansible with &lt;code&gt;pip&lt;/code&gt; or a package manager. See our &lt;a href=&quot;https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html&quot;&gt;installation guide&lt;/a&gt; for details on installing Ansible on a variety of platforms.&lt;/p&gt; 
&lt;p&gt;Power users and developers can run the &lt;code&gt;devel&lt;/code&gt; branch, which has the latest features and fixes, directly. Although it is reasonably stable, you are more likely to encounter breaking changes when running the &lt;code&gt;devel&lt;/code&gt; branch. We recommend getting involved in the Ansible community if you want to run the &lt;code&gt;devel&lt;/code&gt; branch.&lt;/p&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p&gt;Join the Ansible forum to ask questions, get help, and interact with the community.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://forum.ansible.com/c/help/6&quot;&gt;Get Help&lt;/a&gt;: Find help or share your Ansible knowledge to help others. Use tags to filter and subscribe to posts, such as the following: 
  &lt;ul&gt; 
   &lt;li&gt;Posts tagged with &lt;a href=&quot;https://forum.ansible.com/tag/ansible&quot;&gt;ansible&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Posts tagged with &lt;a href=&quot;https://forum.ansible.com/tag/ansible-core&quot;&gt;ansible-core&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Posts tagged with &lt;a href=&quot;https://forum.ansible.com/tag/playbook&quot;&gt;playbook&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://forum.ansible.com/c/chat/4&quot;&gt;Social Spaces&lt;/a&gt;: Meet and interact with fellow enthusiasts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://forum.ansible.com/c/news/5&quot;&gt;News &amp;amp; Announcements&lt;/a&gt;: Track project-wide announcements including social events.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn&quot;&gt;Bullhorn newsletter&lt;/a&gt;: Get release announcements and important changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more ways to get in touch, see &lt;a href=&quot;https://docs.ansible.com/ansible/devel/community/communication.html&quot;&gt;Communicating with the Ansible community&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contribute to Ansible&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out the &lt;a href=&quot;https://raw.githubusercontent.com/ansible/ansible/devel/.github/CONTRIBUTING.md&quot;&gt;Contributor&#39;s Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Read &lt;a href=&quot;https://docs.ansible.com/ansible/devel/community&quot;&gt;Community Information&lt;/a&gt; for all kinds of ways to contribute to and interact with the project, including how to submit bug reports and code to Ansible.&lt;/li&gt; 
 &lt;li&gt;Submit a proposed code update through a pull request to the &lt;code&gt;devel&lt;/code&gt; branch.&lt;/li&gt; 
 &lt;li&gt;Talk to us before making larger changes to avoid duplicate efforts. This not only helps everyone know what is going on, but it also helps save time and effort if we decide some changes are needed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Coding Guidelines&lt;/h2&gt; 
&lt;p&gt;We document our Coding Guidelines in the &lt;a href=&quot;https://docs.ansible.com/ansible/devel/dev_guide/&quot;&gt;Developer Guide&lt;/a&gt;. We particularly suggest you review:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_checklist.html&quot;&gt;Contributing your module to Ansible&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_best_practices.html&quot;&gt;Conventions, tips, and pitfalls&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Branch Info&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;devel&lt;/code&gt; branch corresponds to the release actively under development.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;stable-2.X&lt;/code&gt; branches correspond to stable releases.&lt;/li&gt; 
 &lt;li&gt;Create a branch based on &lt;code&gt;devel&lt;/code&gt; and set up a &lt;a href=&quot;https://docs.ansible.com/ansible/devel/dev_guide/developing_modules_general.html#common-environment-setup&quot;&gt;dev environment&lt;/a&gt; if you want to open a PR.&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href=&quot;https://docs.ansible.com/ansible/devel/reference_appendices/release_and_maintenance.html&quot;&gt;Ansible release and maintenance&lt;/a&gt; page for information about active branches.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Based on team and community feedback, an initial roadmap will be published for a major or minor version (ex: 2.7, 2.8). The &lt;a href=&quot;https://docs.ansible.com/ansible/devel/roadmap/&quot;&gt;Ansible Roadmap page&lt;/a&gt; details what is planned and how to influence the roadmap.&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;p&gt;Ansible was created by &lt;a href=&quot;https://github.com/mpdehaan&quot;&gt;Michael DeHaan&lt;/a&gt; and has contributions from over 5000 users (and growing). Thanks everyone!&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.ansible.com&quot;&gt;Ansible&lt;/a&gt; is sponsored by &lt;a href=&quot;https://www.redhat.com&quot;&gt;Red Hat, Inc.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;GNU General Public License v3.0 or later&lt;/p&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/ansible/ansible/devel/COPYING&quot;&gt;COPYING&lt;/a&gt; to see the full text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>deepseek-ai/DeepSeek-V3</title>
      <link>https://github.com/deepseek-ai/DeepSeek-V3</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;img src=&quot;https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/logo.svg?raw=true&quot; width=&quot;60%&quot; alt=&quot;DeepSeek-V3&quot;&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align=&quot;center&quot; style=&quot;line-height: 1;&quot;&gt; 
 &lt;a href=&quot;https://www.deepseek.com/&quot;&gt;&lt;img alt=&quot;Homepage&quot; src=&quot;https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/badge.svg?raw=true&quot;&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://chat.deepseek.com/&quot;&gt;&lt;img alt=&quot;Chat&quot; src=&quot;https://img.shields.io/badge/%F0%9F%A4%96%2520Chat-DeepSeek%2520V3-536af5?color=536af5&amp;amp;logoColor=white&quot;&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://huggingface.co/deepseek-ai&quot;&gt;&lt;img alt=&quot;Hugging Face&quot; src=&quot;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&amp;amp;logoColor=white&quot;&gt;&lt;/a&gt; 
 &lt;br&gt; 
 &lt;a href=&quot;https://discord.gg/Tc7c45Zzu5&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&amp;amp;logoColor=white&amp;amp;color=7289da&quot;&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-V2/raw/main/figures/qr.jpeg?raw=true&quot;&gt;&lt;img alt=&quot;Wechat&quot; src=&quot;https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&amp;amp;logoColor=white&quot;&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://twitter.com/deepseek_ai&quot;&gt;&lt;img alt=&quot;Twitter Follow&quot; src=&quot;https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&amp;amp;logoColor=white&quot;&gt;&lt;/a&gt; 
 &lt;br&gt; 
 &lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-V3/raw/main/LICENSE-CODE&quot;&gt;&lt;img alt=&quot;Code License&quot; src=&quot;https://img.shields.io/badge/Code_License-MIT-f5de53?&amp;amp;color=f5de53&quot;&gt;&lt;/a&gt; 
 &lt;a href=&quot;https://github.com/deepseek-ai/DeepSeek-V3/raw/main/LICENSE-MODEL&quot;&gt;&lt;img alt=&quot;Model License&quot; src=&quot;https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&amp;amp;color=f5de53&quot;&gt;&lt;/a&gt; 
 &lt;br&gt; 
 &lt;a href=&quot;https://arxiv.org/pdf/2412.19437&quot;&gt;&lt;b&gt;Paper Link&lt;/b&gt;👁️&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#1-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#2-model-summary&quot;&gt;Model Summary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#3-model-downloads&quot;&gt;Model Downloads&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#4-evaluation-results&quot;&gt;Evaluation Results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#5-chat-website--api-platform&quot;&gt;Chat Website &amp;amp; API Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#6-how-to-run-locally&quot;&gt;How to Run Locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#7-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#8-citation&quot;&gt;Citation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#9-contact&quot;&gt;Contact&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;1. Introduction&lt;/h2&gt; 
&lt;p&gt;We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;80%&quot; src=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/figures/benchmark.png&quot;&gt; &lt;/p&gt; 
&lt;h2&gt;2. Model Summary&lt;/h2&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;Architecture: Innovative Load Balancing Strategy and Training Objective&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;On top of the efficient architecture of DeepSeek-V2, we pioneer an auxiliary-loss-free strategy for load balancing, which minimizes the performance degradation that arises from encouraging load balancing.&lt;/li&gt; 
 &lt;li&gt;We investigate a Multi-Token Prediction (MTP) objective and prove it beneficial to model performance. It can also be used for speculative decoding for inference acceleration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;Pre-Training: Towards Ultimate Training Efficiency&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We design an FP8 mixed precision training framework and, for the first time, validate the feasibility and effectiveness of FP8 training on an extremely large-scale model.&lt;/li&gt; 
 &lt;li&gt;Through co-design of algorithms, frameworks, and hardware, we overcome the communication bottleneck in cross-node MoE training, nearly achieving full computation-communication overlap.&lt;br&gt; This significantly enhances our training efficiency and reduces the training costs, enabling us to further scale up the model size without additional overhead.&lt;/li&gt; 
 &lt;li&gt;At an economical cost of only 2.664M H800 GPU hours, we complete the pre-training of DeepSeek-V3 on 14.8T tokens, producing the currently strongest open-source base model. The subsequent training stages after pre-training require only 0.1M GPU hours.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;Post-Training: Knowledge Distillation from DeepSeek-R1&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We introduce an innovative methodology to distill reasoning capabilities from the long-Chain-of-Thought (CoT) model, specifically from one of the DeepSeek R1 series models, into standard LLMs, particularly DeepSeek-V3. Our pipeline elegantly incorporates the verification and reflection patterns of R1 into DeepSeek-V3 and notably improves its reasoning performance. Meanwhile, we also maintain a control over the output style and length of DeepSeek-V3.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;3. Model Downloads&lt;/h2&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;#Total Params&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;#Activated Params&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Context Length&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align=&quot;center&quot;&gt;DeepSeek-V3-Base&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;671B&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;37B&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;128K&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V3-Base&quot;&gt;🤗 Hugging Face&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align=&quot;center&quot;&gt;DeepSeek-V3&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;671B&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;37B&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;128K&lt;/td&gt; 
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-V3&quot;&gt;🤗 Hugging Face&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The total size of DeepSeek-V3 models on Hugging Face is 685B, which includes 671B of the Main Model weights and 14B of the Multi-Token Prediction (MTP) Module weights.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To ensure optimal performance and flexibility, we have partnered with open-source communities and hardware vendors to provide multiple ways to run the model locally. For step-by-step guidance, check out Section 6: &lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#6-how-to-run-locally&quot;&gt;How_to Run_Locally&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For developers looking to dive deeper, we recommend exploring &lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/README_WEIGHTS.md&quot;&gt;README_WEIGHTS.md&lt;/a&gt; for details on the Main Model weights and the Multi-Token Prediction (MTP) Modules. Please note that MTP support is currently under active development within the community, and we welcome your contributions and feedback.&lt;/p&gt; 
&lt;h2&gt;4. Evaluation Results&lt;/h2&gt; 
&lt;h3&gt;Base Model&lt;/h3&gt; 
&lt;h4&gt;Standard Benchmarks&lt;/h4&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;Benchmark (Metric)&lt;/th&gt; 
    &lt;th&gt;# Shots&lt;/th&gt; 
    &lt;th&gt;DeepSeek-V2&lt;/th&gt; 
    &lt;th&gt;Qwen2.5 72B&lt;/th&gt; 
    &lt;th&gt;LLaMA3.1 405B&lt;/th&gt; 
    &lt;th&gt;DeepSeek-V3&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;Architecture&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;MoE&lt;/td&gt; 
    &lt;td&gt;Dense&lt;/td&gt; 
    &lt;td&gt;Dense&lt;/td&gt; 
    &lt;td&gt;MoE&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;# Activated Params&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;21B&lt;/td&gt; 
    &lt;td&gt;72B&lt;/td&gt; 
    &lt;td&gt;405B&lt;/td&gt; 
    &lt;td&gt;37B&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;# Total Params&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;236B&lt;/td&gt; 
    &lt;td&gt;72B&lt;/td&gt; 
    &lt;td&gt;405B&lt;/td&gt; 
    &lt;td&gt;671B&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;English&lt;/td&gt; 
    &lt;td&gt;Pile-test (BPB)&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;0.606&lt;/td&gt; 
    &lt;td&gt;0.638&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;0.542&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;0.548&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;BBH (EM)&lt;/td&gt; 
    &lt;td&gt;3-shot&lt;/td&gt; 
    &lt;td&gt;78.8&lt;/td&gt; 
    &lt;td&gt;79.8&lt;/td&gt; 
    &lt;td&gt;82.9&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;87.5&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MMLU (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;78.4&lt;/td&gt; 
    &lt;td&gt;85.0&lt;/td&gt; 
    &lt;td&gt;84.4&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;87.1&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MMLU-Redux (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;75.6&lt;/td&gt; 
    &lt;td&gt;83.2&lt;/td&gt; 
    &lt;td&gt;81.3&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;86.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MMLU-Pro (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;51.4&lt;/td&gt; 
    &lt;td&gt;58.3&lt;/td&gt; 
    &lt;td&gt;52.8&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;64.4&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;DROP (F1)&lt;/td&gt; 
    &lt;td&gt;3-shot&lt;/td&gt; 
    &lt;td&gt;80.4&lt;/td&gt; 
    &lt;td&gt;80.6&lt;/td&gt; 
    &lt;td&gt;86.0&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;89.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;ARC-Easy (Acc.)&lt;/td&gt; 
    &lt;td&gt;25-shot&lt;/td&gt; 
    &lt;td&gt;97.6&lt;/td&gt; 
    &lt;td&gt;98.4&lt;/td&gt; 
    &lt;td&gt;98.4&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;98.9&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;ARC-Challenge (Acc.)&lt;/td&gt; 
    &lt;td&gt;25-shot&lt;/td&gt; 
    &lt;td&gt;92.2&lt;/td&gt; 
    &lt;td&gt;94.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;95.3&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;95.3&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;HellaSwag (Acc.)&lt;/td&gt; 
    &lt;td&gt;10-shot&lt;/td&gt; 
    &lt;td&gt;87.1&lt;/td&gt; 
    &lt;td&gt;84.8&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;89.2&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;88.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;PIQA (Acc.)&lt;/td&gt; 
    &lt;td&gt;0-shot&lt;/td&gt; 
    &lt;td&gt;83.9&lt;/td&gt; 
    &lt;td&gt;82.6&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;85.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;84.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;WinoGrande (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;86.3&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;82.3&lt;/td&gt; 
    &lt;td&gt;85.2&lt;/td&gt; 
    &lt;td&gt;84.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;RACE-Middle (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;73.1&lt;/td&gt; 
    &lt;td&gt;68.1&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;74.2&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;67.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;RACE-High (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;52.6&lt;/td&gt; 
    &lt;td&gt;50.3&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;56.8&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;51.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;TriviaQA (EM)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;80.0&lt;/td&gt; 
    &lt;td&gt;71.9&lt;/td&gt; 
    &lt;td&gt;82.7&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;82.9&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;NaturalQuestions (EM)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;38.6&lt;/td&gt; 
    &lt;td&gt;33.2&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;41.5&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;40.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;AGIEval (Acc.)&lt;/td&gt; 
    &lt;td&gt;0-shot&lt;/td&gt; 
    &lt;td&gt;57.5&lt;/td&gt; 
    &lt;td&gt;75.8&lt;/td&gt; 
    &lt;td&gt;60.6&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;79.6&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Code&lt;/td&gt; 
    &lt;td&gt;HumanEval (Pass@1)&lt;/td&gt; 
    &lt;td&gt;0-shot&lt;/td&gt; 
    &lt;td&gt;43.3&lt;/td&gt; 
    &lt;td&gt;53.0&lt;/td&gt; 
    &lt;td&gt;54.9&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;65.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MBPP (Pass@1)&lt;/td&gt; 
    &lt;td&gt;3-shot&lt;/td&gt; 
    &lt;td&gt;65.0&lt;/td&gt; 
    &lt;td&gt;72.6&lt;/td&gt; 
    &lt;td&gt;68.4&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;75.4&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;LiveCodeBench-Base (Pass@1)&lt;/td&gt; 
    &lt;td&gt;3-shot&lt;/td&gt; 
    &lt;td&gt;11.6&lt;/td&gt; 
    &lt;td&gt;12.9&lt;/td&gt; 
    &lt;td&gt;15.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;19.4&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;CRUXEval-I (Acc.)&lt;/td&gt; 
    &lt;td&gt;2-shot&lt;/td&gt; 
    &lt;td&gt;52.5&lt;/td&gt; 
    &lt;td&gt;59.1&lt;/td&gt; 
    &lt;td&gt;58.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;67.3&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;CRUXEval-O (Acc.)&lt;/td&gt; 
    &lt;td&gt;2-shot&lt;/td&gt; 
    &lt;td&gt;49.8&lt;/td&gt; 
    &lt;td&gt;59.9&lt;/td&gt; 
    &lt;td&gt;59.9&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;69.8&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Math&lt;/td&gt; 
    &lt;td&gt;GSM8K (EM)&lt;/td&gt; 
    &lt;td&gt;8-shot&lt;/td&gt; 
    &lt;td&gt;81.6&lt;/td&gt; 
    &lt;td&gt;88.3&lt;/td&gt; 
    &lt;td&gt;83.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;89.3&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MATH (EM)&lt;/td&gt; 
    &lt;td&gt;4-shot&lt;/td&gt; 
    &lt;td&gt;43.4&lt;/td&gt; 
    &lt;td&gt;54.4&lt;/td&gt; 
    &lt;td&gt;49.0&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;61.6&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MGSM (EM)&lt;/td&gt; 
    &lt;td&gt;8-shot&lt;/td&gt; 
    &lt;td&gt;63.6&lt;/td&gt; 
    &lt;td&gt;76.2&lt;/td&gt; 
    &lt;td&gt;69.9&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;79.8&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;CMath (EM)&lt;/td&gt; 
    &lt;td&gt;3-shot&lt;/td&gt; 
    &lt;td&gt;78.7&lt;/td&gt; 
    &lt;td&gt;84.5&lt;/td&gt; 
    &lt;td&gt;77.3&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;90.7&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Chinese&lt;/td&gt; 
    &lt;td&gt;CLUEWSC (EM)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;82.0&lt;/td&gt; 
    &lt;td&gt;82.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;83.0&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;82.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;C-Eval (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;81.4&lt;/td&gt; 
    &lt;td&gt;89.2&lt;/td&gt; 
    &lt;td&gt;72.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;90.1&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;CMMLU (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;84.0&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;89.5&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;73.7&lt;/td&gt; 
    &lt;td&gt;88.8&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;CMRC (EM)&lt;/td&gt; 
    &lt;td&gt;1-shot&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;77.4&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;75.8&lt;/td&gt; 
    &lt;td&gt;76.0&lt;/td&gt; 
    &lt;td&gt;76.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;C3 (Acc.)&lt;/td&gt; 
    &lt;td&gt;0-shot&lt;/td&gt; 
    &lt;td&gt;77.4&lt;/td&gt; 
    &lt;td&gt;76.7&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;79.7&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;78.6&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;CCPM (Acc.)&lt;/td&gt; 
    &lt;td&gt;0-shot&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;93.0&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;88.5&lt;/td&gt; 
    &lt;td&gt;78.6&lt;/td&gt; 
    &lt;td&gt;92.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Multilingual&lt;/td&gt; 
    &lt;td&gt;MMMLU-non-English (Acc.)&lt;/td&gt; 
    &lt;td&gt;5-shot&lt;/td&gt; 
    &lt;td&gt;64.0&lt;/td&gt; 
    &lt;td&gt;74.8&lt;/td&gt; 
    &lt;td&gt;73.8&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;79.4&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Best results are shown in bold. Scores with a gap not exceeding 0.3 are considered to be at the same level. DeepSeek-V3 achieves the best performance on most benchmarks, especially on math and code tasks. For more evaluation details, please check our paper.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Context Window&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img width=&quot;80%&quot; src=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/figures/niah.png&quot;&gt; &lt;/p&gt; 
&lt;p&gt;Evaluation results on the &lt;code&gt;Needle In A Haystack&lt;/code&gt; (NIAH) tests. DeepSeek-V3 performs well across all context window lengths up to &lt;strong&gt;128K&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Chat Model&lt;/h3&gt; 
&lt;h4&gt;Standard Benchmarks (Models larger than 67B)&lt;/h4&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Benchmark (Metric)&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;DeepSeek V2-0506&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;DeepSeek V2.5-0905&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Qwen2.5 72B-Inst.&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Llama3.1 405B-Inst.&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Claude-3.5-Sonnet-1022&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;GPT-4o 0513&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;DeepSeek V3&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;Architecture&lt;/td&gt; 
    &lt;td&gt;MoE&lt;/td&gt; 
    &lt;td&gt;MoE&lt;/td&gt; 
    &lt;td&gt;Dense&lt;/td&gt; 
    &lt;td&gt;Dense&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;MoE&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;# Activated Params&lt;/td&gt; 
    &lt;td&gt;21B&lt;/td&gt; 
    &lt;td&gt;21B&lt;/td&gt; 
    &lt;td&gt;72B&lt;/td&gt; 
    &lt;td&gt;405B&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;37B&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;# Total Params&lt;/td&gt; 
    &lt;td&gt;236B&lt;/td&gt; 
    &lt;td&gt;236B&lt;/td&gt; 
    &lt;td&gt;72B&lt;/td&gt; 
    &lt;td&gt;405B&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;671B&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;English&lt;/td&gt; 
    &lt;td&gt;MMLU (EM)&lt;/td&gt; 
    &lt;td&gt;78.2&lt;/td&gt; 
    &lt;td&gt;80.6&lt;/td&gt; 
    &lt;td&gt;85.3&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;88.6&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;88.3&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;87.2&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;88.5&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MMLU-Redux (EM)&lt;/td&gt; 
    &lt;td&gt;77.9&lt;/td&gt; 
    &lt;td&gt;80.3&lt;/td&gt; 
    &lt;td&gt;85.6&lt;/td&gt; 
    &lt;td&gt;86.2&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;88.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;88.0&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;89.1&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MMLU-Pro (EM)&lt;/td&gt; 
    &lt;td&gt;58.5&lt;/td&gt; 
    &lt;td&gt;66.2&lt;/td&gt; 
    &lt;td&gt;71.6&lt;/td&gt; 
    &lt;td&gt;73.3&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;78.0&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;72.6&lt;/td&gt; 
    &lt;td&gt;75.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;DROP (3-shot F1)&lt;/td&gt; 
    &lt;td&gt;83.0&lt;/td&gt; 
    &lt;td&gt;87.8&lt;/td&gt; 
    &lt;td&gt;76.7&lt;/td&gt; 
    &lt;td&gt;88.7&lt;/td&gt; 
    &lt;td&gt;88.3&lt;/td&gt; 
    &lt;td&gt;83.7&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;91.6&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;IF-Eval (Prompt Strict)&lt;/td&gt; 
    &lt;td&gt;57.7&lt;/td&gt; 
    &lt;td&gt;80.6&lt;/td&gt; 
    &lt;td&gt;84.1&lt;/td&gt; 
    &lt;td&gt;86.0&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;86.5&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;84.3&lt;/td&gt; 
    &lt;td&gt;86.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;GPQA-Diamond (Pass@1)&lt;/td&gt; 
    &lt;td&gt;35.3&lt;/td&gt; 
    &lt;td&gt;41.3&lt;/td&gt; 
    &lt;td&gt;49.0&lt;/td&gt; 
    &lt;td&gt;51.1&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;65.0&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;49.9&lt;/td&gt; 
    &lt;td&gt;59.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;SimpleQA (Correct)&lt;/td&gt; 
    &lt;td&gt;9.0&lt;/td&gt; 
    &lt;td&gt;10.2&lt;/td&gt; 
    &lt;td&gt;9.1&lt;/td&gt; 
    &lt;td&gt;17.1&lt;/td&gt; 
    &lt;td&gt;28.4&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;38.2&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;24.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;FRAMES (Acc.)&lt;/td&gt; 
    &lt;td&gt;66.9&lt;/td&gt; 
    &lt;td&gt;65.4&lt;/td&gt; 
    &lt;td&gt;69.8&lt;/td&gt; 
    &lt;td&gt;70.0&lt;/td&gt; 
    &lt;td&gt;72.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;80.5&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;73.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;LongBench v2 (Acc.)&lt;/td&gt; 
    &lt;td&gt;31.6&lt;/td&gt; 
    &lt;td&gt;35.4&lt;/td&gt; 
    &lt;td&gt;39.4&lt;/td&gt; 
    &lt;td&gt;36.1&lt;/td&gt; 
    &lt;td&gt;41.0&lt;/td&gt; 
    &lt;td&gt;48.1&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;48.7&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Code&lt;/td&gt; 
    &lt;td&gt;HumanEval-Mul (Pass@1)&lt;/td&gt; 
    &lt;td&gt;69.3&lt;/td&gt; 
    &lt;td&gt;77.4&lt;/td&gt; 
    &lt;td&gt;77.3&lt;/td&gt; 
    &lt;td&gt;77.2&lt;/td&gt; 
    &lt;td&gt;81.7&lt;/td&gt; 
    &lt;td&gt;80.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;82.6&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;LiveCodeBench (Pass@1-COT)&lt;/td&gt; 
    &lt;td&gt;18.8&lt;/td&gt; 
    &lt;td&gt;29.2&lt;/td&gt; 
    &lt;td&gt;31.1&lt;/td&gt; 
    &lt;td&gt;28.4&lt;/td&gt; 
    &lt;td&gt;36.3&lt;/td&gt; 
    &lt;td&gt;33.4&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;40.5&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;LiveCodeBench (Pass@1)&lt;/td&gt; 
    &lt;td&gt;20.3&lt;/td&gt; 
    &lt;td&gt;28.4&lt;/td&gt; 
    &lt;td&gt;28.7&lt;/td&gt; 
    &lt;td&gt;30.1&lt;/td&gt; 
    &lt;td&gt;32.8&lt;/td&gt; 
    &lt;td&gt;34.2&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;37.6&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;Codeforces (Percentile)&lt;/td&gt; 
    &lt;td&gt;17.5&lt;/td&gt; 
    &lt;td&gt;35.6&lt;/td&gt; 
    &lt;td&gt;24.8&lt;/td&gt; 
    &lt;td&gt;25.3&lt;/td&gt; 
    &lt;td&gt;20.3&lt;/td&gt; 
    &lt;td&gt;23.6&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;51.6&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;SWE Verified (Resolved)&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;22.6&lt;/td&gt; 
    &lt;td&gt;23.8&lt;/td&gt; 
    &lt;td&gt;24.5&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;50.8&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;38.8&lt;/td&gt; 
    &lt;td&gt;42.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;Aider-Edit (Acc.)&lt;/td&gt; 
    &lt;td&gt;60.3&lt;/td&gt; 
    &lt;td&gt;71.6&lt;/td&gt; 
    &lt;td&gt;65.4&lt;/td&gt; 
    &lt;td&gt;63.9&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;84.2&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;72.9&lt;/td&gt; 
    &lt;td&gt;79.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;Aider-Polyglot (Acc.)&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;18.2&lt;/td&gt; 
    &lt;td&gt;7.6&lt;/td&gt; 
    &lt;td&gt;5.8&lt;/td&gt; 
    &lt;td&gt;45.3&lt;/td&gt; 
    &lt;td&gt;16.0&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;49.6&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Math&lt;/td&gt; 
    &lt;td&gt;AIME 2024 (Pass@1)&lt;/td&gt; 
    &lt;td&gt;4.6&lt;/td&gt; 
    &lt;td&gt;16.7&lt;/td&gt; 
    &lt;td&gt;23.3&lt;/td&gt; 
    &lt;td&gt;23.3&lt;/td&gt; 
    &lt;td&gt;16.0&lt;/td&gt; 
    &lt;td&gt;9.3&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;39.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;MATH-500 (EM)&lt;/td&gt; 
    &lt;td&gt;56.3&lt;/td&gt; 
    &lt;td&gt;74.7&lt;/td&gt; 
    &lt;td&gt;80.0&lt;/td&gt; 
    &lt;td&gt;73.8&lt;/td&gt; 
    &lt;td&gt;78.3&lt;/td&gt; 
    &lt;td&gt;74.6&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;90.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;CNMO 2024 (Pass@1)&lt;/td&gt; 
    &lt;td&gt;2.8&lt;/td&gt; 
    &lt;td&gt;10.8&lt;/td&gt; 
    &lt;td&gt;15.9&lt;/td&gt; 
    &lt;td&gt;6.8&lt;/td&gt; 
    &lt;td&gt;13.1&lt;/td&gt; 
    &lt;td&gt;10.8&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;43.2&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Chinese&lt;/td&gt; 
    &lt;td&gt;CLUEWSC (EM)&lt;/td&gt; 
    &lt;td&gt;89.9&lt;/td&gt; 
    &lt;td&gt;90.4&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;91.4&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;84.7&lt;/td&gt; 
    &lt;td&gt;85.4&lt;/td&gt; 
    &lt;td&gt;87.9&lt;/td&gt; 
    &lt;td&gt;90.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;C-Eval (EM)&lt;/td&gt; 
    &lt;td&gt;78.6&lt;/td&gt; 
    &lt;td&gt;79.5&lt;/td&gt; 
    &lt;td&gt;86.1&lt;/td&gt; 
    &lt;td&gt;61.5&lt;/td&gt; 
    &lt;td&gt;76.7&lt;/td&gt; 
    &lt;td&gt;76.0&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;86.5&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;C-SimpleQA (Correct)&lt;/td&gt; 
    &lt;td&gt;48.5&lt;/td&gt; 
    &lt;td&gt;54.1&lt;/td&gt; 
    &lt;td&gt;48.4&lt;/td&gt; 
    &lt;td&gt;50.4&lt;/td&gt; 
    &lt;td&gt;51.3&lt;/td&gt; 
    &lt;td&gt;59.3&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;64.8&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] All models are evaluated in a configuration that limits the output length to 8K. Benchmarks containing fewer than 1000 samples are tested multiple times using varying temperature settings to derive robust final results. DeepSeek-V3 stands as the best-performing open-source model, and also exhibits competitive performance against frontier closed-source models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Open Ended Generation Evaluation&lt;/h4&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;Arena-Hard&lt;/th&gt; 
    &lt;th&gt;AlpacaEval 2.0&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;DeepSeek-V2.5-0905&lt;/td&gt; 
    &lt;td&gt;76.2&lt;/td&gt; 
    &lt;td&gt;50.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Qwen2.5-72B-Instruct&lt;/td&gt; 
    &lt;td&gt;81.2&lt;/td&gt; 
    &lt;td&gt;49.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;LLaMA-3.1 405B&lt;/td&gt; 
    &lt;td&gt;69.3&lt;/td&gt; 
    &lt;td&gt;40.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;GPT-4o-0513&lt;/td&gt; 
    &lt;td&gt;80.4&lt;/td&gt; 
    &lt;td&gt;51.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Claude-Sonnet-3.5-1022&lt;/td&gt; 
    &lt;td&gt;85.2&lt;/td&gt; 
    &lt;td&gt;52.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;DeepSeek-V3&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;85.5&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;70.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] English open-ended conversation evaluations. For AlpacaEval 2.0, we use the length-controlled win rate as the metric.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;5. Chat Website &amp;amp; API Platform&lt;/h2&gt; 
&lt;p&gt;You can chat with DeepSeek-V3 on DeepSeek&#39;s official website: &lt;a href=&quot;https://chat.deepseek.com/sign_in&quot;&gt;chat.deepseek.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We also provide OpenAI-Compatible API at DeepSeek Platform: &lt;a href=&quot;https://platform.deepseek.com/&quot;&gt;platform.deepseek.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. How to Run Locally&lt;/h2&gt; 
&lt;p&gt;DeepSeek-V3 can be deployed locally using the following hardware and open-source community software:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;DeepSeek-Infer Demo&lt;/strong&gt;: We provide a simple and lightweight demo for FP8 and BF16 inference.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SGLang&lt;/strong&gt;: Fully support the DeepSeek-V3 model in both BF16 and FP8 inference modes, with Multi-Token Prediction &lt;a href=&quot;https://github.com/sgl-project/sglang/issues/2591&quot;&gt;coming soon&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LMDeploy&lt;/strong&gt;: Enables efficient FP8 and BF16 inference for local and cloud deployment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TensorRT-LLM&lt;/strong&gt;: Currently supports BF16 inference and INT4/8 quantization, with FP8 support coming soon.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;vLLM&lt;/strong&gt;: Support DeepSeek-V3 model with FP8 and BF16 modes for tensor parallelism and pipeline parallelism.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AMD GPU&lt;/strong&gt;: Enables running the DeepSeek-V3 model on AMD GPUs via SGLang in both BF16 and FP8 modes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Huawei Ascend NPU&lt;/strong&gt;: Supports running DeepSeek-V3 on Huawei Ascend devices.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Since FP8 training is natively adopted in our framework, we only provide FP8 weights. If you require BF16 weights for experimentation, you can use the provided conversion script to perform the transformation.&lt;/p&gt; 
&lt;p&gt;Here is an example of converting FP8 weights to BF16:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;cd inference
python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Hugging Face&#39;s Transformers has not been directly supported yet.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;6.1 Inference with DeepSeek-Infer Demo (example only)&lt;/h3&gt; 
&lt;h4&gt;System Requirements&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Linux with Python 3.10 only. Mac and Windows are not supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-pip-requirements&quot;&gt;torch==2.4.1
triton==3.0.0
transformers==4.46.3
safetensors==0.4.5
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Model Weights &amp;amp; Demo Code Preparation&lt;/h4&gt; 
&lt;p&gt;First, clone our DeepSeek-V3 GitHub repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;git clone https://github.com/deepseek-ai/DeepSeek-V3.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Navigate to the &lt;code&gt;inference&lt;/code&gt; folder and install dependencies listed in &lt;code&gt;requirements.txt&lt;/code&gt;. Easiest way is to use a package manager like &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;uv&lt;/code&gt; to create a new virtual environment and install the dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;cd DeepSeek-V3/inference
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download the model weights from Hugging Face, and put them into &lt;code&gt;/path/to/DeepSeek-V3&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h4&gt;Model Weights Conversion&lt;/h4&gt; 
&lt;p&gt;Convert Hugging Face model weights to a specific format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;python convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run&lt;/h4&gt; 
&lt;p&gt;Then you can chat with DeepSeek-V3:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or batch inference on a given file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --input-file $FILE
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;6.2 Inference with SGLang (recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/sgl-project/sglang&quot;&gt;SGLang&lt;/a&gt; currently supports &lt;a href=&quot;https://lmsys.org/blog/2024-09-04-sglang-v0-3/#deepseek-multi-head-latent-attention-mla-throughput-optimizations&quot;&gt;MLA optimizations&lt;/a&gt;, &lt;a href=&quot;https://lmsys.org/blog/2024-12-04-sglang-v0-4/#data-parallelism-attention-for-deepseek-models&quot;&gt;DP Attention&lt;/a&gt;, FP8 (W8A8), FP8 KV Cache, and Torch Compile, delivering state-of-the-art latency and throughput performance among open-source frameworks.&lt;/p&gt; 
&lt;p&gt;Notably, &lt;a href=&quot;https://github.com/sgl-project/sglang/releases/tag/v0.4.1&quot;&gt;SGLang v0.4.1&lt;/a&gt; fully supports running DeepSeek-V3 on both &lt;strong&gt;NVIDIA and AMD GPUs&lt;/strong&gt;, making it a highly versatile and robust solution.&lt;/p&gt; 
&lt;p&gt;SGLang also supports &lt;a href=&quot;https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3#example-serving-with-2-h208&quot;&gt;multi-node tensor parallelism&lt;/a&gt;, enabling you to run this model on multiple network-connected machines.&lt;/p&gt; 
&lt;p&gt;Multi-Token Prediction (MTP) is in development, and progress can be tracked in the &lt;a href=&quot;https://github.com/sgl-project/sglang/issues/2591&quot;&gt;optimization plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here are the launch instructions from the SGLang team: &lt;a href=&quot;https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3&quot;&gt;https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;6.3 Inference with LMDeploy (recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/InternLM/lmdeploy&quot;&gt;LMDeploy&lt;/a&gt;, a flexible and high-performance inference and serving framework tailored for large language models, now supports DeepSeek-V3. It offers both offline pipeline processing and online deployment capabilities, seamlessly integrating with PyTorch-based workflows.&lt;/p&gt; 
&lt;p&gt;For comprehensive step-by-step instructions on running DeepSeek-V3 with LMDeploy, please refer to here: &lt;a href=&quot;https://github.com/InternLM/lmdeploy/issues/2960&quot;&gt;https://github.com/InternLM/lmdeploy/issues/2960&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;6.4 Inference with TRT-LLM (recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/NVIDIA/TensorRT-LLM&quot;&gt;TensorRT-LLM&lt;/a&gt; now supports the DeepSeek-V3 model, offering precision options such as BF16 and INT4/INT8 weight-only. Support for FP8 is currently in progress and will be released soon. You can access the custom branch of TRTLLM specifically for DeepSeek-V3 support through the following link to experience the new features directly: &lt;a href=&quot;https://github.com/NVIDIA/TensorRT-LLM/tree/deepseek/examples/deepseek_v3&quot;&gt;https://github.com/NVIDIA/TensorRT-LLM/tree/deepseek/examples/deepseek_v3&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;6.5 Inference with vLLM (recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/vllm-project/vllm&quot;&gt;vLLM&lt;/a&gt; v0.6.6 supports DeepSeek-V3 inference for FP8 and BF16 modes on both NVIDIA and AMD GPUs. Aside from standard techniques, vLLM offers &lt;em&gt;pipeline parallelism&lt;/em&gt; allowing you to run this model on multiple machines connected by networks. For detailed guidance, please refer to the &lt;a href=&quot;https://docs.vllm.ai/en/latest/serving/distributed_serving.html&quot;&gt;vLLM instructions&lt;/a&gt;. Please feel free to follow &lt;a href=&quot;https://github.com/vllm-project/vllm/issues/11539&quot;&gt;the enhancement plan&lt;/a&gt; as well.&lt;/p&gt; 
&lt;h3&gt;6.6 Recommended Inference Functionality with AMD GPUs&lt;/h3&gt; 
&lt;p&gt;In collaboration with the AMD team, we have achieved Day-One support for AMD GPUs using SGLang, with full compatibility for both FP8 and BF16 precision. For detailed guidance, please refer to the &lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/#63-inference-with-lmdeploy-recommended&quot;&gt;SGLang instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;6.7 Recommended Inference Functionality with Huawei Ascend NPUs&lt;/h3&gt; 
&lt;p&gt;The &lt;a href=&quot;https://www.hiascend.com/en/software/mindie&quot;&gt;MindIE&lt;/a&gt; framework from the Huawei Ascend community has successfully adapted the BF16 version of DeepSeek-V3. For step-by-step guidance on Ascend NPUs, please follow the &lt;a href=&quot;https://modelers.cn/models/MindIE/deepseekv3&quot;&gt;instructions here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;7. License&lt;/h2&gt; 
&lt;p&gt;This code repository is licensed under &lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/LICENSE-CODE&quot;&gt;the MIT License&lt;/a&gt;. The use of DeepSeek-V3 Base/Chat models is subject to &lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/LICENSE-MODEL&quot;&gt;the Model License&lt;/a&gt;. DeepSeek-V3 series (including Base and Chat) supports commercial use.&lt;/p&gt; 
&lt;h2&gt;8. Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;9. Contact&lt;/h2&gt; 
&lt;p&gt;If you have any questions, please raise an issue or contact us at &lt;a href=&quot;https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/main/service@deepseek.com&quot;&gt;service@deepseek.com&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>disposable-email-domains/disposable-email-domains</title>
      <link>https://github.com/disposable-email-domains/disposable-email-domains</link>
      <description>&lt;p&gt;a list of disposable email domains&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;List of disposable email domains&lt;/h1&gt; 
&lt;p&gt;This repo contains a &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/disposable_email_blocklist.conf&quot;&gt;list of disposable and temporary email address domains&lt;/a&gt; often used to register dummy users in order to spam or abuse some services.&lt;/p&gt; 
&lt;p&gt;We cannot guarantee all of these can still be considered disposable but we do basic checking so chances are they were disposable at one point in time.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;One of the most impactful mechanisms we currently have is prohibiting known &quot;throw-away&quot; email domains from creating accounts on the index. We currently use the &lt;code&gt;disposable-email-domains&lt;/code&gt; list as well as our own internal list to block registration with －or association of － such domains for PyPI accounts.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;-- Ee Durbin, PyPI Admin, Director of Infrastructure (PSF) &lt;a href=&quot;https://blog.pypi.org/posts/2024-06-16-prohibiting-msn-emails/&quot;&gt;link&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Allowlist&lt;/h1&gt; 
&lt;p&gt;The file &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/allowlist.conf&quot;&gt;allowlist.conf&lt;/a&gt; gathers email domains that are often identified as disposable but in fact are not.&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Feel free to create PR with additions or request removal of some domain (with reasons).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Specifically, please cite in your PR where one can generate a disposable email address which uses that domain, so the maintainers can verify it.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Please add new disposable domains directly into &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/disposable_email_blocklist.conf&quot;&gt;disposable_email_blocklist.conf&lt;/a&gt; in the same format (only second level domains on new line without @), then run &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/maintain.sh&quot;&gt;maintain.sh&lt;/a&gt;. The shell script will help you convert uppercase to lowercase, sort, remove duplicates and remove allowlisted domains.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;You can copy, modify, distribute and use the work, even for commercial purposes, all without asking permission.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://creativecommons.org/publicdomain/zero/1.0/&quot;&gt;&lt;img src=&quot;https://licensebuttons.net/p/zero/1.0/88x31.png&quot; alt=&quot;Licensed under CC0&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Changelog&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;1/9/25 Enabled &lt;a href=&quot;https://github.com/sponsors/disposable-email-domains&quot;&gt;GitHub sponsorhip&lt;/a&gt; for this work. Everybody can do it, but currently only one person does it. Send them $2 for a coffee if you care.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2/11/21 We created a github &lt;a href=&quot;https://github.com/disposable-email-domains&quot;&gt;org account&lt;/a&gt; and transferred the repository to it.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;4/18/19 &lt;a href=&quot;https://github.com/di&quot;&gt;@di&lt;/a&gt; &lt;a href=&quot;https://github.com/martenson/disposable-email-domains/issues/205&quot;&gt;joined&lt;/a&gt; as a core maintainer of this project. Thank you!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;7/31/17 &lt;a href=&quot;https://github.com/deguif&quot;&gt;@deguif&lt;/a&gt; &lt;a href=&quot;https://github.com/martenson/disposable-email-domains/issues/106&quot;&gt;joined&lt;/a&gt; as a core maintainer of this project. Thanks!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;12/6/16 - Available as &lt;a href=&quot;https://pypi.org/project/disposable-email-domains&quot;&gt;PyPI module&lt;/a&gt; thanks to &lt;a href=&quot;https://github.com/di&quot;&gt;@di&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;7/27/16 - Converted all domains to the second level. This means that starting from &lt;a href=&quot;https://github.com/martenson/disposable-email-domains/commit/61ae67aacdab0b19098de2e13069d7c35b74017a&quot;&gt;this commit&lt;/a&gt; the implementers should take care of matching the second level domain names properly i.e. &lt;code&gt;@xxx.yyy.zzz&lt;/code&gt; should match &lt;code&gt;yyy.zzz&lt;/code&gt; in blocklist where &lt;code&gt;zzz&lt;/code&gt; is a &lt;a href=&quot;https://publicsuffix.org/&quot;&gt;public suffix&lt;/a&gt;. More info in &lt;a href=&quot;https://github.com/martenson/disposable-email-domains/issues/46&quot;&gt;#46&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;9/2/14 - First commit &lt;a href=&quot;https://github.com/disposable-email-domains/disposable-email-domains/commit/393c21f56b5186f8db7d197b11cf1d7c5490a6f9&quot;&gt;393c21f5&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Example Usage&lt;/h1&gt; 
&lt;p&gt;TOC: &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#python&quot;&gt;Python&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#php&quot;&gt;PHP&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#go&quot;&gt;Go&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#ruby-on-rails&quot;&gt;Ruby on Rails&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#nodejs&quot;&gt;NodeJS&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#c&quot;&gt;C#&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#bash&quot;&gt;bash&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#java&quot;&gt;Java&lt;/a&gt;, &lt;a href=&quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/main/#swift&quot;&gt;Swift&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-Python&quot;&gt;with open(&#39;disposable_email_blocklist.conf&#39;) as blocklist:
    blocklist_content = {line.rstrip() for line in blocklist.readlines()}
if email.partition(&#39;@&#39;)[2] in blocklist_content:
    message = &quot;Please enter your permanent email address.&quot;
    return (False, message)
else:
    return True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Available as &lt;a href=&quot;https://pypi.org/project/disposable-email-domains&quot;&gt;PyPI module&lt;/a&gt; thanks to &lt;a href=&quot;https://github.com/di&quot;&gt;@di&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;&amp;gt;&amp;gt;&amp;gt; from disposable_email_domains import blocklist
&amp;gt;&amp;gt;&amp;gt; &#39;bearsarefuzzy.com&#39; in blocklist
True
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;PHP&lt;/h3&gt; 
&lt;p&gt;contributed by &lt;a href=&quot;https://github.com/txt3rob&quot;&gt;@txt3rob&lt;/a&gt;, &lt;a href=&quot;https://github.com/deguif&quot;&gt;@deguif&lt;/a&gt;, &lt;a href=&quot;https://github.com/pjebs&quot;&gt;@pjebs&lt;/a&gt; and &lt;a href=&quot;https://github.com/Wruczek&quot;&gt;@Wruczek&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure the passed email is valid. You can check that with &lt;a href=&quot;https://secure.php.net/manual/en/function.filter-var.php&quot;&gt;filter_var&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Make sure you have the mbstring extension installed on your server&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class=&quot;language-php&quot;&gt;function isDisposableEmail($email, $blocklist_path = null) {
    if (!$blocklist_path) $blocklist_path = __DIR__ . &#39;/disposable_email_blocklist.conf&#39;;
    $disposable_domains = file($blocklist_path, FILE_IGNORE_NEW_LINES | FILE_SKIP_EMPTY_LINES);
    $domain = mb_strtolower(explode(&#39;@&#39;, trim($email))[1]);
    return in_array($domain, $disposable_domains);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively check out Composer package &lt;a href=&quot;https://github.com/elliotjreed/disposable-emails-filter-php&quot;&gt;https://github.com/elliotjreed/disposable-emails-filter-php&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;p&gt;contributed by &lt;a href=&quot;https://github.com/pjebs&quot;&gt;@pjebs&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;import (&quot;bufio&quot;; &quot;os&quot;; &quot;strings&quot;;)
var disposableList = make(map[string]struct{}, 3500)
func init() {
	f, _ := os.Open(&quot;disposable_email_blocklist.conf&quot;)
	for scanner := bufio.NewScanner(f); scanner.Scan(); {
		disposableList[scanner.Text()] = struct{}{}
	}
	f.Close()
}

func isDisposableEmail(email string) (disposable bool) {
	segs := strings.Split(email, &quot;@&quot;)
	_, disposable = disposableList[strings.ToLower(segs[len(segs)-1])]
	return
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively check out Go package &lt;a href=&quot;https://github.com/rocketlaunchr/anti-disposable-email&quot;&gt;https://github.com/rocketlaunchr/anti-disposable-email&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Ruby on Rails&lt;/h3&gt; 
&lt;p&gt;contributed by &lt;a href=&quot;https://github.com/MitsunChieh&quot;&gt;@MitsunChieh&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;In the resource model, usually it is &lt;code&gt;user.rb&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-Ruby&quot;&gt;before_validation :reject_email_blocklist

def reject_email_blocklist
  blocklist = File.read(&#39;config/disposable_email_blocklist.conf&#39;).split(&quot;\n&quot;)

  if blocklist.include?(email.split(&#39;@&#39;)[1])
 &amp;nbsp; &amp;nbsp;errors[:email] &amp;lt;&amp;lt; &#39;invalid email&#39;
    return false
  else
    return true
  end
end
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Node.js&lt;/h3&gt; 
&lt;p&gt;contributed by &lt;a href=&quot;https://github.com/boywithkeyboard&quot;&gt;@boywithkeyboard&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-js&quot;&gt;import { readFile } from &#39;node:fs/promises&#39;

let blocklist

async function isDisposable(email) {
  if (!blocklist) {
    const content = await readFile(&#39;disposable_email_blocklist.conf&#39;, { encoding: &#39;utf-8&#39; })

    blocklist = content.split(&#39;\r\n&#39;).slice(0, -1)
  }

  return blocklist.includes(email.split(&#39;@&#39;)[1])
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively check out NPM package &lt;a href=&quot;https://github.com/mziyut/disposable-email-domains-js&quot;&gt;https://github.com/mziyut/disposable-email-domains-js&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;C#&lt;/h3&gt; 
&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;private static readonly Lazy&amp;lt;HashSet&amp;lt;string&amp;gt;&amp;gt; _emailBlockList = new Lazy&amp;lt;HashSet&amp;lt;string&amp;gt;&amp;gt;(() =&amp;gt;
{
  var lines = File.ReadLines(&quot;disposable_email_blocklist.conf&quot;)
    .Where(line =&amp;gt; !string.IsNullOrWhiteSpace(line) &amp;amp;&amp;amp; !line.TrimStart().StartsWith(&quot;//&quot;));
  return new HashSet&amp;lt;string&amp;gt;(lines, StringComparer.OrdinalIgnoreCase);
});

private static bool IsBlocklisted(string domain) =&amp;gt; _emailBlockList.Value.Contains(domain);

...

var addr = new MailAddress(email);
if (IsBlocklisted(addr.Host)))
  throw new ApplicationException(&quot;Email is blocklisted.&quot;);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Bash&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;#!/bin/bash

# This script checks if an email address is temporary.

# Read blocklist file into a bash array
mapfile -t blocklist &amp;lt; disposable_email_blocklist.conf

# Check if email domain is in blocklist
if [[ &quot; ${blocklist[@]} &quot; =~ &quot; ${email#*@} &quot; ]]; then
    message=&quot;Please enter your permanent email address.&quot;
    return_value=false
else
    return_value=true
fi

# Return result
echo &quot;$return_value&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Java&lt;/h3&gt; 
&lt;p&gt;Code assumes that you have added &lt;code&gt;disposable_email_blocklist.conf&lt;/code&gt; next to your class as classpath resource.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-Java&quot;&gt;private static final Set&amp;lt;String&amp;gt; DISPOSABLE_EMAIL_DOMAINS;

static {
    Set&amp;lt;String&amp;gt; domains = new HashSet&amp;lt;&amp;gt;();
    try (BufferedReader in = new BufferedReader(
            new InputStreamReader(
                EMailChecker.class.getResourceAsStream(&quot;disposable_email_blocklist.conf&quot;), StandardCharsets.UTF_8))) {
        String line;
        while ((line = in.readLine()) != null) {
            line = line.trim();
            if (line.isEmpty()) {
                continue;
            }
            
            domains.add(line);
        }
    } catch (IOException ex) {
        LOG.error(&quot;Failed to load list of disposable email domains.&quot;, ex);
    }
    DISPOSABLE_EMAIL_DOMAINS = domains;
}

public static boolean isDisposable(String email) throws AddressException {
    InternetAddress contact = new InternetAddress(email);
    return isDisposable(contact);
}

public static boolean isDisposable(InternetAddress contact) throws AddressException {
    String address = contact.getAddress();
    int domainSep = address.indexOf(&#39;@&#39;);
    String domain = (domainSep &amp;gt;= 0) ? address.substring(domainSep + 1) : address;
    return DISPOSABLE_EMAIL_DOMAINS.contains(domain);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Swift&lt;/h3&gt; 
&lt;p&gt;contributed by &lt;a href=&quot;https://github.com/1998code&quot;&gt;@1998code&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-swift&quot;&gt;func checkBlockList(email: String, completion: @escaping (Bool) -&amp;gt; Void) {
    let url = URL(string: &quot;https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/master/disposable_email_blocklist.conf&quot;)!
    let task = URLSession.shared.dataTask(with: url) { data, response, error in
        if let data = data {
            if let string = String(data: data, encoding: .utf8) {
                let lines = string.components(separatedBy: &quot;\n&quot;)
                for line in lines {
                    if email.contains(line) {
                        completion(true)
                        return
                    }
                }
            }
        }
        completion(false)
    }
    task.resume()
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>chengazhen/cursor-auto-free</title>
      <link>https://github.com/chengazhen/cursor-auto-free</link>
      <description>&lt;p&gt;auto sign cursor&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cursor Pro 自动化工具使用说明&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/chengazhen/cursor-auto-free/main/README.EN.md&quot;&gt;English doc&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;在线文档&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://cursor-auto-free-doc.vercel.app&quot;&gt;cursor-auto-free-doc.vercel.app&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;公众号 回复 1 获取 qq 群&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/chengazhen/cursor-auto-free/main/screen/qrcode_for_gh_c985615b5f2b_258.jpg&quot; alt=&quot;公众号&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;英文名字集&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/toniprada/usa-names-dataset&quot;&gt;https://github.com/toniprada/usa-names-dataset&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;许可证声明&lt;/h2&gt; 
&lt;p&gt;本项目采用 &lt;a href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC BY-NC-ND 4.0&lt;/a&gt; 许可证。 这意味着您可以：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;分享 — 在任何媒介以任何形式复制、发行本作品 但必须遵守以下条件：&lt;/li&gt; 
 &lt;li&gt;非商业性使用 — 您不得将本作品用于商业目的&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;声明&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;本项目仅供学习交流使用，请勿用于商业用途。&lt;/li&gt; 
 &lt;li&gt;本项目不承担任何法律责任，使用本项目造成的任何后果，由使用者自行承担。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;骗子&lt;/h2&gt; 
&lt;p&gt;海豚&lt;/p&gt; 
&lt;h2&gt;感谢 linuxDo 这个开源社区(一个真正的技术社区)&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://linux.do/&quot;&gt;https://linux.do/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;特别鸣谢&lt;/h2&gt; 
&lt;p&gt;本项目的开发过程中得到了众多开源项目和社区成员的支持与帮助，在此特别感谢：&lt;/p&gt; 
&lt;h3&gt;开源项目&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/yuaotian/go-cursor-help&quot;&gt;go-cursor-help&lt;/a&gt; - 一个优秀的 Cursor 机器码重置工具，本项目的机器码重置功能使用该项目实现。该项目目前已获得 9.1k Stars，是最受欢迎的 Cursor 辅助工具之一。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;请我喝杯茶 | buy me a cup of tea&lt;/h2&gt; 
&lt;img src=&quot;https://raw.githubusercontent.com/chengazhen/cursor-auto-free/main/screen/image.png&quot; width=&quot;300&quot;&gt; 
&lt;img src=&quot;https://raw.githubusercontent.com/chengazhen/cursor-auto-free/main/screen/28613e3f3f23a935b66a7ba31ff4e3f.jpg&quot; width=&quot;300&quot;&gt; 
&lt;img src=&quot;https://raw.githubusercontent.com/chengazhen/cursor-auto-free/main/screen/mm_facetoface_collect_qrcode_1738583247120.png&quot; width=&quot;300&quot;&gt;</description>
    </item>
    
  </channel>
</rss>
