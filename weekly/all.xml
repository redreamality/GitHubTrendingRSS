<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="data:text/xsl;base64,<?xml version="1.0" encoding="utf-8"?><xsl:stylesheet version="3.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform" xmlns:atom="http://www.w3.org/2005/Atom"><xsl:output method="html" version="1.0" encoding="UTF-8" indent="yes"/><xsl:template match="/"><xsl:variable name="title"><xsl:value-of select="/rss/channel/title"/></xsl:variable><xsl:variable name="description"><xsl:value-of select="/rss/channel/description"/></xsl:variable><xsl:variable name="link"><xsl:value-of select="/rss/channel/link"/></xsl:variable><html class="dark scroll-smooth"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="referrer" content="unsafe-url"/><title><xsl:value-of select="$title"/></title><style>*,:after,:before{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: ;--tw-contain-size: ;--tw-contain-layout: ;--tw-contain-paint: ;--tw-contain-style: }::backdrop{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: ;--tw-contain-size: ;--tw-contain-layout: ;--tw-contain-paint: ;--tw-contain-style: }
        
        /*! tailwindcss v3.4.17 | MIT License | https://tailwindcss.com*/*,:after,:before{box-sizing:border-box;border:0 solid #e7e7f0}:after,:before{--tw-content:""}:host,html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;-o-tab-size:4;tab-size:4;font-family:ui-sans-serif,system-ui,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;font-feature-settings:normal;font-variation-settings:normal;-webkit-tap-highlight-color:transparent}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-feature-settings:normal;font-variation-settings:normal;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit;border-collapse:collapse}button,input,optgroup,select,textarea{font-family:inherit;font-feature-settings:inherit;font-variation-settings:inherit;font-size:100%;font-weight:inherit;line-height:inherit;letter-spacing:inherit;color:inherit;margin:0;padding:0}button,select{text-transform:none}button,input:where([type=button]),input:where([type=reset]),input:where([type=submit]){-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}fieldset{margin:0}fieldset,legend{padding:0}menu,ol,ul{list-style:none;margin:0;padding:0}dialog{padding:0}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{opacity:1;color:#a8a8b8}input::placeholder,textarea::placeholder{opacity:1;color:#a8a8b8}[role=button],button{cursor:pointer}:disabled{cursor:default}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}[hidden]:where(:not([hidden=until-found])){display:none}:root{--card-radius:0.75rem;--btn-radius:var(--card-radius);--badge-radius:var(--btn-radius);--input-radius:var(--btn-radius);--avatar-radius:9999px;--annonce-radius:var(--avatar-radius);--ui-border-color:#1f1f31;--btn-border:#1f1f31;--badge-border:var(--btn-border);--input-border:var(--ui-border-color);--ui-disabled-border:#121220;--ui-error-border:#e11d48;--ui-success-border:#65a30d;--input-outline:#4f46e5;--ui-bg:rgb(18 18 32/var(--ui-bg-opacity));--ui-soft-bg:#1f1f31;--overlay-bg:rgba(2,2,13,.25);--input-bg:var(--ui-soft-bg);--ui-disabled-bg:#121220;--card-padding:1.5rem;--display-text-color:#fff;--title-text-color:var(--display-text-color);--body-text-color:#d6d6e1;--caption-text-color:#6e6e81;--placeholder-text-color:#4d4d5f;--ui-bg-opacity:1;color:var(--body-text-color)}*,.border{border-color:var(--ui-border-color)}button:disabled{border:none!important;background:var(--ui-disabled-bg)!important;background-image:none!important;box-shadow:none!important;color:var(--placeholder-text-color)!important;pointer-events:none!important}button:disabled:before{content:var(--tw-content);display:none}a:focus-visible,button:focus-visible{outline-width:2px;outline-offset:2px;outline-color:#4f46e5}a:focus-visible:focus-visible,button:focus-visible:focus-visible{outline-style:solid}input:user-invalid,select:user-invalid,textarea:user-invalid{--input-border:var(--ui-error-border);--ui-border-color:var(--ui-error-border);--input-outline:var(--ui-error-border);--title-text-color:#fb7185}[data-rounded=none]{--card-radius:0px;--avatar-radius:0px}[data-rounded=default]{--card-radius:0.25rem}[data-rounded=small]{--card-radius:0.125rem}[data-rounded=medium]{--card-radius:0.375rem}[data-rounded=large]{--card-radius:0.5rem}[data-rounded=xlarge]{--card-radius:0.75rem}[data-rounded="2xlarge"]{--card-radius:1rem;--input-radius:0.75rem}[data-rounded="3xlarge"]{--card-radius:1.5rem;--input-radius:0.75rem}[data-rounded=full]{--card-radius:1.5rem;--btn-radius:9999px;--input-radius:1rem}[data-shade=glassy]{--ui-bd-blur:40px;--ui-bg-opacity:0.75;--ui-bg:rgb(58 58 75/var(--ui-bg-opacity));--ui-border-color:rgba(250,250,254,.1);--ui-soft-bg:rgba(77,77,95,.5)}[data-shade="800"]{--ui-border-color:#3a3a4b;--ui-bg:#1f1f31;--ui-soft-bg:#121220}[data-shade="900"]{--ui-border-color:#1f1f31;--ui-bg:#121220;--ui-soft-bg:#1f1f31}[data-shade="950"]{--ui-border-color:#1f1f31;--ui-bg:#02020d;--ui-soft-bg:#1f1f31}.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}@media (min-width:1536px){.container{max-width:1536px}}.icon-\[tabler--rss\]{display:inline-block;width:1em;height:1em;background-color:currentColor;-webkit-mask-image:var(--svg);mask-image:var(--svg);-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;--svg:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24'%3E%3Cpath fill='none' stroke='%23000' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' d='M4 19a1 1 0 1 0 2 0 1 1 0 1 0-2 0M4 4a16 16 0 0 1 16 16M4 11a9 9 0 0 1 9 9'/%3E%3C/svg%3E")}.link{--tw-text-opacity:1;color:rgb(129 140 248/var(--tw-text-opacity,1));transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}.link.variant-ghost:hover,.link.variant-underlined{text-decoration-line:underline}.link.variant-animated{position:relative}.link.variant-animated:before{position:absolute;left:0;right:0;bottom:0;height:1px;transform-origin:right;--tw-scale-x:0;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);content:var(--tw-content);transition-duration:.2s}.link.variant-animated:hover:before{transform-origin:left;content:var(--tw-content);--tw-scale-x:1;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.link.intent-info{--tw-text-opacity:1;color:rgb(96 165 250/var(--tw-text-opacity,1))}.link.intent-neutral{--tw-text-opacity:1;color:rgb(255 255 255/var(--tw-text-opacity,1))}.link.variant-animated.intent-neutral:before{content:var(--tw-content);background-color:hsla(0,0%,100%,.5)}.link.variant-animated.intent-info:before{content:var(--tw-content);--tw-bg-opacity:1;background-color:rgb(37 99 235/var(--tw-bg-opacity,1))}.link.variant-animated.intent-primary:before{content:var(--tw-content);--tw-bg-opacity:1;background-color:rgb(79 70 229/var(--tw-bg-opacity,1))}.link.variant-ghost.intent-neutral,.link.variant-underlined.intent-neutral{text-decoration-color:hsla(0,0%,100%,.5)}.mx-auto{margin-left:auto;margin-right:auto}.my-2{margin-top:.5rem;margin-bottom:.5rem}.my-6{margin-top:1.5rem;margin-bottom:1.5rem}.mb-2{margin-bottom:.5rem}.mb-6{margin-bottom:1.5rem}.mb-8{margin-bottom:2rem}.ml-1{margin-left:.25rem}.ml-4{margin-left:1rem}.mr-2{margin-right:.5rem}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mt-3{margin-top:.75rem}.block{display:block}.inline-block{display:inline-block}.inline{display:inline}.flex{display:flex}.grid{display:grid}.hidden{display:none}.h-4{height:1rem}.h-8{height:2rem}.min-h-screen{min-height:100vh}.min-h-svh{min-height:100svh}.w-4{width:1rem}.w-8{width:2rem}.max-w-full{max-width:100%}.max-w-screen-lg{max-width:1024px}.flex-1{flex:1 1 0%}.cursor-pointer{cursor:pointer}.list-disc{list-style-type:disc}.grid-cols-1{grid-template-columns:repeat(1,minmax(0,1fr))}.flex-col{flex-direction:column}.items-center{align-items:center}.justify-between{justify-content:space-between}.gap-4{gap:1rem}.gap-6{gap:1.5rem}.gap-8{gap:2rem}.space-y-2>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(.5rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(.5rem*var(--tw-space-y-reverse))}.space-y-3>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(.75rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(.75rem*var(--tw-space-y-reverse))}.space-y-4>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(1rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(1rem*var(--tw-space-y-reverse))}.space-y-6>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(1.5rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(1.5rem*var(--tw-space-y-reverse))}.scroll-smooth{scroll-behavior:smooth}.truncate{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.bg-gray-925{--tw-bg-opacity:1;background-color:rgb(9 9 21/var(--tw-bg-opacity,1))}.bg-gradient-to-r{background-image:linear-gradient(to right,var(--tw-gradient-stops))}.from-primary-600{--tw-gradient-from:#4f46e5 var(--tw-gradient-from-position);--tw-gradient-to:rgba(79,70,229,0) var(--tw-gradient-to-position);--tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to)}.to-accent-400{--tw-gradient-to:#e879f9 var(--tw-gradient-to-position)}.bg-clip-text{-webkit-background-clip:text;background-clip:text}.p-1{padding:.25rem}.px-4{padding-left:1rem;padding-right:1rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.py-4{padding-top:1rem;padding-bottom:1rem}.py-6{padding-top:1.5rem;padding-bottom:1.5rem}.pl-5{padding-left:1.25rem}.pt-2{padding-top:.5rem}.text-center{text-align:center}.font-sans{font-family:ui-sans-serif,system-ui,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}.text-2xl{font-size:1.5rem;line-height:2rem}.text-lg{font-size:1.125rem;line-height:1.75rem}.text-sm{font-size:.875rem;line-height:1.25rem}.text-xs{font-size:.75rem;line-height:1rem}.font-bold{font-weight:700}.font-medium{font-weight:500}.font-semibold{font-weight:600}.leading-normal{line-height:1.5}.text-gray-400{--tw-text-opacity:1;color:rgb(168 168 184/var(--tw-text-opacity,1))}.text-gray-500{--tw-text-opacity:1;color:rgb(110 110 129/var(--tw-text-opacity,1))}.text-transparent{color:transparent}.antialiased{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.transition{transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}.text-title{color:var(--title-text-color)}.text-body{color:var(--body-text-color)}.\!text-caption{color:var(--caption-text-color)!important}.text-caption{color:var(--caption-text-color)}.dark{--display-text-color:#fff;--title-text-color:var(--display-text-color);--caption-text-color:#6e6e81;--body-text-color:#d6d6e1;--placeholder-text-color:#4d4d5f;--ui-border-color:#232323}[data-shade="900"]:where(.dark,.dark *),[data-shade="925"]:where(.dark,.dark *),[data-shade="950"]:where(.dark,.dark *){--ui-border-color:#383838}.hover\:text-gray-300:hover{--tw-text-opacity:1;color:rgb(214 214 225/var(--tw-text-opacity,1))}.group[open] .group-open\:rotate-180{--tw-rotate:180deg;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}@media (min-width:768px){.md\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.md\:p-4{padding:1rem}.md\:px-6{padding-left:1.5rem;padding-right:1.5rem}.md\:pt-6{padding-top:1.5rem}}@media (min-width:1024px){.lg\:grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}.lg\:dark\:bg-gray-900:is(.dark *){--tw-bg-opacity:1;background-color:rgb(18 18 32/var(--tw-bg-opacity,1))}}</style></head><body class="bg-gray-925 min-h-screen min-h-svh font-sans leading-normal antialiased lg:dark:bg-gray-900"><main class="min-w-screen container mx-auto flex min-h-screen max-w-screen-lg flex-col px-4 py-6 md:px-6"><header class="space-y-2 pt-2 md:pt-6"><a title="{$title}" href="{$link}" target="_blank" rel="noopener noreferrer"><h1 class="flex text-2xl"><span class="icon-[tabler--rss] mr-2 h-8 w-8"/><span class="lg2:text-3xl from-primary-600 to-accent-400 inline-block bg-gradient-to-r bg-clip-text font-bold text-transparent"><xsl:value-of select="$title" disable-output-escaping="yes"/></span></h1></a><p class="text-body pt-2 text-lg py-4"><xsl:value-of select="$description" disable-output-escaping="yes"/></p><p class="text-caption text-sm">
              This RSS feed for the
              <a class="link intent-neutral variant-animated !text-caption font-bold" title="{$title}" href="{$link}" target="_blank" rel="noopener noreferrer"><xsl:value-of select="$title"/></a>
              website.
            </p><p class="text-body text-sm hidden" id="subscribe-links">
              You can subscribe this RSS feed by
              <a class="link intent-neutral variant-animated font-bold" title="Feedly" data-href="https://feedly.com/i/subscription/feed/" target="_blank" rel="noopener noreferrer">Feedly</a>,
              <a class="link intent-neutral variant-animated font-bold" title="Inoreader" data-href="https://www.inoreader.com/feed/" target="_blank" rel="noopener noreferrer">Inoreader</a>,
              <a class="link intent-neutral variant-animated font-bold" title="Newsblur" data-href="https://www.newsblur.com/?url=" target="_blank" rel="noopener noreferrer">Newsblur</a>,
              <a class="link intent-neutral variant-animated font-bold" title="Follow" data-href="follow://add?url=" rel="noopener noreferrer">Follow</a>,
              <a class="link intent-neutral variant-animated font-bold" title="RSS Reader" data-href="feed:" data-raw="true" rel="noopener noreferrer">RSS Reader</a>
              or
              <a class="link intent-neutral variant-animated font-bold" title="{$title} 's feed source" data-href="" data-raw="true" rel="noopener noreferrer">View Source</a>.
            </p><script>
              document.addEventListener('DOMContentLoaded', function () {
                document.querySelectorAll('a[data-href]').forEach(function (a) {
                  const url = new URL(location.href)
                  const feed = url.searchParams.get('url') || location.href
                  const raw = a.getAttribute('data-raw')
                  if (raw) {
                    a.href = a.getAttribute('data-href') + feed
                  } else {
                    a.href = a.getAttribute('data-href') + encodeURIComponent(feed)
                  }
                })
                document.getElementById('subscribe-links').classList.remove('hidden')
              })
            </script></header><hr class="my-6"/><section class="flex-1 space-y-6 p-1 md:p-4"><xsl:choose><xsl:when test="/rss/channel/item"><xsl:for-each select="/rss/channel/item"><article class="space-y-2"><details><summary class="max-w-full truncate"><xsl:if test="title"><h2 class="text-title inline cursor-pointer text-lg font-semibold"><xsl:value-of select="title" disable-output-escaping="yes"/></h2></xsl:if><xsl:if test="pubDate"><time class="text-caption ml-4 mt-1 block text-sm"><xsl:value-of select="pubDate"/></time></xsl:if></summary><div class="text-body px-4 py-2"><p class="my-2"><xsl:choose><xsl:when test="description"><xsl:value-of select="description" disable-output-escaping="yes"/></xsl:when></xsl:choose></p><xsl:if test="link"><a class="link variant-animated intent-neutral font-bold" href="{link}" target="_blank" rel="noopener noreferrer">
                            Read More
                          </a></xsl:if></div></details></article></xsl:for-each></xsl:when><xsl:when test="/atom:feed/atom:entry"><xsl:for-each select="/atom:feed/atom:entry"><article class="space-y-2"><details><summary class="max-w-full truncate"><xsl:if test="atom:title"><h2 class="text-title inline cursor-pointer text-lg font-semibold"><xsl:value-of select="atom:title" disable-output-escaping="yes"/></h2></xsl:if><xsl:if test="atom:updated"><time class="text-caption ml-4 mt-1 block text-sm"><xsl:value-of select="atom:updated"/></time></xsl:if></summary><div class="text-body px-4 py-2"><p class="my-2"><xsl:choose><xsl:when test="atom:summary"><xsl:value-of select="atom:summary" disable-output-escaping="yes"/></xsl:when><xsl:when test="atom:content"><xsl:value-of select="atom:content" disable-output-escaping="yes"/></xsl:when></xsl:choose></p><xsl:if test="atom:link/@href"><a class="link variant-animated intent-neutral font-bold" href="{atom:link/@href}" target="_blank" rel="noopener noreferrer">
                            Read More
                          </a></xsl:if></div></details></article></xsl:for-each></xsl:when></xsl:choose></section><hr class="my-6"/><footer class="text-gray-400"><div class="container mx-auto px-4"><div class="mb-8"><h3 class="text-lg font-semibold text-title mb-6">Popular Feed Collections</h3><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6"><div class="space-y-3"><a href="https://redreamality.com/GitHubTrendingRSS/weekly/python.xml" class="block hover:text-gray-300"><div class="font-medium">🐍 Python TrendWatch</div><div class="text-xs text-gray-500">AI, ML &amp; Data Science Innovation Feed</div></a><a href="https://redreamality.com/GitHubTrendingRSS/weekly/cuda.xml" class="block hover:text-gray-300"><div class="font-medium">⚡ CUDA Accelerator</div><div class="text-xs text-gray-500">GPU Computing &amp; Deep Learning Updates</div></a><a href="https://redreamality.com/GitHubTrendingRSS/weekly/matlab.xml" class="block hover:text-gray-300"><div class="font-medium">🧠 MATLAB TrendPulse</div><div class="text-xs text-gray-500">MEG, EEG and iEEG Research Feed</div></a></div><div class="space-y-3"><a href="https://redreamality.com/GitHubTrendingRSS/weekly/rust.xml" class="block hover:text-gray-300"><div class="font-medium">🦀 Rust Systems Feed</div><div class="text-xs text-gray-500">High-Performance &amp; Safe Systems Programming</div></a><a href="https://redreamality.com/GitHubTrendingRSS/weekly/go.xml" class="block hover:text-gray-300"><div class="font-medium">🚀 Go Infrastructure</div><div class="text-xs text-gray-500">Cloud Native &amp; DevOps Excellence</div></a><a href="https://redreamality.com/GitHubTrendingRSS/weekly/typescript.xml" class="block hover:text-gray-300"><div class="font-medium">📱 TypeScript Ecosystem</div><div class="text-xs text-gray-500">Modern Web &amp; App Development</div></a></div><div class="space-y-3"><a href="https://redreamality.com/GitHubTrendingRSS/daily/adblock-filter-list.xml" class="block hover:text-gray-300"><div class="font-medium">🛡️ Privacy Shield</div><div class="text-xs text-gray-500">AdBlock &amp; Security Updates</div></a><a href="https://redreamality.com/GitHubTrendingRSS/daily/all.xml" class="block hover:text-gray-300"><div class="font-medium">🌟 Global TechRadar</div><div class="text-xs text-gray-500">Cross-Language Innovation Pulse, add it to your RSS reader rsshub://github/trending/monthly/any/zh</div></a></div></div></div><div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-8"><div class="space-y-4"><h3 class="text-lg font-semibold text-title">Getting Started</h3><div class="grid grid-cols-1 gap-4"><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">📖 Feed Integration Guide</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">1. Choose Your RSS Reader:</p><ul class="list-disc pl-5 space-y-2"><li>Feedly: Professional choice for cross-platform sync</li><li>Inoreader: Advanced filtering capabilities</li><li>NetNewsWire: Perfect for macOS/iOS users</li><li>FreshRSS: Self-hosted option with full control</li></ul><p class="mt-3 mb-2">2. Add Our Feeds:</p><ul class="list-disc pl-5 space-y-2"><li>Copy the feed URL (e.g., rsshub://github/trending/monthly/any/zh)</li><li>In your RSS reader, look for "Add Feed" or "Subscribe"</li><li>Paste the URL and customize update frequency</li></ul></div></details><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">🎯 Custom Feed Creation</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Create Your Perfect Feed:</p><ul class="list-disc pl-5 space-y-2"><li>Language-specific: /GitHubTrendingRSS/[frequency]/[language].xml</li><li>Topic-focused: Combine multiple language feeds</li><li>Custom time ranges: daily, weekly, or monthly updates</li><li>Regional feeds: Focus on specific developer communities</li></ul><p class="mt-3">Pro tip: Use tags in your RSS reader to organize feeds by topic, language, or priority.</p></div></details><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">⚡ Feed Management Tips</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Optimize Your Feed Reading:</p><ul class="list-disc pl-5 space-y-2"><li>Set update frequencies based on feed importance</li><li>Use folders to group related feeds (e.g., AI/ML, Web Dev)</li><li>Enable notifications only for high-priority feeds</li><li>Archive valuable resources for future reference</li></ul><p class="mt-3">Advanced Features:</p><ul class="list-disc pl-5 space-y-2"><li>Filter feeds using keywords to focus on specific topics</li><li>Set up IFTTT integrations for automated workflows</li><li>Export/backup your feed collection regularly</li></ul></div></details></div></div><div class="space-y-4"><h3 class="text-lg font-semibold text-title">Common Questions</h3><div class="grid grid-cols-1 gap-4"><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">🤔 About Github Radar</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Github Radar is your intelligent curator for:</p><ul class="list-disc pl-5 space-y-2"><li>Trending repositories across all programming languages</li><li>Language-specific innovation and updates</li><li>Regional development trends and patterns</li><li>Open source community movements</li></ul><p class="mt-3">Our mission is to help developers stay updated with minimal effort through smart feed curation and organization.</p></div></details><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">📊 Feed Frequency Options</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Choose Your Update Rhythm:</p><ul class="list-disc pl-5 space-y-2"><li>Daily: Perfect for fast-moving technologies and security updates</li><li>Weekly: Ideal for maintaining awareness without overwhelm</li><li>Monthly: Best for long-term trend analysis and strategic planning</li></ul><p class="mt-3">Customize by combining different frequencies for different topics based on your needs.</p></div></details><details class="group"><summary class="flex cursor-pointer items-center justify-between hover:text-gray-300"><h4 class="font-medium">🔧 Technical Support</h4><span class="transition group-open:rotate-180"><svg fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24"><path d="M6 9l6 6 6-6"/></svg></span></summary><div class="text-sm text-gray-500 mt-3 group-open:animate-fadeIn"><p class="mb-2">Supported RSS Readers:</p><ul class="list-disc pl-5 space-y-2"><li>Desktop: NetNewsWire, Reeder, FeedReader</li><li>Mobile: Feedly, Inoreader, NewsBlur</li><li>Self-hosted: FreshRSS, Tiny Tiny RSS</li><li>Browser-based: Feedbro, RSS Feed Reader</li></ul><p class="mt-3">Common Issues:</p><ul class="list-disc pl-5 space-y-2"><li>Feed not updating? Check your reader's refresh settings</li><li>Missing content? Verify your internet connection</li><li>Format issues? Try re-subscribing to the feed</li></ul></div></details></div></div></div><div class="text-center text-sm"><p class="mt-2">Acknowledgement: Page decorated by <a href="https://github.com/ccbikai/RSS.Beauty"><svg class="inline-block w-4 h-4 ml-1" viewBox="0 0 16 16" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg></a> RSS.Beauty</p></div></div></footer></main></body></html></xsl:template></xsl:stylesheet>"?>
<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Sat, 29 Mar 2025 02:30:41 GMT</pubDate>
    <link>http://redreamality.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>ourongxing/newsnow</title>
      <link>https://github.com/ourongxing/newsnow</link>
      <description>&lt;p&gt;Elegant reading of real-time and hottest news&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NewsNow&lt;/h1&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ourongxing/newsnow/main/screenshots/preview-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ourongxing/newsnow/main/screenshots/preview-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;p&gt;English | &lt;a href=&quot;https://raw.githubusercontent.com/ourongxing/newsnow/main/README.zh-CN.md&quot;&gt;简体中文&lt;/a&gt; | &lt;a href=&quot;https://raw.githubusercontent.com/ourongxing/newsnow/main/README.ja-JP.md&quot;&gt;日本語&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This is a demo version currently supporting Chinese only. A full-featured version with better customization and English content support will be released later.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Elegant reading of real-time and hottest news&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Clean and elegant UI design for optimal reading experience&lt;/li&gt; 
 &lt;li&gt;Real-time updates on trending news&lt;/li&gt; 
 &lt;li&gt;GitHub OAuth login with data synchronization&lt;/li&gt; 
 &lt;li&gt;30-minute default cache duration (logged-in users can force refresh)&lt;/li&gt; 
 &lt;li&gt;Adaptive scraping interval (minimum 2 minutes) based on source update frequency to optimize resource usage and prevent IP bans&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;h3&gt;Basic Deployment&lt;/h3&gt; 
&lt;p&gt;For deployments without login and caching:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork this repository&lt;/li&gt; 
 &lt;li&gt;Import to platforms like Cloudflare Page or Vercel&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Cloudflare Page Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Build command: &lt;code&gt;pnpm run build&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Output directory: &lt;code&gt;dist/output/public&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;GitHub OAuth Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/settings/applications/new&quot;&gt;Create a GitHub App&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;No special permissions required&lt;/li&gt; 
 &lt;li&gt;Set callback URL to: &lt;code&gt;https://your-domain.com/api/oauth/github&lt;/code&gt; (replace &lt;code&gt;your-domain&lt;/code&gt; with your actual domain)&lt;/li&gt; 
 &lt;li&gt;Obtain Client ID and Client Secret&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Refer to &lt;code&gt;example.env.server&lt;/code&gt;. For local development, rename it to &lt;code&gt;.env.server&lt;/code&gt; and configure:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-env&quot;&gt;# Github Client ID
G_CLIENT_ID=
# Github Client Secret
G_CLIENT_SECRET=
# JWT Secret, usually the same as Client Secret
JWT_SECRET=
# Initialize database, must be set to true on first run, can be turned off afterward
INIT_TABLE=true
# Whether to enable cache
ENABLE_CACHE=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Database Support&lt;/h3&gt; 
&lt;p&gt;Supported database connectors: &lt;a href=&quot;https://db0.unjs.io/connectors&quot;&gt;https://db0.unjs.io/connectors&lt;/a&gt; &lt;strong&gt;Cloudflare D1 Database&lt;/strong&gt; is recommended.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create D1 database in Cloudflare Worker dashboard&lt;/li&gt; 
 &lt;li&gt;Configure database_id and database_name in wrangler.toml&lt;/li&gt; 
 &lt;li&gt;If wrangler.toml doesn&#39;t exist, rename example.wrangler.toml and modify configurations&lt;/li&gt; 
 &lt;li&gt;Changes will take effect on next deployment&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Docker Deployment&lt;/h3&gt; 
&lt;p&gt;In project root directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;docker compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also set Environment Variables in &lt;code&gt;docker-compose.yml&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Requires Node.js &amp;gt;= 20&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;corepack enable
pnpm i
pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Adding Data Sources&lt;/h3&gt; 
&lt;p&gt;Refer to &lt;code&gt;shared/sources&lt;/code&gt; and &lt;code&gt;server/source&lt;/code&gt;s directories. The project provides complete type definitions and a clean architecture.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add &lt;strong&gt;multi-language support&lt;/strong&gt; (English, Chinese, more to come).&lt;/li&gt; 
 &lt;li&gt;Improve &lt;strong&gt;personalization options&lt;/strong&gt; (category-based news, saved preferences).&lt;/li&gt; 
 &lt;li&gt;Expand &lt;strong&gt;data sources&lt;/strong&gt; to cover global news in multiple languages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;release when ready&lt;/strong&gt;&lt;/em&gt; &lt;img src=&quot;https://testmnbbs.oss-cn-zhangjiakou.aliyuncs.com/pic/20250328172146_rec_.gif?x-oss-process=base_webp&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Feel free to submit pull requests or create issues for feature requests and bug reports.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ourongxing/newsnow/main/LICENSE&quot;&gt;MIT&lt;/a&gt; © ourongxing&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mark3labs/mcp-go</title>
      <link>https://github.com/mark3labs/mcp-go</link>
      <description>&lt;p&gt;A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MCP Go 🚀&lt;/h1&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/mark3labs/mcp-go/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/mark3labs/mcp-go/actions/workflows/ci.yml/badge.svg?branch=main&quot; alt=&quot;Build&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://goreportcard.com/report/github.com/mark3labs/mcp-go&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/mark3labs/mcp-go?cache&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pkg.go.dev/github.com/mark3labs/mcp-go&quot;&gt;&lt;img src=&quot;https://pkg.go.dev/badge/github.com/mark3labs/mcp-go.svg?sanitize=true&quot; alt=&quot;GoDoc&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;p&gt;&lt;strong&gt;A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?v=qoaeYMrXJH0&quot; title=&quot;Tutorial&quot;&gt;&lt;img src=&quot;http://img.youtube.com/vi/qoaeYMrXJH0/0.jpg&quot; alt=&quot;Tutorial&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
    &quot;context&quot;
    &quot;errors&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // Create MCP server
    s := server.NewMCPServer(
        &quot;Demo 🚀&quot;,
        &quot;1.0.0&quot;,
    )

    // Add tool
    tool := mcp.NewTool(&quot;hello_world&quot;,
        mcp.WithDescription(&quot;Say hello to someone&quot;),
        mcp.WithString(&quot;name&quot;,
            mcp.Required(),
            mcp.Description(&quot;Name of the person to greet&quot;),
        ),
    )

    // Add tool handler
    s.AddTool(tool, helloHandler)

    // Start the stdio server
    if err := server.ServeStdio(s); err != nil {
        fmt.Printf(&quot;Server error: %v\n&quot;, err)
    }
}

func helloHandler(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    name, ok := request.Params.Arguments[&quot;name&quot;].(string)
    if !ok {
        return nil, errors.New(&quot;name must be a string&quot;)
    }

    return mcp.NewToolResultText(fmt.Sprintf(&quot;Hello, %s!&quot;, name)), nil
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That&#39;s it!&lt;/p&gt; 
&lt;p&gt;MCP Go handles all the complex protocol details and server management, so you can focus on building great tools. It aims to be high-level and easy to use.&lt;/p&gt; 
&lt;h3&gt;Key features:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: High-level interface means less code and faster development&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple&lt;/strong&gt;: Build MCP servers with minimal boilerplate&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complete&lt;/strong&gt;*: MCP Go aims to provide a full implementation of the core MCP specification&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;(*emphasis on &lt;em&gt;aims&lt;/em&gt;)&lt;/p&gt; 
&lt;p&gt;🚨 🚧 🏗️ &lt;em&gt;MCP Go is under active development, as is the MCP specification itself. Core features are working but some advanced capabilities are still in progress.&lt;/em&gt;&lt;/p&gt; 
&lt;!-- omit in toc --&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#quickstart&quot;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#what-is-mcp&quot;&gt;What is MCP?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#core-concepts&quot;&gt;Core Concepts&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#server&quot;&gt;Server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#tools&quot;&gt;Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#prompts&quot;&gt;Prompts&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#examples&quot;&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#contributing&quot;&gt;Contributing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#prerequisites&quot;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#installation-1&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#testing&quot;&gt;Testing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/mark3labs/mcp-go/main/#opening-a-pull-request&quot;&gt;Opening a Pull Request&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;go get github.com/mark3labs/mcp-go
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Let&#39;s create a simple MCP server that exposes a calculator tool and some data:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;package main

import (
    &quot;context&quot;
    &quot;errors&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // Create a new MCP server
    s := server.NewMCPServer(
        &quot;Calculator Demo&quot;,
        &quot;1.0.0&quot;,
        server.WithResourceCapabilities(true, true),
        server.WithLogging(),
    )

    // Add a calculator tool
    calculatorTool := mcp.NewTool(&quot;calculate&quot;,
        mcp.WithDescription(&quot;Perform basic arithmetic operations&quot;),
        mcp.WithString(&quot;operation&quot;,
            mcp.Required(),
            mcp.Description(&quot;The operation to perform (add, subtract, multiply, divide)&quot;),
            mcp.Enum(&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;),
        ),
        mcp.WithNumber(&quot;x&quot;,
            mcp.Required(),
            mcp.Description(&quot;First number&quot;),
        ),
        mcp.WithNumber(&quot;y&quot;,
            mcp.Required(),
            mcp.Description(&quot;Second number&quot;),
        ),
    )

    // Add the calculator handler
    s.AddTool(calculatorTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
        op := request.Params.Arguments[&quot;operation&quot;].(string)
        x := request.Params.Arguments[&quot;x&quot;].(float64)
        y := request.Params.Arguments[&quot;y&quot;].(float64)

        var result float64
        switch op {
        case &quot;add&quot;:
            result = x + y
        case &quot;subtract&quot;:
            result = x - y
        case &quot;multiply&quot;:
            result = x * y
        case &quot;divide&quot;:
            if y == 0 {
                return nil, errors.New(&quot;Cannot divide by zero&quot;)
            }
            result = x / y
        }

        return mcp.NewToolResultText(fmt.Sprintf(&quot;%.2f&quot;, result)), nil
    })

    // Start the server
    if err := server.ServeStdio(s); err != nil {
        fmt.Printf(&quot;Server error: %v\n&quot;, err)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What is MCP?&lt;/h2&gt; 
&lt;p&gt;The &lt;a href=&quot;https://modelcontextprotocol.io&quot;&gt;Model Context Protocol (MCP)&lt;/a&gt; lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions. MCP servers can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Expose data through &lt;strong&gt;Resources&lt;/strong&gt; (think of these sort of like GET endpoints; they are used to load information into the LLM&#39;s context)&lt;/li&gt; 
 &lt;li&gt;Provide functionality through &lt;strong&gt;Tools&lt;/strong&gt; (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)&lt;/li&gt; 
 &lt;li&gt;Define interaction patterns through &lt;strong&gt;Prompts&lt;/strong&gt; (reusable templates for LLM interactions)&lt;/li&gt; 
 &lt;li&gt;And more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Core Concepts&lt;/h2&gt; 
&lt;h3&gt;Server&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Show Server Examples&lt;/summary&gt; 
 &lt;p&gt;The server is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Create a basic server
s := server.NewMCPServer(
    &quot;My Server&quot;,  // Server name
    &quot;1.0.0&quot;,     // Version
)

// Start the server using stdio
if err := server.ServeStdio(s); err != nil {
    log.Fatalf(&quot;Server error: %v&quot;, err)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Resources&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Show Resource Examples&lt;/summary&gt; Resources are how you expose data to LLMs. They can be anything - files, API responses, database queries, system information, etc. Resources can be: 
 &lt;ul&gt; 
  &lt;li&gt;Static (fixed URI)&lt;/li&gt; 
  &lt;li&gt;Dynamic (using URI templates)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Here&#39;s a simple example of a static resource:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Static resource example - exposing a README file
resource := mcp.NewResource(
    &quot;docs://readme&quot;,
    &quot;Project README&quot;,
    mcp.WithResourceDescription(&quot;The project&#39;s README file&quot;), 
    mcp.WithMIMEType(&quot;text/markdown&quot;),
)

// Add resource with its handler
s.AddResource(resource, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    content, err := os.ReadFile(&quot;README.md&quot;)
    if err != nil {
        return nil, err
    }
    
    return []mcp.ResourceContents{
        mcp.TextResourceContents{
            URI:      &quot;docs://readme&quot;,
            MIMEType: &quot;text/markdown&quot;,
            Text:     string(content),
        },
    }, nil
})
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;And here&#39;s an example of a dynamic resource using a template:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Dynamic resource example - user profiles by ID
template := mcp.NewResourceTemplate(
    &quot;users://{id}/profile&quot;,
    &quot;User Profile&quot;,
    mcp.WithTemplateDescription(&quot;Returns user profile information&quot;),
    mcp.WithTemplateMIMEType(&quot;application/json&quot;),
)

// Add template with its handler
s.AddResourceTemplate(template, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    // Extract ID from the URI using regex matching
    // The server automatically matches URIs to templates
    userID := extractIDFromURI(request.Params.URI)
    
    profile, err := getUserProfile(userID)  // Your DB/API call here
    if err != nil {
        return nil, err
    }
    
    return []mcp.ResourceContents{
        mcp.TextResourceContents{
            URI:      request.Params.URI,
            MIMEType: &quot;application/json&quot;,
            Text:     profile,
        },
    }, nil
})
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The examples are simple but demonstrate the core concepts. Resources can be much more sophisticated - serving multiple contents, integrating with databases or external APIs, etc.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Show Tool Examples&lt;/summary&gt; 
 &lt;p&gt;Tools let LLMs take actions through your server. Unlike resources, tools are expected to perform computation and have side effects. They&#39;re similar to POST endpoints in a REST API.&lt;/p&gt; 
 &lt;p&gt;Simple calculation example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;calculatorTool := mcp.NewTool(&quot;calculate&quot;,
    mcp.WithDescription(&quot;Perform basic arithmetic calculations&quot;),
    mcp.WithString(&quot;operation&quot;,
        mcp.Required(),
        mcp.Description(&quot;The arithmetic operation to perform&quot;),
        mcp.Enum(&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;),
    ),
    mcp.WithNumber(&quot;x&quot;,
        mcp.Required(),
        mcp.Description(&quot;First number&quot;),
    ),
    mcp.WithNumber(&quot;y&quot;,
        mcp.Required(),
        mcp.Description(&quot;Second number&quot;),
    ),
)

s.AddTool(calculatorTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    op := request.Params.Arguments[&quot;operation&quot;].(string)
    x := request.Params.Arguments[&quot;x&quot;].(float64)
    y := request.Params.Arguments[&quot;y&quot;].(float64)

    var result float64
    switch op {
    case &quot;add&quot;:
        result = x + y
    case &quot;subtract&quot;:
        result = x - y
    case &quot;multiply&quot;:
        result = x * y
    case &quot;divide&quot;:
        if y == 0 {
            return nil, errors.New(&quot;Division by zero is not allowed&quot;)
        }
        result = x / y
    }
    
    return mcp.FormatNumberResult(result), nil
})
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;HTTP request example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;httpTool := mcp.NewTool(&quot;http_request&quot;,
    mcp.WithDescription(&quot;Make HTTP requests to external APIs&quot;),
    mcp.WithString(&quot;method&quot;,
        mcp.Required(),
        mcp.Description(&quot;HTTP method to use&quot;),
        mcp.Enum(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;),
    ),
    mcp.WithString(&quot;url&quot;,
        mcp.Required(),
        mcp.Description(&quot;URL to send the request to&quot;),
        mcp.Pattern(&quot;^https?://.*&quot;),
    ),
    mcp.WithString(&quot;body&quot;,
        mcp.Description(&quot;Request body (for POST/PUT)&quot;),
    ),
)

s.AddTool(httpTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    method := request.Params.Arguments[&quot;method&quot;].(string)
    url := request.Params.Arguments[&quot;url&quot;].(string)
    body := &quot;&quot;
    if b, ok := request.Params.Arguments[&quot;body&quot;].(string); ok {
        body = b
    }

    // Create and send request
    var req *http.Request
    var err error
    if body != &quot;&quot; {
        req, err = http.NewRequest(method, url, strings.NewReader(body))
    } else {
        req, err = http.NewRequest(method, url, nil)
    }
    if err != nil {
        return nil, fmt.Errorf(&quot;Failed to create request: %v&quot;, err)
    }

    client := &amp;amp;http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return nil, fmt.Errorf(&quot;Request failed: %v&quot;, err)
    }
    defer resp.Body.Close()

    // Return response
    respBody, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, fmt.Errorf(&quot;Failed to read response: %v&quot;, err)
    }

    return mcp.NewToolResultText(fmt.Sprintf(&quot;Status: %d\nBody: %s&quot;, resp.StatusCode, string(respBody))), nil
})
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Tools can be used for any kind of computation or side effect:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Database queries&lt;/li&gt; 
  &lt;li&gt;File operations&lt;/li&gt; 
  &lt;li&gt;External API calls&lt;/li&gt; 
  &lt;li&gt;Calculations&lt;/li&gt; 
  &lt;li&gt;System operations&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each tool should:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Have a clear description&lt;/li&gt; 
  &lt;li&gt;Validate inputs&lt;/li&gt; 
  &lt;li&gt;Handle errors gracefully&lt;/li&gt; 
  &lt;li&gt;Return structured responses&lt;/li&gt; 
  &lt;li&gt;Use appropriate result types&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Prompts&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Show Prompt Examples&lt;/summary&gt; 
 &lt;p&gt;Prompts are reusable templates that help LLMs interact with your server effectively. They&#39;re like &quot;best practices&quot; encoded into your server. Here are some examples:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// Simple greeting prompt
s.AddPrompt(mcp.NewPrompt(&quot;greeting&quot;,
    mcp.WithPromptDescription(&quot;A friendly greeting prompt&quot;),
    mcp.WithArgument(&quot;name&quot;,
        mcp.ArgumentDescription(&quot;Name of the person to greet&quot;),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    name := request.Params.Arguments[&quot;name&quot;]
    if name == &quot;&quot; {
        name = &quot;friend&quot;
    }
    
    return mcp.NewGetPromptResult(
        &quot;A friendly greeting&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewTextContent(fmt.Sprintf(&quot;Hello, %s! How can I help you today?&quot;, name)),
            ),
        },
    ), nil
})

// Code review prompt with embedded resource
s.AddPrompt(mcp.NewPrompt(&quot;code_review&quot;,
    mcp.WithPromptDescription(&quot;Code review assistance&quot;),
    mcp.WithArgument(&quot;pr_number&quot;,
        mcp.ArgumentDescription(&quot;Pull request number to review&quot;),
        mcp.RequiredArgument(),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    prNumber := request.Params.Arguments[&quot;pr_number&quot;]
    if prNumber == &quot;&quot; {
        return nil, fmt.Errorf(&quot;pr_number is required&quot;)
    }
    
    return mcp.NewGetPromptResult(
        &quot;Code review assistance&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleSystem,
                mcp.NewTextContent(&quot;You are a helpful code reviewer. Review the changes and provide constructive feedback.&quot;),
            ),
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewEmbeddedResource(mcp.ResourceContents{
                    URI: fmt.Sprintf(&quot;git://pulls/%s/diff&quot;, prNumber),
                    MIMEType: &quot;text/x-diff&quot;,
                }),
            ),
        },
    ), nil
})

// Database query builder prompt
s.AddPrompt(mcp.NewPrompt(&quot;query_builder&quot;,
    mcp.WithPromptDescription(&quot;SQL query builder assistance&quot;),
    mcp.WithArgument(&quot;table&quot;,
        mcp.ArgumentDescription(&quot;Name of the table to query&quot;),
        mcp.RequiredArgument(),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    tableName := request.Params.Arguments[&quot;table&quot;]
    if tableName == &quot;&quot; {
        return nil, fmt.Errorf(&quot;table name is required&quot;)
    }
    
    return mcp.NewGetPromptResult(
        &quot;SQL query builder assistance&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleSystem,
                mcp.NewTextContent(&quot;You are a SQL expert. Help construct efficient and safe queries.&quot;),
            ),
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewEmbeddedResource(mcp.ResourceContents{
                    URI: fmt.Sprintf(&quot;db://schema/%s&quot;, tableName),
                    MIMEType: &quot;application/json&quot;,
                }),
            ),
        },
    ), nil
})
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Prompts can include:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;System instructions&lt;/li&gt; 
  &lt;li&gt;Required arguments&lt;/li&gt; 
  &lt;li&gt;Embedded resources&lt;/li&gt; 
  &lt;li&gt;Multiple messages&lt;/li&gt; 
  &lt;li&gt;Different content types (text, images, etc.)&lt;/li&gt; 
  &lt;li&gt;Custom URI schemes&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;For examples, see the &lt;code&gt;examples/&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Extras&lt;/h2&gt; 
&lt;h3&gt;Request Hooks&lt;/h3&gt; 
&lt;p&gt;Hook into the request lifecycle by creating a &lt;code&gt;Hooks&lt;/code&gt; object with your selection among the possible callbacks. This enables telemetry across all functionality, and observability of various facts, for example the ability to count improperly-formatted requests, or to log the agent identity during initialization.&lt;/p&gt; 
&lt;p&gt;Add the &lt;code&gt;Hooks&lt;/code&gt; to the server at the time of creation using the &lt;code&gt;server.WithHooks&lt;/code&gt; option.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;h3&gt;Open Developer Guide&lt;/h3&gt;&lt;/summary&gt; 
 &lt;h3&gt;Prerequisites&lt;/h3&gt; 
 &lt;p&gt;Go version &amp;gt;= 1.23&lt;/p&gt; 
 &lt;h3&gt;Installation&lt;/h3&gt; 
 &lt;p&gt;Create a fork of this repository, then clone it:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/mark3labs/mcp-go.git
cd mcp-go
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Testing&lt;/h3&gt; 
 &lt;p&gt;Please make sure to test any new functionality. Your tests should be simple and atomic and anticipate change rather than cement complex patterns.&lt;/p&gt; 
 &lt;p&gt;Run tests from the root directory:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;go test -v &#39;./...&#39;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Opening a Pull Request&lt;/h3&gt; 
 &lt;p&gt;Fork the repository and create a new branch:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git checkout -b my-branch
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Make your changes and commit them:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git add . &amp;amp;&amp;amp; git commit -m &quot;My changes&quot;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Push your changes to your fork:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git push origin my-branch
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Feel free to reach out in a GitHub issue or discussion if you have any questions!&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>RSSNext/Folo</title>
      <link>https://github.com/RSSNext/Folo</link>
      <description>&lt;p&gt;🧡 Follow everything in one place&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://github.com/RSSNext/Folo&quot;&gt; &lt;img src=&quot;https://github.com/RSSNext/follow/assets/41265413/c6c02ad5-cddc-46f5-8420-a47afe1c82fe&quot; alt=&quot;Logo&quot; width=&quot;80&quot; height=&quot;80&quot;&gt; &lt;/a&gt; 
 &lt;h3&gt;Folo&lt;/h3&gt; 
 &lt;p&gt; &lt;img src=&quot;https://github.com/user-attachments/assets/cbe924f2-d8b0-48b0-814e-7c06ccb1911c&quot; height=&quot;60&quot;&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;img src=&quot;https://github.com/user-attachments/assets/6997a236-3df3-49d5-98a4-514f6d1a02c4&quot; height=&quot;60&quot;&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/RSSNext/Follow?color=ffcb47&amp;amp;labelColor=black&amp;amp;style=flat-square&amp;amp;logo=github&amp;amp;label=Stars&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/RSSNext/Folo?style=flat-square&amp;amp;logo=github&amp;amp;label=Contributors&amp;amp;labelColor=black&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://status.follow.is/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://status.follow.is/api/badge/18/uptime?color=%2344CC10&amp;amp;labelColor=black&amp;amp;style=flat-square&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/RSSNext/Folo/total?color=369eff&amp;amp;labelColor=black&amp;amp;logo=github&amp;amp;style=flat-square&amp;amp;label=Downloads&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://x.com/intent/follow?screen_name=follow_app_&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Follow-blue?color=1d9bf0&amp;amp;logo=x&amp;amp;labelColor=black&amp;amp;style=flat-square&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.gg/followapp&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Ffollowapp%3Fwith_counts%3Dtrue&amp;amp;query=approximate_member_count&amp;amp;color=5865F2&amp;amp;label=Discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square&quot;&gt;&lt;/a&gt; &lt;br&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/package-json/v/RSSNext/Folo?filename=%2Fapps%2Fmobile%2Fpackage.json&amp;amp;style=flat-square&amp;amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iNTUiIGhlaWdodD0iNTUiIHZpZXdCb3g9IjAgMCA1NSA1NSIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQxLjc5NDQgMTBIMTguNjc4NkMxNS44ODMzIDEwIDEzLjYxNzIgMTIuMTk2NSAxMy42MTcyIDE0LjkwNTlDMTMuNjE3MiAxNy42MTU0IDE1Ljg4MzMgMTkuODExOSAxOC42Nzg2IDE5LjgxMTlINDEuNzk0NEM0NC41ODk5IDE5LjgxMTkgNDYuODU1OSAxNy42MTU0IDQ2Ljg1NTkgMTQuOTA1OUM0Ni44NTU5IDEyLjE5NjUgNDQuNTg5OSAxMCA0MS43OTQ0IDEwWiIgZmlsbD0id2hpdGUiLz4KPHBhdGggZD0iTTI5LjQ2ODMgMjIuNzU1OUgxNC4wNjE1QzExLjI2NjEgMjIuNzU1OSA5IDI0Ljk1MjMgOSAyNy42NjE4QzkgMzAuMzcxMyAxMS4yNjYxIDMyLjU2NzcgMTQuMDYxNSAzMi41Njc3SDI5LjQ2ODNDMzIuMjYzNyAzMi41Njc3IDM0LjUyOTggMzAuMzcxMyAzNC41Mjk4IDI3LjY2MThDMzQuNTI5OCAyNC45NTIzIDMyLjI2MzcgMjIuNzU1OSAyOS40NjgzIDIyLjc1NTlaIiBmaWxsPSJ3aGl0ZSIvPgo8cGF0aCBkPSJNMzAuOTU4OSA0MC40MjcyQzMwLjk1ODkgMzcuNzE3OSAyOC42OTI4IDM1LjUyMTUgMjUuODk3NCAzNS41MjE1QzIzLjEwMjEgMzUuNTIxNSAyMC44MzU5IDM3LjcxNzkgMjAuODM1OSA0MC40MjcyQzIwLjgzNTkgNDMuMTM3MSAyMy4xMDIxIDQ1LjMzMzIgMjUuODk3NCA0NS4zMzMyQzI4LjY5MjggNDUuMzMzMiAzMC45NTg5IDQzLjEzNzEgMzAuOTU4OSA0MC40MjcyWiIgZmlsbD0id2hpdGUiLz4KPC9zdmc%2BCg%3D%3D&amp;amp;label=Mobile&amp;amp;labelColor=black&amp;amp;color=FF5E01&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/package-json/v/RSSNext/Folo?filename=%2Fapps%2Fdesktop%2Fpackage.json&amp;amp;style=flat-square&amp;amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iNTUiIGhlaWdodD0iNTUiIHZpZXdCb3g9IjAgMCA1NSA1NSIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQxLjc5NDQgMTBIMTguNjc4NkMxNS44ODMzIDEwIDEzLjYxNzIgMTIuMTk2NSAxMy42MTcyIDE0LjkwNTlDMTMuNjE3MiAxNy42MTU0IDE1Ljg4MzMgMTkuODExOSAxOC42Nzg2IDE5LjgxMTlINDEuNzk0NEM0NC41ODk5IDE5LjgxMTkgNDYuODU1OSAxNy42MTU0IDQ2Ljg1NTkgMTQuOTA1OUM0Ni44NTU5IDEyLjE5NjUgNDQuNTg5OSAxMCA0MS43OTQ0IDEwWiIgZmlsbD0id2hpdGUiLz4KPHBhdGggZD0iTTI5LjQ2ODMgMjIuNzU1OUgxNC4wNjE1QzExLjI2NjEgMjIuNzU1OSA5IDI0Ljk1MjMgOSAyNy42NjE4QzkgMzAuMzcxMyAxMS4yNjYxIDMyLjU2NzcgMTQuMDYxNSAzMi41Njc3SDI5LjQ2ODNDMzIuMjYzNyAzMi41Njc3IDM0LjUyOTggMzAuMzcxMyAzNC41Mjk4IDI3LjY2MThDMzQuNTI5OCAyNC45NTIzIDMyLjI2MzcgMjIuNzU1OSAyOS40NjgzIDIyLjc1NTlaIiBmaWxsPSJ3aGl0ZSIvPgo8cGF0aCBkPSJNMzAuOTU4OSA0MC40MjcyQzMwLjk1ODkgMzcuNzE3OSAyOC42OTI4IDM1LjUyMTUgMjUuODk3NCAzNS41MjE1QzIzLjEwMjEgMzUuNTIxNSAyMC44MzU5IDM3LjcxNzkgMjAuODM1OSA0MC40MjcyQzIwLjgzNTkgNDMuMTM3MSAyMy4xMDIxIDQ1LjMzMzIgMjUuODk3NCA0NS4zMzMyQzI4LjY5MjggNDUuMzMzMiAzMC45NTg5IDQzLjEzNzEgMzAuOTU4OSA0MC40MjcyWiIgZmlsbD0id2hpdGUiLz4KPC9zdmc%2BCg%3D%3D&amp;amp;label=Desktop&amp;amp;labelColor=black&amp;amp;color=FF5E01&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot;&gt;&lt;img src=&quot;https://img.shields.io/itunes/v/6739802604?style=flat-square&amp;amp;logo=apple&amp;amp;label=App%20Store&amp;amp;color=FF5C00&amp;amp;labelColor=black&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ffolo-mac-app-store-version.rss3.workers.dev%2F&amp;amp;query=version&amp;amp;prefix=v&amp;amp;style=flat-square&amp;amp;logo=apple&amp;amp;label=Mac%20App%20Store&amp;amp;labelColor=black&amp;amp;color=FF5E01&amp;amp;cacheSeconds=3600&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://apps.microsoft.com/detail/9nvfzpv0v0ht?mode=direct&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ffolo-microsoft-store-version.rss3.workers.dev%2F&amp;amp;query=version&amp;amp;style=flat-square&amp;amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIj48cGF0aCBmaWxsPSIjZmZmIiBkPSJNMyAzaDguNTN2OC41M0gzek0xMi40NjkgM2g4LjUzdjguNTNoLTguNTN6TTMgMTIuNDdoOC41M1YyMUgzek0xMi40NjkgMTIuNDdoOC41M1YyMWgtOC41M3oiLz48L3N2Zz4%3D&amp;amp;logoColor=white&amp;amp;label=Microsoft%20Store&amp;amp;labelColor=black&amp;amp;color=FF5E01&amp;amp;cacheSeconds=3600&amp;amp;prefix=v&quot;&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; 
  &lt;!-- &lt;a href=&quot;https://github.com/RSSNext/Folo&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/59b957fb-59ed-4ef0-994e-f6a402a6fe2b&quot; alt=&quot;GitHub Trending&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt; --&gt; &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/83168d47-b9b1-4f28-abec-4e37075c7f1b&quot; alt=&quot;App Store&quot; width=&quot;52%&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/7b4f27f1-c345-400f-a307-9c61c43263ac&quot; alt=&quot;GitHub Trending&quot; width=&quot;46%&quot;&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;As they say, your thoughts are what you read—and we’ve been consuming noisy feeds for too long! Folo organizes content into one timeline, keeping you updated on what matters, noise-free. Share lists, explore collections, and enjoy distraction-free browsing.&lt;/p&gt; 
&lt;h2&gt;👋🏻 Getting Started &amp;amp; Join Our Community&lt;/h2&gt; 
&lt;p&gt;Whether for users or professional developers, Folo will be your open information playground. Please be aware that Folo is currently under active development, and feedback is welcome for any &lt;a href=&quot;https://github.com/RSSNext/Folo/issues&quot;&gt;issue&lt;/a&gt; encountered.&lt;/p&gt; 
&lt;p&gt;Feel free to try it using the following methods:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;left&quot;&gt;Operating System&lt;/th&gt; 
   &lt;th align=&quot;left&quot;&gt;Source&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;Any&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://app.follow.is&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/51ef7800-b683-4493-83e8-eb4752366997&quot; alt=&quot;Browser&quot; height=&quot;55&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;iOS&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/a94d8698-2a11-4f43-9b0a-b756b17b61f7&quot; alt=&quot;App Store&quot; height=&quot;55&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;macOS&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://apps.apple.com/us/app/folo-follow-everything/id6739802604&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/0d47f902-7fa3-494e-ad28-9ab11af5e6d4&quot; alt=&quot;Microsoft Store&quot; height=&quot;55&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/cf61e197-d756-4606-a8ad-fb591f79fdfc&quot; alt=&quot;App Store&quot; height=&quot;55&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;Windows&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://apps.microsoft.com/detail/9nvfzpv0v0ht?mode=direct&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/b3112bab-9dd0-4893-9488-890dcb368f70&quot; alt=&quot;Microsoft Store&quot; height=&quot;55&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/RSSNext/Folo/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/cf61e197-d756-4606-a8ad-fb591f79fdfc&quot; alt=&quot;App Store&quot; height=&quot;55&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;Linux&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://github.com/RSSNext/Folo/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/cf61e197-d756-4606-a8ad-fb591f79fdfc&quot; alt=&quot;App Store&quot; height=&quot;55&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;You can also install using the following methods maintained by our community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you are using Arch Linux, you can install package &lt;a href=&quot;https://aur.archlinux.org/packages/follow-appimage&quot;&gt;follow-appimage&lt;/a&gt; that maintained by &lt;a href=&quot;https://github.com/ttimochan&quot;&gt;timochan&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you are using Nix, you can install package &lt;a href=&quot;https://github.com/NixOS/nixpkgs/raw/master/pkgs/by-name/fo/follow/package.nix&quot;&gt;follow&lt;/a&gt; that maintained by &lt;a href=&quot;https://github.com/iosmanthus&quot;&gt;iosmanthus&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you are using macOS with &lt;a href=&quot;https://brew.sh&quot;&gt;Homebrew&lt;/a&gt;, you can install cask &lt;a href=&quot;https://formulae.brew.sh/cask/follow&quot;&gt;follow&lt;/a&gt; (also &lt;a href=&quot;https://formulae.brew.sh/cask/follow@alpha&quot;&gt;@alpha&lt;/a&gt; and &lt;a href=&quot;https://formulae.brew.sh/cask/follow@nightly&quot;&gt;@nightly&lt;/a&gt;) that maintained by &lt;a href=&quot;https://github.com/realSunyz&quot;&gt;realSunyz&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align=&quot;left&quot;&gt;&lt;a href=&quot;https://discord.gg/followapp&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Ffollowapp%3Fwith_counts%3Dtrue&amp;amp;query=approximate_member_count&amp;amp;color=5865F2&amp;amp;label=Discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th align=&quot;left&quot;&gt;Join our Discord server to connect with developers, request features, and receive support.&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align=&quot;left&quot;&gt;&lt;a href=&quot;https://x.com/intent/follow?screen_name=follow_app_&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/any_text-Follow-blue?color=2CA5E0&amp;amp;label=_&amp;amp;logo=x&amp;amp;labelColor=black&amp;amp;style=flat-square&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align=&quot;left&quot;&gt;Follow us on X/Twitter for product updates and to join in on reward activities.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Star Us&lt;/strong&gt;, You will receive all release notifications from GitHub without any delay ~&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/a08f9437-b24c-4388-8f01-2826e09eeaf2&quot; alt=&quot;Image&quot;&gt;&lt;/p&gt; 
&lt;a href=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=783512367&quot; target=&quot;_blank&quot; style=&quot;display: block&quot; align=&quot;center&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=783512367&amp;amp;image_size=auto&amp;amp;color_scheme=dark&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt; 
  &lt;img alt=&quot;Performance Stats of RSSNext/Folo - Last 28 days&quot; src=&quot;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=783512367&amp;amp;image_size=auto&amp;amp;color_scheme=light&quot; width=&quot;655&quot; height=&quot;auto&quot;&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;h3&gt;Customized Information Hub&lt;/h3&gt; 
&lt;p&gt;Subscribe to a vast range of feeds and curated lists. Curate your favorites and keep track of what matters most to you.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/11dc7d21-f5d8-4e41-9269-24fc352aa02b&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;AI At Your Fingertips&lt;/h3&gt; 
&lt;p&gt;A smarter and more efficient browsing with AI-powered features like translation, summary, and more.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/37cf4f2f-4c5e-4775-86e8-2fa1a1b2ecf5&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Dynamic Content Support&lt;/h3&gt; 
&lt;p&gt;Because we know content is more than just text. From articles to videos, images to audio — Folo gets it all covered.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/d1379fd6-8767-476e-b0dc-d61753715e26&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;$POWER An Ownership Economy&lt;/h3&gt; 
&lt;p&gt;Tip creators across instantly with $POWER, support content you love, and unlock value in your own work. Your content, your power.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/23bbcd63-45ca-40c8-83ef-96bd1100b701&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;More Than Just An App&lt;/h3&gt; 
&lt;p&gt;This isn’t just another app. Folo is a community — introducing a new era of openness and community-driven experience.&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/62004a04-eaea-4f5d-bfbf-4e68b6b90286&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;You are welcome to join the open source community to build together, please check our &lt;a href=&quot;https://raw.githubusercontent.com/RSSNext/Folo/dev/CONTRIBUTING.md&quot;&gt;Contributing Guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;🔏 Code signing policy&lt;/h2&gt; 
&lt;p&gt;Folo for Windows uses free code signing provided by &lt;a href=&quot;https://about.signpath.io/&quot;&gt;SignPath.io&lt;/a&gt;, certificate by &lt;a href=&quot;https://signpath.org/&quot;&gt;SignPath Foundation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Folo for macOS and iOS are signed and notarized by &lt;a href=&quot;https://developer.apple.com/programs/&quot;&gt;Apple Developer Program&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All released files are verified with &lt;a href=&quot;https://github.com/RSSNext/Folo/attestations&quot;&gt;GitHub artifact attestations&lt;/a&gt; to ensure their provenance and integrity.&lt;/p&gt; 
&lt;h2&gt;📝 License&lt;/h2&gt; 
&lt;p&gt;Folo is licensed under the GNU General Public License version 3 with the addition of the following special exception:&lt;/p&gt; 
&lt;p&gt;All content in the &lt;code&gt;icons/mgc&lt;/code&gt; directory is copyrighted by &lt;a href=&quot;https://mgc.mingcute.com/&quot;&gt;https://mgc.mingcute.com/&lt;/a&gt; and cannot be redistributed.&lt;/p&gt; 
&lt;p&gt;All content in the &lt;code&gt;lottie&lt;/code&gt; directory is distributed under the &lt;a href=&quot;https://lottiefiles.com/page/license&quot;&gt;Lottie Simple License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ocrmypdf/OCRmyPDF</title>
      <link>https://github.com/ocrmypdf/OCRmyPDF</link>
      <description>&lt;p&gt;OCRmyPDF adds an OCR text layer to scanned PDF files, allowing them to be searched&lt;/p&gt;&lt;hr&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ocrmypdf/OCRmyPDF/main/docs/images/logo.svg?sanitize=true&quot; width=&quot;240&quot; alt=&quot;OCRmyPDF&quot;&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ocrmypdf/OCRmyPDF/actions/workflows/build.yml&quot;&gt;&lt;img src=&quot;https://github.com/ocrmypdf/OCRmyPDF/actions/workflows/build.yml/badge.svg?sanitize=true&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/ocrmypdf/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/ocrmypdf.svg?sanitize=true&quot; alt=&quot;PyPI version&quot; title=&quot;PyPI version&quot;&gt;&lt;/a&gt; &lt;img src=&quot;https://img.shields.io/homebrew/v/ocrmypdf.svg?sanitize=true&quot; alt=&quot;Homebrew version&quot; title=&quot;Homebrew version&quot;&gt; &lt;img src=&quot;https://readthedocs.org/projects/ocrmypdf/badge/?version=latest&quot; alt=&quot;ReadTheDocs&quot; title=&quot;RTD&quot;&gt; &lt;img src=&quot;https://img.shields.io/pypi/pyversions/ocrmypdf&quot; alt=&quot;Python versions&quot; title=&quot;Supported Python versions&quot;&gt;&lt;/p&gt; 
&lt;p&gt;OCRmyPDF adds an OCR text layer to scanned PDF files, allowing them to be searched or copy-pasted.&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;ocrmypdf                      # it&#39;s a scriptable command line program
   -l eng+fra                 # it supports multiple languages
   --rotate-pages             # it can fix pages that are misrotated
   --deskew                   # it can deskew crooked PDFs!
   --title &quot;My PDF&quot;           # it can change output metadata
   --jobs 4                   # it uses multiple cores by default
   --output-type pdfa         # it produces PDF/A by default
   input_scanned.pdf          # takes PDF input (or images)
   output_searchable.pdf      # produces validated PDF output
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href=&quot;https://ocrmypdf.readthedocs.io/en/latest/release_notes.html&quot;&gt;See the release notes for details on the latest changes&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Main features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generates a searchable &lt;a href=&quot;https://en.wikipedia.org/?title=PDF/A&quot;&gt;PDF/A&lt;/a&gt; file from a regular PDF&lt;/li&gt; 
 &lt;li&gt;Places OCR text accurately below the image to ease copy / paste&lt;/li&gt; 
 &lt;li&gt;Keeps the exact resolution of the original embedded images&lt;/li&gt; 
 &lt;li&gt;When possible, inserts OCR information as a &quot;lossless&quot; operation without disrupting any other content&lt;/li&gt; 
 &lt;li&gt;Optimizes PDF images, often producing files smaller than the input file&lt;/li&gt; 
 &lt;li&gt;If requested, deskews and/or cleans the image before performing OCR&lt;/li&gt; 
 &lt;li&gt;Validates input and output files&lt;/li&gt; 
 &lt;li&gt;Distributes work across all available CPU cores&lt;/li&gt; 
 &lt;li&gt;Uses &lt;a href=&quot;https://github.com/tesseract-ocr/tesseract&quot;&gt;Tesseract OCR&lt;/a&gt; engine to recognize more than &lt;a href=&quot;https://github.com/tesseract-ocr/tessdata&quot;&gt;100 languages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Keeps your private data private.&lt;/li&gt; 
 &lt;li&gt;Scales properly to handle files with thousands of pages.&lt;/li&gt; 
 &lt;li&gt;Battle-tested on millions of PDFs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src=&quot;https://raw.githubusercontent.com/ocrmypdf/OCRmyPDF/main/misc/screencast/demo.svg?sanitize=true&quot; alt=&quot;Demo of OCRmyPDF in a terminal session&quot;&gt; 
&lt;p&gt;For details: please consult the &lt;a href=&quot;https://ocrmypdf.readthedocs.io/en/latest/&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;I searched the web for a free command line tool to OCR PDF files: I found many, but none of them were really satisfying:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Either they produced PDF files with misplaced text under the image (making copy/paste impossible)&lt;/li&gt; 
 &lt;li&gt;Or they did not handle accents and multilingual characters&lt;/li&gt; 
 &lt;li&gt;Or they changed the resolution of the embedded images&lt;/li&gt; 
 &lt;li&gt;Or they generated ridiculously large PDF files&lt;/li&gt; 
 &lt;li&gt;Or they crashed when trying to OCR&lt;/li&gt; 
 &lt;li&gt;Or they did not produce valid PDF files&lt;/li&gt; 
 &lt;li&gt;On top of that none of them produced PDF/A files (format dedicated for long time storage)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;...so I decided to develop my own tool.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Linux, Windows, macOS and FreeBSD are supported. Docker images are also available, for both x64 and ARM.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operating system&lt;/th&gt; 
   &lt;th&gt;Install command&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Debian, Ubuntu&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apt install ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows Subsystem for Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apt install ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fedora&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dnf install ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Homebrew)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;brew install ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (MacPorts)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;port install ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (nix)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;nix-env -i ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LinuxBrew&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;brew install ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FreeBSD&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pkg install py-ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ubuntu Snap&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;snap install ocrmypdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For everyone else, &lt;a href=&quot;https://ocrmypdf.readthedocs.io/en/latest/installation.html&quot;&gt;see our documentation&lt;/a&gt; for installation steps.&lt;/p&gt; 
&lt;h2&gt;Languages&lt;/h2&gt; 
&lt;p&gt;OCRmyPDF uses Tesseract for OCR, and relies on its language packs. For Linux users, you can often find packages that provide language packs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Display a list of all Tesseract language packs
apt-cache search tesseract-ocr

# Debian/Ubuntu users
apt-get install tesseract-ocr-chi-sim  # Example: Install Chinese Simplified language pack

# Arch Linux users
pacman -S tesseract-data-eng tesseract-data-deu # Example: Install the English and German language packs

# brew macOS users
brew install tesseract-lang
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then pass the &lt;code&gt;-l LANG&lt;/code&gt; argument to OCRmyPDF to give a hint as to what languages it should search for. Multiple languages can be requested.&lt;/p&gt; 
&lt;p&gt;OCRmyPDF supports Tesseract 4.1.1+. It will automatically use whichever version it finds first on the &lt;code&gt;PATH&lt;/code&gt; environment variable. On Windows, if &lt;code&gt;PATH&lt;/code&gt; does not provide a Tesseract binary, we use the highest version number that is installed according to the Windows Registry.&lt;/p&gt; 
&lt;h2&gt;Documentation and support&lt;/h2&gt; 
&lt;p&gt;Once OCRmyPDF is installed, the built-in help which explains the command syntax and options can be accessed via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;ocrmypdf --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Our &lt;a href=&quot;https://ocrmypdf.readthedocs.io/en/latest/index.html&quot;&gt;documentation is served on Read the Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please report issues on our &lt;a href=&quot;https://github.com/ocrmypdf/OCRmyPDF/issues&quot;&gt;GitHub issues&lt;/a&gt; page, and follow the issue template for quick response.&lt;/p&gt; 
&lt;h2&gt;Feature demo&lt;/h2&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Add an OCR layer and convert to PDF/A
ocrmypdf input.pdf output.pdf

# Convert an image to single page PDF
ocrmypdf input.jpg output.pdf

# Add OCR to a file in place (only modifies file on success)
ocrmypdf myfile.pdf myfile.pdf

# OCR with non-English languages (look up your language&#39;s ISO 639-3 code)
ocrmypdf -l fra LeParisien.pdf LeParisien.pdf

# OCR multilingual documents
ocrmypdf -l eng+fra Bilingual-English-French.pdf Bilingual-English-French.pdf

# Deskew (straighten crooked pages)
ocrmypdf --deskew input.pdf output.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more features, see the &lt;a href=&quot;https://ocrmypdf.readthedocs.io/en/latest/index.html&quot;&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;In addition to the required Python version, OCRmyPDF requires external program installations of Ghostscript and Tesseract OCR. OCRmyPDF is pure Python, and runs on pretty much everything: Linux, macOS, Windows and FreeBSD.&lt;/p&gt; 
&lt;h2&gt;Press &amp;amp; Media&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@ikirichenko/going-paperless-with-ocrmypdf-e2f36143f46a&quot;&gt;Going paperless with OCRmyPDF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@treyharris/converting-a-scanned-document-into-a-compressed-searchable-pdf-with-redactions-63f61c34fe4c&quot;&gt;Converting a scanned document into a compressed searchable PDF with redactions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://heise.de/-2279695&quot;&gt;c&#39;t 1-2014, page 59&lt;/a&gt;: Detailed presentation of OCRmyPDF v1.0 in the leading German IT magazine c&#39;t&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://heise.de/-2356670&quot;&gt;heise Open Source, 09/2014: Texterkennung mit OCRmyPDF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.heise.de/ratgeber/Durchsuchbare-PDF-Dokumente-mit-OCRmyPDF-erstellen-4607592.html&quot;&gt;heise Durchsuchbare PDF-Dokumente mit OCRmyPDF erstellen&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.linuxlinks.com/excellent-utilities-ocrmypdf-add-ocr-text-layer-scanned-pdfs/&quot;&gt;Excellent Utilities: OCRmyPDF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.linux-community.de/ausgaben/linuxuser/2021/06/texterkennung-mit-ocrmypdf-und-scanbd-automatisieren/&quot;&gt;LinuxUser Texterkennung mit OCRmyPDF und Scanbd automatisieren&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=32028752&quot;&gt;Y Combinator discussion&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Business enquiries&lt;/h2&gt; 
&lt;p&gt;OCRmyPDF would not be the software that it is today without companies and users choosing to provide support for feature development and consulting enquiries. We are happy to discuss all enquiries, whether for extending the existing feature set, or integrating OCRmyPDF into a larger system.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The OCRmyPDF software is licensed under the Mozilla Public License 2.0 (MPL-2.0). This license permits integration of OCRmyPDF with other code, included commercial and closed source, but asks you to publish source-level modifications you make to OCRmyPDF.&lt;/p&gt; 
&lt;p&gt;Some components of OCRmyPDF have other licenses, as indicated by standard SPDX license identifiers or the DEP5 copyright and licensing information file. Generally speaking, non-core code is licensed under MIT, and the documentation and test files are licensed under Creative Commons ShareAlike 4.0 (CC-BY-SA 4.0).&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;The software is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ageerle/ruoyi-ai</title>
      <link>https://github.com/ageerle/ruoyi-ai</link>
      <description>&lt;p&gt;RuoYi AI 是一个全栈式 AI 开发平台，旨在帮助开发者快速构建和部署个性化的 AI 应用。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RuoYi AI&lt;/h1&gt; 
&lt;!-- PROJECT SHIELDS --&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/ageerle/ruoyi-ai/graphs/contributors&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/contributors/ageerle/ruoyi-ai.svg?style=flat-square&quot; alt=&quot;Contributors&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ageerle/ruoyi-ai/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/ageerle/ruoyi-ai.svg?style=flat-square&quot; alt=&quot;Forks&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ageerle/ruoyi-ai/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/ageerle/ruoyi-ai.svg?style=flat-square&quot; alt=&quot;Stargazers&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://img.shields.io/github/issues/ageerle/ruoyi-ai.svg&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/ageerle/ruoyi-ai.svg?style=flat-square&quot; alt=&quot;Issues&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/ageerle/ruoyi-ai/raw/master/LICENSE.txt&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/ageerle/ruoyi-ai.svg?style=flat-square&quot; alt=&quot;MIT License&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br&gt; 
&lt;img style=&quot;text-align: center;&quot; src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/00.png&quot; alt=&quot;Logo&quot; width=&quot;150&quot; height=&quot;150&quot;&gt; 
&lt;h3 style=&quot;text-align: center;&quot;&gt;快速搭建属于自己的 AI 助手平台&lt;/h3&gt; 
&lt;p style=&quot;text-align: center;&quot;&gt; 全新升级，开箱即用，简单高效 &lt;br&gt; &lt;a href=&quot;https://doc.pandarobot.chat&quot;&gt;&lt;strong&gt;探索本项目的文档 »&lt;/strong&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&quot;https://web.pandarobot.chat&quot;&gt;项目预览&lt;/a&gt; · &lt;a href=&quot;https://github.com/ageerle/ruoyi-ai/issues&quot;&gt;报告Bug&lt;/a&gt; · &lt;a href=&quot;https://github.com/ageerle/ruoyi-ai/issues&quot;&gt;提出新特性&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;目录&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E6%BA%90%E7%A0%81%E5%9C%B0%E5%9D%80&quot;&gt;源码地址&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E7%89%B9%E8%89%B2%E5%8A%9F%E8%83%BD&quot;&gt;特色功能&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E9%A1%B9%E7%9B%AE%E6%BC%94%E7%A4%BA&quot;&gt;项目演示&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E5%90%8E%E5%8F%B0%E7%AE%A1%E7%90%86&quot;&gt;后台管理&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E7%94%A8%E6%88%B7%E7%AB%AF&quot;&gt;用户端&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E5%B0%8F%E7%A8%8B%E5%BA%8F%E7%AB%AF&quot;&gt;小程序端&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E5%BC%80%E5%8F%91%E5%89%8D%E7%9A%84%E9%85%8D%E7%BD%AE%E8%A6%81%E6%B1%82&quot;&gt;开发前的配置要求&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E8%AF%B4%E6%98%8E&quot;&gt;文件目录说明&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84%E6%A1%86%E6%9E%B6&quot;&gt;使用到的框架&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E8%B4%A1%E7%8C%AE%E8%80%85&quot;&gt;贡献者&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E5%A6%82%E4%BD%95%E5%8F%82%E4%B8%8E%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE&quot;&gt;如何参与开源项目&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6&quot;&gt;版本控制&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E4%BD%9C%E8%80%85&quot;&gt;作者&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E9%B8%A3%E8%B0%A2&quot;&gt;鸣谢&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;源码地址&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;项目文档: &lt;a href=&quot;https://doc.pandarobot.chat&quot;&gt;https://doc.pandarobot.chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;前端-后台管理: &lt;a href=&quot;https://github.com/ageerle/ruoyi-admin&quot;&gt;https://github.com/ageerle/ruoyi-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;前端-用户端: &lt;a href=&quot;https://github.com/ageerle/ruoyi-web&quot;&gt;https://github.com/ageerle/ruoyi-web&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;小程序端: &lt;a href=&quot;https://github.com/ageerle/ruoyi-uniapp&quot;&gt;https://github.com/ageerle/ruoyi-uniapp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;演示地址: &lt;a href=&quot;https://web.pandarobot.chat&quot;&gt;https://web.pandarobot.chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;后台管理: &lt;a href=&quot;https://admin.pandarobot.chat&quot;&gt;https://admin.pandarobot.chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;用户名: admin 密码：admin123&lt;/li&gt; 
 &lt;li&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;gitcode源码地址&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gitcode.com/ageerle/ruoyi-ai&quot;&gt;https://gitcode.com/ageerle/ruoyi-ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gitcode.com/ageerle/ruoyi-web&quot;&gt;https://gitcode.com/ageerle/ruoyi-web&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gitcode.com/ageerle/ruoyi-admin&quot;&gt;https://gitcode.com/ageerle/ruoyi-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gitcode.com/ageerle/ruoyi-uniapp&quot;&gt;https://gitcode.com/ageerle/ruoyi-uniapp&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;特色功能&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;全套开源系统：提供完整的前端应用、后台管理以及小程序应用，基于MIT协议，开箱即用。&lt;/li&gt; 
 &lt;li&gt;本地RAG方案：集成Milvus/Weaviate向量库、本地向量化模型与Ollama，实现本地化RAG&lt;/li&gt; 
 &lt;li&gt;丰富插件功能：支持联网、SQL查询插件及Text2API插件，扩展系统能力与应用场景。&lt;/li&gt; 
 &lt;li&gt;内置SSE、websocket等网络协议，支持对接多种大语言模型，同时还集成了MidJourney和DALLE AI绘画功能&lt;/li&gt; 
 &lt;li&gt;强大的多媒体功能：支持AI翻译、PPT制作、语音克隆和翻唱等&lt;/li&gt; 
 &lt;li&gt;扩展功能：支持将大模型接入个人或企业微信&lt;/li&gt; 
 &lt;li&gt;支付功能：支持易支付、微信支付等多种支付方式&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;项目演示&lt;/h3&gt; 
&lt;h4&gt;后台管理&lt;/h4&gt; 
&lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; justify-content: center;&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/02.png&quot; alt=&quot;drawing&quot; style=&quot;width: 600px; height: 300px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/03.png&quot; alt=&quot;drawing&quot; style=&quot;width: 600px; height: 300px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/04.png&quot; alt=&quot;drawing&quot; style=&quot;width: 600px; height: 300px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/05.png&quot; alt=&quot;drawing&quot; style=&quot;width: 600px; height: 300px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
&lt;/div&gt; 
&lt;h4&gt;用户端&lt;/h4&gt; 
&lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; justify-content: center;&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/08.png&quot; alt=&quot;drawing&quot; style=&quot;width: 600px; height: 300px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/09.png&quot; alt=&quot;drawing&quot; style=&quot;width: 600px; height: 300px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/10.png&quot; alt=&quot;drawing&quot; style=&quot;width: 600px; height: 300px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/11.png&quot; alt=&quot;drawing&quot; style=&quot;width: 600px; height: 300px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
&lt;/div&gt; 
&lt;h4&gt;小程序端&lt;/h4&gt; 
&lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; justify-content: flex-start;&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/06.png&quot; alt=&quot;drawing&quot; style=&quot;width: 320px; height: 600px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/07.png&quot; alt=&quot;drawing&quot; style=&quot;width: 320px; height: 600px; border: 2px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);&quot;&gt; 
&lt;/div&gt; 
&lt;h3&gt;开发前的配置要求&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;jdk 17&lt;/li&gt; 
 &lt;li&gt;mysql 5.7、8.0&lt;/li&gt; 
 &lt;li&gt;redis 版本必须 &amp;gt;= 5.X&lt;/li&gt; 
 &lt;li&gt;maven 3.8+&lt;/li&gt; 
 &lt;li&gt;nodejs 20+ &amp;amp; pnpm&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;文件目录说明&lt;/h3&gt; 
&lt;p&gt;RuoYi-AI&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;├─ ruoyi-admin                         // 管理模块
│  └─ RuoYiApplication                 // 启动类
│  └─ RuoYiServletInitializer          // 容器部署初始化类
│  └─ resources                        // 资源文件
│      └─ i18n/messages.properties     // 国际化配置文件
│      └─ application.yml              // 框架总配置文件
│      └─ application-dev.yml          // 开发环境配置文件
│      └─ application-prod.yml         // 生产环境配置文件
│      └─ banner.txt                   // 框架启动图标
│      └─ logback-plus.xml             // 日志配置文件
│      └─ ip2region.xdb                // IP区域地址库
├─ ruoyi-common                        // 通用模块
│  └─ ruoyi-common-bom                 // common依赖包管理
   └─ ruoyi-common-chat                // 聊天模块
│  └─ ruoyi-common-core                // 核心模块
│  └─ ruoyi-common-doc                 // 系统接口模块
│  └─ ruoyi-common-encrypt             // 数据加解密模块
│  └─ ruoyi-common-excel               // excel模块
│  └─ ruoyi-common-idempotent          // 幂等功能模块
│  └─ ruoyi-common-json                // 序列化模块
│  └─ ruoyi-common-log                 // 日志模块
│  └─ ruoyi-common-mail                // 邮件模块
│  └─ ruoyi-common-mybatis             // 数据库模块
│  └─ ruoyi-common-oss                 // oss服务模块
│  └─ ruoyi-common-pay                 // 支付模块
│  └─ ruoyi-common-ratelimiter         // 限流功能模块
│  └─ ruoyi-common-redis               // 缓存服务模块
│  └─ ruoyi-common-satoken             // satoken模块
│  └─ ruoyi-common-security            // 安全模块
│  └─ ruoyi-common-sensitive           // 脱敏模块
│  └─ ruoyi-common-sms                 // 短信模块
│  └─ ruoyi-common-tenant              // 租户模块
│  └─ ruoyi-common-translation         // 通用翻译模块
│  └─ ruoyi-common-web                 // web模块
├─ ruoyi-modules                       // 模块组
│  └─ ruoyi-demo                       // 演示模块
│  └─ ruoyi-system                     // 业务模块
├─ .run                 // 执行脚本文件
├─ .editorconfig        // 编辑器编码格式配置
├─ LICENSE              // 开源协议
├─ pom.xml              // 公共依赖
├─ README.md            // 框架说明文件


&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;版本控制&lt;/h3&gt; 
&lt;p&gt;该项目使用Git进行版本管理。您可以在repository参看当前可用版本。&lt;/p&gt; 
&lt;h3&gt;版权说明&lt;/h3&gt; 
&lt;p&gt;该项目使用了MIT授权许可，详情请参阅 &lt;a href=&quot;https://github.com/ageerle/ruoyi-ai/raw/main/LICENSE&quot;&gt;LICENSE.txt&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;作者寄语&lt;/h3&gt; 
&lt;p&gt;最近，我们的项目意外地受到了广泛关注，甚至被许多人误以为是一个已经成熟且能够快速落地的项目。然而，事实并非如此。这个项目是我个人在业余时间进行的研究，主要目的是学习和探索。它是一个以人工智能（AI）为核心的平台，旨在帮助企业通过配置的方式快速构建AI应用。&lt;/p&gt; 
&lt;h4&gt;项目现状&lt;/h4&gt; 
&lt;p&gt;目前，项目还处于早期阶段，距离成熟还有很长的路要走。由于个人精力有限，项目的发展速度受到了一定的限制。为了加快项目的进度，我真诚地希望更多人能够参与到项目中来。无论是经验丰富的开发者，还是刚刚入门的小白，我都热烈欢迎你们提交Pull Request（PR）。即使代码修改得很少，或者存在一些错误，都没有关系。我会认真审核每一位贡献者的代码，并和大家一起完善项目。&lt;/p&gt; 
&lt;h4&gt;开发计划&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;智能体管理&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过设置提示词、插件、知识库等，用户可以快速构建一个AI应用。这将极大地简化AI应用的开发流程，降低开发门槛，使更多企业能够轻松地利用AI技术。&lt;/p&gt; 
&lt;div&gt; 
 &lt;img src=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/image/13.png&quot; alt=&quot;drawing&quot; width=&quot;600px&quot; height=&quot;300px&quot;&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;流程编排&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;通过流程编排功能，用户可以将不同的模型按照业务逻辑进行有序连接。这将解决单一模型能力不足的问题，充分发挥多个模型的协同作用，从而更好地满足企业的复杂业务需求。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;感谢&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;最后，我要感谢RuoYi-Vue-Plus、chatgpt-java、chatgpt-web-midjourney-proxy等优秀框架。正是因为这些项目的开源和共享，我才能够在这个基础上进行开发，使我们的项目能够取得今天的成果。再次感谢这些项目及其背后的开发者们！&lt;/p&gt; 
&lt;p&gt;希望更多志同道合的朋友能够加入我们，共同推动这个项目的发展。让我们一起努力，将这个项目打造成一个真正成熟、实用的AI平台！&lt;/p&gt; 
&lt;h4&gt;如何参与开源项目&lt;/h4&gt; 
&lt;p&gt;贡献使开源社区成为一个学习、激励和创造的绝佳场所。你所作的任何贡献都是&lt;strong&gt;非常感谢&lt;/strong&gt;的。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork 这个项目&lt;/li&gt; 
 &lt;li&gt;创建你的功能分支 (&lt;code&gt;git checkout -b feature/dev&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;提交你的更改 (&lt;code&gt;git commit -m &#39;Add some dev&#39;&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;推送到分支 (&lt;code&gt;git push origin feature/dev&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;打开拉取请求&lt;/li&gt; 
 &lt;li&gt;pr请提交到GitHub上，会定时同步到gitee&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;项目文档&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;项目文档基于vitepress构建&lt;/li&gt; 
 &lt;li&gt;按照&lt;a href=&quot;https://raw.githubusercontent.com/ageerle/ruoyi-ai/main/#%E5%A6%82%E4%BD%95%E5%8F%82%E4%B8%8E%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE&quot;&gt;如何参与开源项目&lt;/a&gt;拉取 &lt;a href=&quot;https://github.com/ageerle/ruoyi-doc&quot;&gt;https://github.com/ageerle/ruoyi-doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;安装依赖：npm install&lt;/li&gt; 
 &lt;li&gt;启动项目：npm run docs:dev&lt;/li&gt; 
 &lt;li&gt;主页路径：docs/guide/introduction/index.md&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;鸣谢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Grt1228/chatgpt-java&quot;&gt;chatgpt-java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gitee.com/dromara/RuoYi-Vue-Plus&quot;&gt;RuoYi-Vue-Plus&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Dooy/chatgpt-web-midjourney-proxy&quot;&gt;chatgpt-web-midjourney-proxy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/vbenjs/vue-vben-admin&quot;&gt;Vben Admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.naiveui.com&quot;&gt;Naive UI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- links --&gt;</description>
    </item>
    
    <item>
      <title>donnemartin/system-design-primer</title>
      <link>https://github.com/donnemartin/system-design-primer</link>
      <description>&lt;p&gt;Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md&quot;&gt;English&lt;/a&gt; ∙ &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-ja.md&quot;&gt;日本語&lt;/a&gt; ∙ &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-Hans.md&quot;&gt;简体中文&lt;/a&gt; ∙ &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-TW.md&quot;&gt;繁體中文&lt;/a&gt; | &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/170&quot;&gt;العَرَبِيَّة‎&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/220&quot;&gt;বাংলা&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/40&quot;&gt;Português do Brasil&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/186&quot;&gt;Deutsch&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/130&quot;&gt;ελληνικά&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/272&quot;&gt;עברית&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/104&quot;&gt;Italiano&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/102&quot;&gt;한국어&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/110&quot;&gt;فارسی&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/68&quot;&gt;Polski&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/87&quot;&gt;русский язык&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/136&quot;&gt;Español&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/187&quot;&gt;ภาษาไทย&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/39&quot;&gt;Türkçe&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/127&quot;&gt;tiếng Việt&lt;/a&gt; ∙ &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/250&quot;&gt;Français&lt;/a&gt; | &lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/28&quot;&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Help &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/TRANSLATIONS.md&quot;&gt;translate&lt;/a&gt; this guide!&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;The System Design Primer&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png&quot;&gt; &lt;br&gt; &lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt; 
 &lt;p&gt;Prep for the system design interview.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Learn how to design large-scale systems&lt;/h3&gt; 
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt; 
&lt;p&gt;System design is a broad topic. There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt; 
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt; 
&lt;h3&gt;Learn from the open source community&lt;/h3&gt; 
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt; 
&lt;h3&gt;Prep for the system design interview&lt;/h3&gt; 
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt; 
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#study-guide&quot;&gt;Study guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question&quot;&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions&quot;&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions&quot;&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions&quot;&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Anki flashcards&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/zdCAkB3.png&quot;&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p&gt;The provided &lt;a href=&quot;https://apps.ankiweb.net/&quot;&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg&quot;&gt;System design deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg&quot;&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg&quot;&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt; 
&lt;h3&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt; 
&lt;p&gt;Looking for resources to help you prep for the &lt;a href=&quot;https://github.com/donnemartin/interactive-coding-challenges&quot;&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/b4YtAEN.png&quot;&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p&gt;Check out the sister repo &lt;a href=&quot;https://github.com/donnemartin/interactive-coding-challenges&quot;&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg&quot;&gt;Coding deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn from the community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix errors&lt;/li&gt; 
 &lt;li&gt;Improve sections&lt;/li&gt; 
 &lt;li&gt;Add new sections&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/donnemartin/system-design-primer/issues/28&quot;&gt;Translate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Content that needs some polishing is placed &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development&quot;&gt;under development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Review the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/CONTRIBUTING.md&quot;&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Index of system design topics&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Summaries of various system design topics, including pros and cons. &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png&quot;&gt; &lt;br&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-topics-start-here&quot;&gt;System design topics: start here&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-1-review-the-scalability-video-lecture&quot;&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-2-review-the-scalability-article&quot;&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#next-steps&quot;&gt;Next steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#performance-vs-scalability&quot;&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-vs-throughput&quot;&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-vs-consistency&quot;&gt;Availability vs consistency&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem&quot;&gt;CAP theorem&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cp---consistency-and-partition-tolerance&quot;&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#ap---availability-and-partition-tolerance&quot;&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#consistency-patterns&quot;&gt;Consistency patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#weak-consistency&quot;&gt;Weak consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency&quot;&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#strong-consistency&quot;&gt;Strong consistency&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-patterns&quot;&gt;Availability patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#fail-over&quot;&gt;Fail-over&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#replication&quot;&gt;Replication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-in-numbers&quot;&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#domain-name-system&quot;&gt;Domain name system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network&quot;&gt;Content delivery network&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#push-cdns&quot;&gt;Push CDNs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#pull-cdns&quot;&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer&quot;&gt;Load balancer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive&quot;&gt;Active-passive&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active&quot;&gt;Active-active&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing&quot;&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing&quot;&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#horizontal-scaling&quot;&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server&quot;&gt;Reverse proxy (web server)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer-vs-reverse-proxy&quot;&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-layer&quot;&gt;Application layer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#microservices&quot;&gt;Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#service-discovery&quot;&gt;Service discovery&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database&quot;&gt;Database&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#relational-database-management-system-rdbms&quot;&gt;Relational database management system (RDBMS)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication&quot;&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication&quot;&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation&quot;&gt;Federation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding&quot;&gt;Sharding&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization&quot;&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-tuning&quot;&gt;SQL tuning&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#nosql&quot;&gt;NoSQL&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store&quot;&gt;Key-value store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#document-store&quot;&gt;Document store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#wide-column-store&quot;&gt;Wide column store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#graph-database&quot;&gt;Graph Database&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql&quot;&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache&quot;&gt;Cache&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#client-caching&quot;&gt;Client caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cdn-caching&quot;&gt;CDN caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#web-server-caching&quot;&gt;Web server caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database-caching&quot;&gt;Database caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-caching&quot;&gt;Application caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-database-query-level&quot;&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-object-level&quot;&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#when-to-update-the-cache&quot;&gt;When to update the cache&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache-aside&quot;&gt;Cache-aside&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-through&quot;&gt;Write-through&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-behind-write-back&quot;&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#refresh-ahead&quot;&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism&quot;&gt;Asynchronism&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#message-queues&quot;&gt;Message queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#task-queues&quot;&gt;Task queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#back-pressure&quot;&gt;Back pressure&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication&quot;&gt;Communication&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#transmission-control-protocol-tcp&quot;&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#user-datagram-protocol-udp&quot;&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#remote-procedure-call-rpc&quot;&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest&quot;&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#security&quot;&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix&quot;&gt;Appendix&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table&quot;&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know&quot;&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions&quot;&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures&quot;&gt;Real world architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-architectures&quot;&gt;Company architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs&quot;&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development&quot;&gt;Under development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#credits&quot;&gt;Credits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contact-info&quot;&gt;Contact info&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Study guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A: No, you don&#39;t need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How much experience you have&lt;/li&gt; 
 &lt;li&gt;What your technical background is&lt;/li&gt; 
 &lt;li&gt;What positions you are interviewing for&lt;/li&gt; 
 &lt;li&gt;Which companies you are interviewing with&lt;/li&gt; 
 &lt;li&gt;Luck&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More experienced candidates are generally expected to know more about system design. Architects or team leads might be expected to know more than individual contributors. Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt; 
&lt;p&gt;Start broad and go deeper in a few areas. It helps to know a little about various key system design topics. Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Short&lt;/th&gt; 
   &lt;th&gt;Medium&lt;/th&gt; 
   &lt;th&gt;Long&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics&quot;&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few articles in the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs&quot;&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures&quot;&gt;Real world architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question&quot;&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions&quot;&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions&quot;&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions&quot;&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;How to approach a system design interview question&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;How to tackle a system design interview question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;. You are expected to lead it.&lt;/p&gt; 
&lt;p&gt;You can use the following steps to guide the discussion. To help solidify this process, work through the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions&quot;&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt; 
&lt;h3&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt; 
&lt;p&gt;Gather requirements and scope the problem. Ask questions to clarify use cases and constraints. Discuss assumptions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Who is going to use it?&lt;/li&gt; 
 &lt;li&gt;How are they going to use it?&lt;/li&gt; 
 &lt;li&gt;How many users are there?&lt;/li&gt; 
 &lt;li&gt;What does the system do?&lt;/li&gt; 
 &lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt; 
 &lt;li&gt;How much data do we expect to handle?&lt;/li&gt; 
 &lt;li&gt;How many requests per second do we expect?&lt;/li&gt; 
 &lt;li&gt;What is the expected read to write ratio?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Create a high level design&lt;/h3&gt; 
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sketch the main components and connections&lt;/li&gt; 
 &lt;li&gt;Justify your ideas&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3: Design core components&lt;/h3&gt; 
&lt;p&gt;Dive into details for each core component. For example, if you were asked to &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generating and storing a hash of the full url 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;MD5&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;Base62&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hash collisions&lt;/li&gt; 
   &lt;li&gt;SQL or NoSQL&lt;/li&gt; 
   &lt;li&gt;Database schema&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Translating a hashed url to the full url 
  &lt;ul&gt; 
   &lt;li&gt;Database lookup&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;API and object-oriented design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 4: Scale the design&lt;/h3&gt; 
&lt;p&gt;Identify and address bottlenecks, given the constraints. For example, do you need the following to address scalability issues?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Load balancer&lt;/li&gt; 
 &lt;li&gt;Horizontal scaling&lt;/li&gt; 
 &lt;li&gt;Caching&lt;/li&gt; 
 &lt;li&gt;Database sharding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Discuss potential solutions and trade-offs. Everything is a trade-off. Address bottlenecks using &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics&quot;&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Back-of-the-envelope calculations&lt;/h3&gt; 
&lt;p&gt;You might be asked to do some estimates by hand. Refer to the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix&quot;&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html&quot;&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table&quot;&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know&quot;&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/&quot;&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.hiredintech.com/system-design&quot;&gt;The system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ZgdS0EUmn70&quot;&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://leetcode.com/discuss/career/229177/My-System-Design-Template&quot;&gt;System design template&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a web crawler&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Mint.com&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the data structures for a social network&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store for a search engine&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Amazon&#39;s sales ranking by category feature&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Design a web crawler&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Design Mint.com&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Design the data structures for a social network&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Design a key-value store for a search engine&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Design Amazon&#39;s sales ranking by category feature&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;h3&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md&quot;&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png&quot; alt=&quot;Imgur&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Object-oriented design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a hash map&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/hash_table/hash_map.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a least recently used cache&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/lru_cache/lru_cache.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a call center&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/call_center/call_center.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a deck of cards&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a parking lot&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/parking_lot/parking_lot.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat server&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/online_chat/online_chat.ipynb&quot;&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a circular array&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an object-oriented design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;System design topics: start here&lt;/h2&gt; 
&lt;p&gt;New to system design?&lt;/p&gt; 
&lt;p&gt;First, you&#39;ll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt; 
&lt;h3&gt;Step 1: Review the scalability video lecture&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=-W9F__D3oY4&quot;&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;Vertical scaling&lt;/li&gt; 
   &lt;li&gt;Horizontal scaling&lt;/li&gt; 
   &lt;li&gt;Caching&lt;/li&gt; 
   &lt;li&gt;Load balancing&lt;/li&gt; 
   &lt;li&gt;Database replication&lt;/li&gt; 
   &lt;li&gt;Database partitioning&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Review the scalability article&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono&quot;&gt;Scalability&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones&quot;&gt;Clones&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database&quot;&gt;Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache&quot;&gt;Caches&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism&quot;&gt;Asynchronism&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;p&gt;Next, we&#39;ll look at high-level trade-offs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Then we&#39;ll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt; 
&lt;h2&gt;Performance vs scalability&lt;/h2&gt; 
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href=&quot;http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html&quot;&gt;A word on scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Latency vs throughput&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt; 
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://community.cadence.com/cadence_blogs_8/b/fv/posts/understanding-latency-vs-throughput&quot;&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability vs consistency&lt;/h2&gt; 
&lt;h3&gt;CAP theorem&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bgLMI2u.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://robertgreiner.com/2014/08/cap-theorem-revisited&quot;&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Networks aren&#39;t reliable, so you&#39;ll need to support partition tolerance. You&#39;ll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;CP - consistency and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt; 
&lt;h4&gt;AP - availability and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Responses return the most readily available version of the data available on any node, which might not be the latest. Writes might take some time to propagate when the partition is resolved.&lt;/p&gt; 
&lt;p&gt;AP is a good choice if the business needs to allow for &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency&quot;&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://robertgreiner.com/2014/08/cap-theorem-revisited/&quot;&gt;CAP theorem revisited&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://ksat.me/a-plain-english-introduction-to-cap-theorem&quot;&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/henryr/cap-faq&quot;&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=k-Yaq8AHlFA&quot;&gt;The CAP theorem&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Consistency patterns&lt;/h2&gt; 
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data. Recall the definition of consistency from the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem&quot;&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt; 
&lt;h3&gt;Weak consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads may or may not see it. A best effort approach is taken.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as memcached. Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games. For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt; 
&lt;h3&gt;Eventual consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as DNS and email. Eventual consistency works well in highly available systems.&lt;/p&gt; 
&lt;h3&gt;Strong consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will see it. Data is replicated synchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in file systems and RDBMSes. Strong consistency works well in systems that need transactions.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://snarfed.org/transactions_across_datacenters_io.html&quot;&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability patterns&lt;/h2&gt; 
&lt;p&gt;There are two complementary patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Fail-over&lt;/h3&gt; 
&lt;h4&gt;Active-passive&lt;/h4&gt; 
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby. If the heartbeat is interrupted, the passive server takes over the active&#39;s IP address and resumes service.&lt;/p&gt; 
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in &#39;hot&#39; standby or whether it needs to start up from &#39;cold&#39; standby. Only the active server handles traffic.&lt;/p&gt; 
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt; 
&lt;h4&gt;Active-active&lt;/h4&gt; 
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt; 
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers. If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt; 
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): failover&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt; 
 &lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Replication&lt;/h3&gt; 
&lt;h4&gt;Master-slave and master-master&lt;/h4&gt; 
&lt;p&gt;This topic is further discussed in the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database&quot;&gt;Database&lt;/a&gt; section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication&quot;&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication&quot;&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Availability in numbers&lt;/h3&gt; 
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt; 
&lt;h4&gt;99.9% availability - three 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;8h 45min 57s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;43m 49.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;10m 4.8s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;1m 26.4s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;99.99% availability - four 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;52min 35.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;4m 23s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;1m 5s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;8.6s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Availability in parallel vs in sequence&lt;/h4&gt; 
&lt;p&gt;If a service consists of multiple components prone to failure, the service&#39;s overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt; 
&lt;h6&gt;In sequence&lt;/h6&gt; 
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt; 
&lt;h6&gt;In parallel&lt;/h6&gt; 
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt; 
&lt;h2&gt;Domain name system&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/IOyLj4i.jpg&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/srikrupa5/dns-security-presentation-issa&quot;&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href=&quot;http://www.example.com&quot;&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt; 
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level. Your router or ISP provides information about which DNS server(s) to contact when doing a lookup. Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays. DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_to_live&quot;&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href=&quot;http://www.example.com&quot;&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Services such as &lt;a href=&quot;https://www.cloudflare.com/dns/&quot;&gt;CloudFlare&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/route53/&quot;&gt;Route 53&lt;/a&gt; provide managed DNS services. Some DNS services can route traffic through various methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.jscape.com/blog/load-balancing-algorithms&quot;&gt;Weighted round robin&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt; 
   &lt;li&gt;Balance between varying cluster sizes&lt;/li&gt; 
   &lt;li&gt;A/B testing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html&quot;&gt;Latency-based&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html&quot;&gt;Geolocation-based&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): DNS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt; 
 &lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href=&quot;http://superuser.com/questions/472695/who-controls-the-dns-servers/472729&quot;&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;DNS services have recently come under &lt;a href=&quot;http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/&quot;&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter&#39;s IP address(es).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx&quot;&gt;DNS architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Domain_Name_System&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://support.dnsimple.com/categories/dns/&quot;&gt;DNS articles&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Content delivery network&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h9TAuGI.jpg&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/&quot;&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon&#39;s CloudFront support dynamic content. The site&#39;s DNS resolution will tell clients which server to contact.&lt;/p&gt; 
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Users receive content from data centers close to them&lt;/li&gt; 
 &lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Push CDNs&lt;/h3&gt; 
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server. You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN. You can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt; 
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn&#39;t often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt; 
&lt;h3&gt;Pull CDNs&lt;/h3&gt; 
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content. You leave the content on your server and rewrite URLs to point to the CDN. This results in a slower request until the content is cached on the CDN.&lt;/p&gt; 
&lt;p&gt;A &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_to_live&quot;&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached. Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt; 
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): CDN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt; 
 &lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt; 
 &lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://figshare.com/articles/Globally_distributed_content_delivery/6605972&quot;&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/&quot;&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Content_delivery_network&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Load balancer&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h81n9iK.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html&quot;&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases. In each case, the load balancer returns the response from the computing resource to the appropriate client. Load balancers are effective at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt; 
 &lt;li&gt;Preventing overloading resources&lt;/li&gt; 
 &lt;li&gt;Helping to eliminate a single point of failure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href=&quot;https://en.wikipedia.org/wiki/X.509&quot;&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client&#39;s requests to same instance if the web apps do not keep track of sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To protect against failures, it&#39;s common to set up multiple load balancers, either in &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive&quot;&gt;active-passive&lt;/a&gt; or &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active&quot;&gt;active-active&lt;/a&gt; mode.&lt;/p&gt; 
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Random&lt;/li&gt; 
 &lt;li&gt;Least loaded&lt;/li&gt; 
 &lt;li&gt;Session/cookies&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.g33kinfo.com/info/round-robin-vs-weighted-round-robin-lb&quot;&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing&quot;&gt;Layer 4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing&quot;&gt;Layer 7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Layer 4 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication&quot;&gt;transport layer&lt;/a&gt; to decide how to distribute requests. Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet. Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href=&quot;https://www.nginx.com/resources/glossary/layer-4-load-balancing/&quot;&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Layer 7 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 7 load balancers look at the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication&quot;&gt;application layer&lt;/a&gt; to decide how to distribute requests. This can involve contents of the header, message, and cookies. Layer 7 load balancers terminate network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server. For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt; 
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt; 
&lt;h3&gt;Horizontal scaling&lt;/h3&gt; 
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability. Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;. It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers 
  &lt;ul&gt; 
   &lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt; 
   &lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database&quot;&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache&quot;&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): load balancer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt; 
 &lt;li&gt;Introducing a load balancer to help eliminate a single point of failure results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&quot;&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.haproxy.org/download/1.2/doc/architecture.txt&quot;&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones&quot;&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Load_balancing_(computing)&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/glossary/layer-4-load-balancing/&quot;&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/glossary/layer-7-load-balancing/&quot;&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html&quot;&gt;ELB listener config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reverse proxy (web server)&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n41Azff.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg&quot;&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public. Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server&#39;s response to the client.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy&#39;s IP, allowing you to scale servers or change their configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href=&quot;https://en.wikipedia.org/wiki/X.509&quot;&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly 
  &lt;ul&gt; 
   &lt;li&gt;HTML/CSS/JS&lt;/li&gt; 
   &lt;li&gt;Photos&lt;/li&gt; 
   &lt;li&gt;Videos&lt;/li&gt; 
   &lt;li&gt;Etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Load balancer vs reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploying a load balancer is useful when you have multiple servers. Often, load balancers route traffic to a set of servers serving the same function.&lt;/li&gt; 
 &lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt; 
 &lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href=&quot;https://en.wikipedia.org/wiki/Failover&quot;&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/&quot;&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&quot;&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.haproxy.org/download/1.2/doc/architecture.txt&quot;&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Reverse_proxy&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Application layer&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yB5SYwm.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer&quot;&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently. Adding a new API results in adding application servers without necessarily adding additional web servers. The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together. Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt; 
&lt;p&gt;Workers in the application layer also help enable &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism&quot;&gt;asynchronism&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Microservices&lt;/h3&gt; 
&lt;p&gt;Related to this discussion are &lt;a href=&quot;https://en.wikipedia.org/wiki/Microservices&quot;&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services. Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href=&quot;https://smartbear.com/learn/api-design/what-are-microservices&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt; 
&lt;h3&gt;Service Discovery&lt;/h3&gt; 
&lt;p&gt;Systems such as &lt;a href=&quot;https://www.consul.io/docs/index.html&quot;&gt;Consul&lt;/a&gt;, &lt;a href=&quot;https://coreos.com/etcd/docs/latest&quot;&gt;Etcd&lt;/a&gt;, and &lt;a href=&quot;http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper&quot;&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports. &lt;a href=&quot;https://www.consul.io/intro/getting-started/checks.html&quot;&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#hypertext-transfer-protocol-http&quot;&gt;HTTP&lt;/a&gt; endpoint. Both Consul and Etcd have a built in &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store&quot;&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): application layer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt; 
 &lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://lethain.com/introduction-to-architecting-systems-for-scale&quot;&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview&quot;&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Service-oriented_architecture&quot;&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper&quot;&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/&quot;&gt;Here&#39;s what you need to know about building microservices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Database&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Xkm5CXz.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kKjm4ehYiMs&quot;&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Relational database management system (RDBMS)&lt;/h3&gt; 
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href=&quot;https://en.wikipedia.org/wiki/Database_transaction&quot;&gt;transactions&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Master-slave replication&lt;/h4&gt; 
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate to additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/C9ioGtn.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-slave replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication&quot;&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Master-master replication&lt;/h4&gt; 
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes. If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/krAHLGg.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-master replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You&#39;ll need a load balancer or you&#39;ll need to make changes to your application logic to determine where to write.&lt;/li&gt; 
 &lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt; 
 &lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication&quot;&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt; 
 &lt;li&gt;Writes are replayed to the read replicas. If there are a lot of writes, the read replicas can get bogged down with replaying writes and can&#39;t do as many reads.&lt;/li&gt; 
 &lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt; 
 &lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt; 
 &lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Multi-master_replication&quot;&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Federation&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/U3qV33e.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kKjm4ehYiMs&quot;&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Federation (or functional partitioning) splits up databases by function. For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag. Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality. With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt; 
 &lt;li&gt;You&#39;ll need to update your application logic to determine which database to read and write.&lt;/li&gt; 
 &lt;li&gt;Joining data from two databases is more complex with a &lt;a href=&quot;http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers&quot;&gt;server link&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kKjm4ehYiMs&quot;&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sharding&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wU8x5Id.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data. Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt; 
&lt;p&gt;Similar to the advantages of &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation&quot;&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits. Index size is also reduced, which generally improves performance with faster queries. If one shard goes down, the other shards are still operational, although you&#39;ll want to add some form of replication to avoid data loss. Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt; 
&lt;p&gt;Common ways to shard a table of users is either through the user&#39;s last name initial or the user&#39;s geographic location.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You&#39;ll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt; 
 &lt;li&gt;Data distribution can become lopsided in a shard. For example, a set of power users on a shard could result in increased load to that shard compared to others. 
  &lt;ul&gt; 
   &lt;li&gt;Rebalancing adds additional complexity. A sharding function based on &lt;a href=&quot;http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html&quot;&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt; 
 &lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html&quot;&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Shard_(database_architecture)&quot;&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html&quot;&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Denormalization&lt;/h4&gt; 
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins. Some RDBMS such as &lt;a href=&quot;https://en.wikipedia.org/wiki/PostgreSQL&quot;&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href=&quot;https://en.wikipedia.org/wiki/Materialized_view&quot;&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt; 
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation&quot;&gt;federation&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding&quot;&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity. Denormalization might circumvent the need for such complex joins.&lt;/p&gt; 
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1. A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): denormalization&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data is duplicated.&lt;/li&gt; 
 &lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt; 
 &lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;Source(s) and further reading: denormalization&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Denormalization&quot;&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;SQL tuning&lt;/h4&gt; 
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href=&quot;https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning&quot;&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt; 
&lt;p&gt;It&#39;s important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href=&quot;http://httpd.apache.org/docs/2.2/programs/ab.html&quot;&gt;ab&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html&quot;&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt; 
&lt;h5&gt;Tighten up the schema&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts. &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches. Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt; 
 &lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt; 
 &lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href=&quot;http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search&quot;&gt;improve search performance&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Use good indices&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt; 
 &lt;li&gt;Indices are usually represented as self-balancing &lt;a href=&quot;https://en.wikipedia.org/wiki/B-tree&quot;&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt; 
 &lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt; 
 &lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt; 
 &lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Avoid expensive joins&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization&quot;&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Partition tables&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Tune the query cache&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;In some cases, the &lt;a href=&quot;https://dev.mysql.com/doc/refman/5.7/en/query-cache.html&quot;&gt;query cache&lt;/a&gt; could lead to &lt;a href=&quot;https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/&quot;&gt;performance issues&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/&quot;&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l&quot;&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search&quot;&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html&quot;&gt;Slow query log&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NoSQL&lt;/h3&gt; 
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;. Data is denormalized, and joins are generally done in the application code. Most NoSQL stores lack true ACID transactions and favor &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency&quot;&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases. In comparison with the &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem&quot;&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn&#39;t receive input during that period.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to choosing between &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql&quot;&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s). We&#39;ll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt; 
&lt;h4&gt;Key-value store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: hash table&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD. Data stores can maintain keys in &lt;a href=&quot;https://en.wikipedia.org/wiki/Lexicographical_order&quot;&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges. Key-value stores can allow for storing of metadata with a value.&lt;/p&gt; 
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer. Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt; 
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: key-value store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Key-value_database&quot;&gt;Key-value database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or&quot;&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://qnimate.com/overview-of-redis-architecture/&quot;&gt;Redis architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://adayinthelifeof.nl/2011/02/06/memcache-internals/&quot;&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Document store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object. Document stores provide APIs or a query language to query based on the internal structure of the document itself. &lt;em&gt;Note, many key-value stores include features for working with a value&#39;s metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories. Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt; 
&lt;p&gt;Some document stores like &lt;a href=&quot;https://www.mongodb.com/mongodb-architecture&quot;&gt;MongoDB&lt;/a&gt; and &lt;a href=&quot;https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/&quot;&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries. &lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf&quot;&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt; 
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: document store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Document-oriented_database&quot;&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.mongodb.com/mongodb-architecture&quot;&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/&quot;&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up&quot;&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Wide column store&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n16iOGk.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html&quot;&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A wide column store&#39;s basic unit of data is a column (name/value pair). A column can be grouped in column families (analogous to a SQL table). Super column families further group column families. You can access each column independently with a row key, and columns with the same row key form a row. Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt; 
&lt;p&gt;Google introduced &lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf&quot;&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href=&quot;https://www.edureka.co/blog/hbase-architecture/&quot;&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href=&quot;http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html&quot;&gt;Cassandra&lt;/a&gt; from Facebook. Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt; 
&lt;p&gt;Wide column stores offer high availability and high scalability. They are often used for very large data sets.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: wide column store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html&quot;&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf&quot;&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.edureka.co/blog/hbase-architecture/&quot;&gt;HBase architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html&quot;&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Graph database&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/fNcl65g.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png&quot;&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: graph&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes. Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt; 
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network. They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources. Many graphs can only be accessed with &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest&quot;&gt;REST APIs&lt;/a&gt;.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: graph&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_database&quot;&gt;Graph database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://neo4j.com/&quot;&gt;Neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.twitter.com/2010/introducing-flockdb&quot;&gt;FlockDB&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: NoSQL&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/3342497/explanation-of-base-terminology&quot;&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq&quot;&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database&quot;&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qI_g07C_Q5I&quot;&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://horicky.blogspot.com/2009/11/nosql-patterns.html&quot;&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;SQL or NoSQL&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wXGqG5f.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;https://www.infoq.com/articles/Transition-RDBMS-NoSQL/&quot;&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Structured data&lt;/li&gt; 
 &lt;li&gt;Strict schema&lt;/li&gt; 
 &lt;li&gt;Relational data&lt;/li&gt; 
 &lt;li&gt;Need for complex joins&lt;/li&gt; 
 &lt;li&gt;Transactions&lt;/li&gt; 
 &lt;li&gt;Clear patterns for scaling&lt;/li&gt; 
 &lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt; 
 &lt;li&gt;Lookups by index are very fast&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Semi-structured data&lt;/li&gt; 
 &lt;li&gt;Dynamic or flexible schema&lt;/li&gt; 
 &lt;li&gt;Non-relational data&lt;/li&gt; 
 &lt;li&gt;No need for complex joins&lt;/li&gt; 
 &lt;li&gt;Store many TB (or PB) of data&lt;/li&gt; 
 &lt;li&gt;Very data intensive workload&lt;/li&gt; 
 &lt;li&gt;Very high throughput for IOPS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt; 
 &lt;li&gt;Leaderboard or scoring data&lt;/li&gt; 
 &lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt; 
 &lt;li&gt;Frequently accessed (&#39;hot&#39;) tables&lt;/li&gt; 
 &lt;li&gt;Metadata/lookup tables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kKjm4ehYiMs&quot;&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.sitepoint.com/sql-vs-nosql-differences/&quot;&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cache&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Q6z24La.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html&quot;&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases. In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt; 
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions. Popular items can skew the distribution, causing bottlenecks. Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt; 
&lt;h3&gt;Client caching&lt;/h3&gt; 
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server&quot;&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt; 
&lt;h3&gt;CDN caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network&quot;&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt; 
&lt;h3&gt;Web server caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server&quot;&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href=&quot;https://www.varnish-cache.org/&quot;&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly. Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt; 
&lt;h3&gt;Database caching&lt;/h3&gt; 
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case. Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt; 
&lt;h3&gt;Application caching&lt;/h3&gt; 
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage. Since the data is held in RAM, it is much faster than typical databases where data is stored on disk. RAM is more limited than disk, so &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_algorithms&quot;&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)&quot;&gt;least recently used (LRU)&lt;/a&gt; can help invalidate &#39;cold&#39; entries and keep &#39;hot&#39; data in RAM.&lt;/p&gt; 
&lt;p&gt;Redis has the following additional features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Persistence option&lt;/li&gt; 
 &lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Row level&lt;/li&gt; 
 &lt;li&gt;Query-level&lt;/li&gt; 
 &lt;li&gt;Fully-formed serializable objects&lt;/li&gt; 
 &lt;li&gt;Fully-rendered HTML&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt; 
&lt;h3&gt;Caching at the database query level&lt;/h3&gt; 
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache. This approach suffers from expiration issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt; 
 &lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Caching at the object level&lt;/h3&gt; 
&lt;p&gt;See your data as an object, similar to what you do with your application code. Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt; 
 &lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;User sessions&lt;/li&gt; 
 &lt;li&gt;Fully rendered web pages&lt;/li&gt; 
 &lt;li&gt;Activity streams&lt;/li&gt; 
 &lt;li&gt;User graph data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;When to update the cache&lt;/h3&gt; 
&lt;p&gt;Since you can only store a limited amount of data in cache, you&#39;ll need to determine which cache update strategy works best for your use case.&lt;/p&gt; 
&lt;h4&gt;Cache-aside&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/ONjORqk.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast&quot;&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application is responsible for reading and writing from storage. The cache does not interact with storage directly. The application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt; 
 &lt;li&gt;Load entry from the database&lt;/li&gt; 
 &lt;li&gt;Add entry to cache&lt;/li&gt; 
 &lt;li&gt;Return entry&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;def get_user(self, user_id):
    user = cache.get(&quot;user.{0}&quot;, user_id)
    if user is None:
        user = db.query(&quot;SELECT * FROM users WHERE user_id = {0}&quot;, user_id)
        if user is not None:
            key = &quot;user.{0}&quot;.format(user_id)
            cache.set(key, json.dumps(user))
    return user
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href=&quot;https://memcached.org/&quot;&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt; 
&lt;p&gt;Subsequent reads of data added to cache are fast. Cache-aside is also referred to as lazy loading. Only requested data is cached, which avoids filling up the cache with data that isn&#39;t requested.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): cache-aside&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt; 
 &lt;li&gt;Data can become stale if it is updated in the database. This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt; 
 &lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-through&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/0vBc0hN.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Application adds/updates entry in cache&lt;/li&gt; 
 &lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt; 
 &lt;li&gt;Return&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Application code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;set_user(12345, {&quot;foo&quot;:&quot;bar&quot;})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Cache code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;def set_user(user_id, values):
    user = db.query(&quot;UPDATE Users WHERE id = {0}&quot;, user_id, values)
    cache.set(user_id, user)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast. Users are generally more tolerant of latency when updating data than reading data. Data in the cache is not stale.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): write through&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database. Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt; 
 &lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-behind (write-back)&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/rgSrvjG.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/update entry in cache&lt;/li&gt; 
 &lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): write-behind&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt; 
 &lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Refresh-ahead&lt;/h4&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/kxtjqgE.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast&quot;&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt; 
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): cache&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_algorithms&quot;&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt; 
 &lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast&quot;&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html&quot;&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://lethain.com/introduction-to-architecting-systems-for-scale/&quot;&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/jboner/scalability-availability-stability-patterns/&quot;&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache&quot;&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html&quot;&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cache_(computing)&quot;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Asynchronism&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/54GYsSx.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer&quot;&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line. They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt; 
&lt;h3&gt;Message queues&lt;/h3&gt; 
&lt;p&gt;Message queues receive, hold, and deliver messages. If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt; 
 &lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user is not blocked and the job is processed in the background. During this time, the client might optionally do a small amount of processing to make it seem like the task has completed. For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://redis.io/&quot;&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.rabbitmq.com/&quot;&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the &#39;AMQP&#39; protocol and manage your own nodes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://aws.amazon.com/sqs/&quot;&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt; 
&lt;h3&gt;Task queues&lt;/h3&gt; 
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.celeryproject.org/en/stable/&quot;&gt;Celery&lt;/a&gt;&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt; 
&lt;h3&gt;Back pressure&lt;/h3&gt; 
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. &lt;a href=&quot;http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html&quot;&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with &lt;a href=&quot;https://en.wikipedia.org/wiki/Exponential_backoff&quot;&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): asynchronism&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=1KRYH75wgy4&quot;&gt;It&#39;s all a numbers game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html&quot;&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Little%27s_law&quot;&gt;Little&#39;s law&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function&quot;&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/5KeocQs.jpg&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.escotal.com/osilayer.html&quot;&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt; 
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server. It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request. HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt; 
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint). Below are common HTTP verbs:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Verb&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Idempotent*&lt;/th&gt; 
   &lt;th&gt;Safe&lt;/th&gt; 
   &lt;th&gt;Cacheable&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Reads a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PUT&lt;/td&gt; 
   &lt;td&gt;Creates or replace a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PATCH&lt;/td&gt; 
   &lt;td&gt;Partially updates a resource&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DELETE&lt;/td&gt; 
   &lt;td&gt;Deletes a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt; 
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: HTTP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/glossary/http/&quot;&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol&quot;&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1&quot;&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Transmission control protocol (TCP)&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/JdAsdvG.jpg&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/&quot;&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href=&quot;https://en.wikipedia.org/wiki/Internet_Protocol&quot;&gt;IP network&lt;/a&gt;. Connection is established and terminated using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Handshaking&quot;&gt;handshake&lt;/a&gt;. All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sequence numbers and &lt;a href=&quot;https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation&quot;&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)&quot;&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets. If there are multiple timeouts, the connection is dropped. TCP also implements &lt;a href=&quot;https://en.wikipedia.org/wiki/Flow_control_(data)&quot;&gt;flow control&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Network_congestion#Congestion_control&quot;&gt;congestion control&lt;/a&gt;. These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt; 
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage. It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href=&quot;https://memcached.org/&quot;&gt;memcached&lt;/a&gt; server. &lt;a href=&quot;https://en.wikipedia.org/wiki/Connection_pool&quot;&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt; 
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical. Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt; 
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need all of the data to arrive intact&lt;/li&gt; 
 &lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User datagram protocol (UDP)&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yzDrJtA.jpg&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/&quot;&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;UDP is connectionless. Datagrams (analogous to packets) are guaranteed only at the datagram level. Datagrams might reach their destination out of order or not at all. UDP does not support congestion control. Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt; 
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet. This is useful with &lt;a href=&quot;https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol&quot;&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt; 
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt; 
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need the lowest latency&lt;/li&gt; 
 &lt;li&gt;Late data is worse than loss of data&lt;/li&gt; 
 &lt;li&gt;You want to implement your own error correction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/&quot;&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/&quot;&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp&quot;&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&quot;&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/User_Datagram_Protocol&quot;&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf&quot;&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Remote procedure call (RPC)&lt;/h3&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/iF4Mkb5.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview&quot;&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server. The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program. Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls. Popular RPC frameworks include &lt;a href=&quot;https://developers.google.com/protocol-buffers/&quot;&gt;Protobuf&lt;/a&gt;, &lt;a href=&quot;https://thrift.apache.org/&quot;&gt;Thrift&lt;/a&gt;, and &lt;a href=&quot;https://avro.apache.org/docs/current/&quot;&gt;Avro&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure. The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; - Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt; 
 &lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample RPC calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  &quot;data&quot;:&quot;anId&quot;;
  &quot;anotherdata&quot;: &quot;another value&quot;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RPC is focused on exposing behaviors. RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt; 
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You know your target platform.&lt;/li&gt; 
 &lt;li&gt;You want to control how your &quot;logic&quot; is accessed.&lt;/li&gt; 
 &lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt; 
 &lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt; 
 &lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt; 
 &lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt; 
 &lt;li&gt;You might not be able to leverage existing technologies out of the box. For example, it might require additional effort to ensure &lt;a href=&quot;https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/&quot;&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href=&quot;http://www.squid-cache.org/&quot;&gt;Squid&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Representational state transfer (REST)&lt;/h3&gt; 
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server. The server provides a representation of resources and actions that can either manipulate or get a new representation of resources. All communication must be stateless and cacheable.&lt;/p&gt; 
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don&#39;t reinvent the wheel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;http://restcookbook.com/Basics/hateoas/&quot;&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample REST calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{&quot;anotherdata&quot;: &quot;another value&quot;}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;REST is focused on exposing data. It minimizes the coupling between client/server and is often used for public HTTP APIs. REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href=&quot;https://github.com/for-GET/know-your-http-well/raw/master/headers.md&quot;&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH. Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): REST&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy. For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path. With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt; 
 &lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn&#39;t fit your use case. For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt; 
 &lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt; 
 &lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RPC and REST calls comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operation&lt;/th&gt; 
   &lt;th&gt;RPC&lt;/th&gt; 
   &lt;th&gt;REST&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Resign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br&gt;{&lt;br&gt;&quot;personid&quot;: &quot;1234&quot;&lt;br&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person’s items list&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an item to a person’s items&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br&gt;{&lt;br&gt;&quot;personid&quot;: &quot;1234&quot;;&lt;br&gt;&quot;itemid&quot;: &quot;456&quot;&lt;br&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br&gt;{&lt;br&gt;&quot;itemid&quot;: &quot;456&quot;&lt;br&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Update an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br&gt;{&lt;br&gt;&quot;itemid&quot;: &quot;456&quot;;&lt;br&gt;&quot;key&quot;: &quot;value&quot;&lt;br&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br&gt;{&lt;br&gt;&quot;key&quot;: &quot;value&quot;&lt;br&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Delete an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br&gt;{&lt;br&gt;&quot;itemid&quot;: &quot;456&quot;&lt;br&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;i&gt;&lt;a href=&quot;https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/&quot;&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/&quot;&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://programmers.stackexchange.com/a/181186&quot;&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/15056878/rest-vs-json-rpc&quot;&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/&quot;&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs&quot;&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview&quot;&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://code.facebook.com/posts/1468950976659943/&quot;&gt;Thrift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://arstechnica.com/civis/viewtopic.php?t=1190508&quot;&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;This section could use some updates. Consider &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;contributing&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Security is a broad topic. Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won&#39;t need to know more than the basics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt; 
 &lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross-site_scripting&quot;&gt;XSS&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/SQL_injection&quot;&gt;SQL injection&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt; 
 &lt;li&gt;Use the principle of &lt;a href=&quot;https://en.wikipedia.org/wiki/Principle_of_least_privilege&quot;&gt;least privilege&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/shieldfy/API-Security-Checklist&quot;&gt;API security checklist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/FallibleInc/security-guide-for-developers&quot;&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet&quot;&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Appendix&lt;/h2&gt; 
&lt;p&gt;You&#39;ll sometimes be asked to do &#39;back-of-the-envelope&#39; estimates. For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take. The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt; 
&lt;h3&gt;Powers of two table&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Power_of_two&quot;&gt;Powers of two&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Latency numbers every programmer should know&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
HDD seek                            10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from HDD     30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read sequentially from HDD at 30 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt; 
 &lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt; 
 &lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Latency numbers visualized&lt;/h4&gt; 
&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67&quot; alt=&quot;&quot;&gt;&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gist.github.com/jboner/2841832&quot;&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gist.github.com/hellerbarde/2843375&quot;&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf&quot;&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf&quot;&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Additional system design interview questions&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=PE4gwstWhmc&quot;&gt;youtube.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a search engine like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://queue.acm.org/detail.cfm?id=988407&quot;&gt;queue.acm.org&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search&quot;&gt;stackexchange.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.ardendertat.com/2012/01/11/implementing-search-engines/&quot;&gt;ardendertat.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://infolab.stanford.edu/~backrub/google.html&quot;&gt;stanford.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch&quot;&gt;quora.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Google docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://code.google.com/p/google-mobwrite/&quot;&gt;code.google.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://neil.fraser.name/writing/sync/&quot;&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store like Redis&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/dvirsky/introduction-to-redis&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a cache system like Memcached&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/oemebamo/introduction-to-memcached&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a recommendation system like Amazon&#39;s&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html&quot;&gt;hulu.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://ijcai13.org/files/tutorial_slides/td3.pdf&quot;&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://n00tc0d3r.blogspot.com/&quot;&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html&quot;&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/flickr-architecture&quot;&gt;highscalability.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html&quot;&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook news feed function&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed&quot;&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed&quot;&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook timeline function&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.facebook.com/note.php?note_id=10150468255628920&quot;&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html&quot;&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook chat function&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf&quot;&gt;erlang-factory.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0&quot;&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a graph search function like Facebook&#39;s&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920&quot;&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920&quot;&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920&quot;&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://figshare.com/articles/Globally_distributed_content_delivery/6605972&quot;&gt;figshare.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a trending topic system like Twitter&#39;s&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/&quot;&gt;michael-noll.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/&quot;&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a random ID generation system&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://blog.twitter.com/2010/announcing-snowflake&quot;&gt;blog.twitter.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://github.com/twitter/snowflake/&quot;&gt;github.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Return the top k requests during a time interval&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.cs.ucsb.edu/sites/default/files/documents/2005-23.pdf&quot;&gt;cs.ucsb.edu&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf&quot;&gt;wpi.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html&quot;&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an online multiplayer card game&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://web.archive.org/web/20180929181117/http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html&quot;&gt;indieflashblog.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://buildnewgames.com/real-time-multiplayer/&quot;&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a garbage collection system&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/&quot;&gt;stuffwithstuff.com&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf&quot;&gt;washington.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an API rate limiter&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://stripe.com/blog/rate-limiters&quot;&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a Stock Exchange (like NASDAQ or Binance)&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://youtu.be/b1e4t2k2KJY&quot;&gt;Jane Street&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://around25.com/blog/building-a-trading-engine-for-a-crypto-exchange/&quot;&gt;Golang Implementation&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://bhomnick.net/building-a-simple-limit-order-in-go/&quot;&gt;Go Implementation&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Real world architectures&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/TcUo2fw.png&quot;&gt; &lt;br&gt; &lt;i&gt;&lt;a href=&quot;https://www.infoq.com/presentations/Twitter-Timeline-Scalability&quot;&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Don&#39;t focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt; 
 &lt;li&gt;Study what problems are solved by each component, where it works, where it doesn&#39;t&lt;/li&gt; 
 &lt;li&gt;Review the lessons learned&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/AGrishchenko/apache-spark-architecture&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/previa/storm-16094009&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf&quot;&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/alexbaranau/intro-to-hbase&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf&quot;&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/mdirolf/introduction-to-mongodb&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://research.google.com/archive/spanner-osdi2012.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/oemebamo/introduction-to-memcached&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/dvirsky/introduction-to-redis&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html&quot;&gt;apache.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf&quot;&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/mumrah/kafka-talk-tri-hug&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper&quot;&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Add an architecture&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company architectures&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Company&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/amazon-architecture&quot;&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cinchcast&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html&quot;&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DataSift&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html&quot;&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=PE4gwstWhmc&quot;&gt;How we&#39;ve scaled Dropbox&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ESPN&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html&quot;&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/google-architecture&quot;&gt;Google architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html&quot;&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances&quot;&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Justin.tv&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html&quot;&gt;Justin.Tv&#39;s live video broadcasting architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf&quot;&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf&quot;&gt;TAO: Facebook’s distributed data store for the social graph&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf&quot;&gt;Facebook’s photo storage&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html&quot;&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Flickr&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/flickr-architecture&quot;&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mailbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html&quot;&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Netflix&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html&quot;&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html&quot;&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pinterest&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html&quot;&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html&quot;&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Playfish&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html&quot;&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PlentyOfFish&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/plentyoffish-architecture&quot;&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Salesforce&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html&quot;&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stack Overflow&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html&quot;&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TripAdvisor&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html&quot;&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tumblr&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html&quot;&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster&quot;&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html&quot;&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html&quot;&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.infoq.com/presentations/Twitter-Timeline-Scalability&quot;&gt;Timelines at scale&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=5cKTP36HVgI&quot;&gt;Big and small data at Twitter&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=z8LU0Cj6BOU&quot;&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html&quot;&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Uber&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html&quot;&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html&quot;&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html&quot;&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;YouTube&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=w5WVu624fY8&quot;&gt;YouTube scalability&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://highscalability.com/youtube-architecture&quot;&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company engineering blogs&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt; 
 &lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://nerds.airbnb.com/&quot;&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://developer.atlassian.com/blog/&quot;&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/aws/&quot;&gt;AWS Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://word.bitly.com/&quot;&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.box.com/blog/category/engineering&quot;&gt;Box Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/&quot;&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tech.dropbox.com/&quot;&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.quora.com/q/quoraengineering&quot;&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.ebaytechblog.com/&quot;&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.evernote.com/tech/&quot;&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://codeascraft.com/&quot;&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.facebook.com/Engineering&quot;&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://code.flickr.net/&quot;&gt;Flickr Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://engineering.foursquare.com/&quot;&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.blog/category/engineering&quot;&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://googleresearch.blogspot.com/&quot;&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://engineering.groupon.com/&quot;&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://engineering.heroku.com/&quot;&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://product.hubspot.com/blog/topic/engineering&quot;&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://highscalability.com/&quot;&gt;High Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://instagram-engineering.tumblr.com/&quot;&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/blogs/&quot;&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blogs.janestreet.com/category/ocaml/&quot;&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://engineering.linkedin.com/blog&quot;&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://engineering.microsoft.com/&quot;&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/pythonengineering/&quot;&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://techblog.netflix.com/&quot;&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/paypal-engineering&quot;&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://medium.com/@Pinterest_Engineering&quot;&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.redditblog.com/&quot;&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://developer.salesforce.com/blogs/engineering/&quot;&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://slack.engineering/&quot;&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://labs.spotify.com/&quot;&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://stripe.com/blog/engineering&quot;&gt;Stripe Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.twilio.com/engineering&quot;&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://blog.twitter.com/engineering/&quot;&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://eng.uber.com/&quot;&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://yahooeng.tumblr.com/&quot;&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://engineeringblog.yelp.com/&quot;&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.zynga.com/blogs/engineering&quot;&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;p&gt;Looking to add a blog? To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kilimchoi/engineering-blogs&quot;&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Under development&lt;/h2&gt; 
&lt;p&gt;Interested in adding a section or helping complete one in-progress? &lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed computing with MapReduce&lt;/li&gt; 
 &lt;li&gt;Consistent hashing&lt;/li&gt; 
 &lt;li&gt;Scatter gather&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing&quot;&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt; 
&lt;p&gt;Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.hiredintech.com/system-design/the-system-design-process/&quot;&gt;Hired in tech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.amazon.com/dp/0984782850/&quot;&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://highscalability.com/&quot;&gt;High scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/checkcheckzz/system-design-interview&quot;&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/shashank88/system_design&quot;&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/mmcgrana/services-engineering&quot;&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://gist.github.com/vasanthk/485d1c25737e8e72759f&quot;&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://dancres.github.io/Pages/&quot;&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview&quot;&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact info&lt;/h2&gt; 
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt; 
&lt;p&gt;My contact info can be found on my &lt;a href=&quot;https://github.com/donnemartin&quot;&gt;GitHub page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Shubhamsaboo/awesome-llm-apps</title>
      <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
      <description>&lt;p&gt;Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;http://www.theunwindai.com&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/unwind_black.png&quot; width=&quot;900px&quot; alt=&quot;Unwind AI&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.linkedin.com/in/shubhamsaboo/&quot;&gt; &lt;img src=&quot;https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;amp;style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://twitter.com/Saboo_Shubham_&quot;&gt; &lt;img src=&quot;https://img.shields.io/twitter/follow/Shubham_Saboo&quot; alt=&quot;Twitter&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;h1&gt;🌟 Awesome LLM Apps&lt;/h1&gt; 
&lt;p&gt;A curated collection of awesome LLM apps built with RAG and AI agents. This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.&lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://trendshift.io/repositories/9876&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://trendshift.io/api/badge/repositories/9876&quot; alt=&quot;Shubhamsaboo%2Fawesome-llm-apps | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot;&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;🤔 Why Awesome LLM Apps?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;💡 Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.&lt;/li&gt; 
 &lt;li&gt;🔥 Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with RAG and AI Agents.&lt;/li&gt; 
 &lt;li&gt;🎓 Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚨 Open Source AI Agent Hackathon! 🚨&lt;/h2&gt; 
&lt;p&gt;We&#39;re launching a Global AI Agent Hackathon in collaboration with AI Agent ecosystem partners — open to all developers, builders, and startups working on agents, RAG, tool use, or multi-agent systems.&lt;/p&gt; 
&lt;h3&gt;💰 Win up to $20,000 in cash by building Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🏅 10 winners: $300 each&lt;/li&gt; 
 &lt;li&gt;🥉 10 winners: $500 each&lt;/li&gt; 
 &lt;li&gt;🥈 5 winners: $1,000 each&lt;/li&gt; 
 &lt;li&gt;🥇 1 winner: $2,000&lt;/li&gt; 
 &lt;li&gt;🏆 GRAND PRIZE: $5,000 🏆&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🎁 Bonus&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Top 5 projects will be featured in the top trending &lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps&quot;&gt;Awesome LLM Apps&lt;/a&gt; repo.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤝 Partners&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.theunwindai.com&quot;&gt;Unwind AI&lt;/a&gt;, &lt;a href=&quot;https://www.agno.com&quot;&gt;Agno&lt;/a&gt; and more Agent ecosystem companies joining soon.&lt;/p&gt; 
&lt;h3&gt;📅 Here&#39;s the timeline:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;April 3rd - Final dates revealed&lt;/li&gt; 
 &lt;li&gt;April 10th - Prize and success criteria announced&lt;/li&gt; 
 &lt;li&gt;April 15th (tentative) - Hackathon starts&lt;/li&gt; 
 &lt;li&gt;May 30th (tentative) - Hackathon ends&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Join us for a month of building Agents!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Prizes will be distributed on an ongoing basis and continue till all prizes are awarded.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;⭐ Star this repo and follow along to stay updated.&lt;/p&gt; 
&lt;h3&gt;🤝 Want to join us as a partner or judge?&lt;/h3&gt; 
&lt;p&gt;If you&#39;re a company in the AI agent ecosystem or would like to judge the hackathon, reach out to &lt;a href=&quot;https://x.com/Saboo_Shubham_&quot;&gt;Shubham Saboo&lt;/a&gt; or &lt;a href=&quot;https://x.com/ashpreetbedi&quot;&gt;Ashpreet Bedi&lt;/a&gt; on X to partner. Let’s make this the biggest open source AI Agent hackathon.&lt;/p&gt; 
&lt;h2&gt;📂 Featured AI Projects&lt;/h2&gt; 
&lt;h3&gt;AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_customer_support_agent&quot;&gt;💼 AI Customer Support Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_investment_agent&quot;&gt;📈 AI Investment Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_legal_agent_team&quot;&gt;👨‍⚖️ AI Legal Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_recruitment_agent_team&quot;&gt;💼 AI Recruitment Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_services_agency&quot;&gt;👨‍💼 AI Services Agency&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_competitor_intelligence_agent_team&quot;&gt;🧲 AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_health_fitness_agent&quot;&gt;🏋️‍♂️ AI Health &amp;amp; Fitness Planner Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_startup_trend_analysis_agent&quot;&gt;📈 AI Startup Trend Analysis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_journalist_agent&quot;&gt;🗞️ AI Journalist Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_finance_agent_team&quot;&gt;💲 AI Finance Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_competitor_intelligence_agent_team&quot;&gt;🧲 AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_lead_generation_agent&quot;&gt;🎯 AI Lead Generation Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_personal_finance_agent&quot;&gt;💰 AI Personal Finance Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_medical_imaging_agent&quot;&gt;🩻 AI Medical Scan Diagnosis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_teaching_agent_team&quot;&gt;👨‍🏫 AI Teaching Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_travel_agent&quot;&gt;🛫 AI Travel Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_movie_production_agent&quot;&gt;🎬 AI Movie Production Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/multi_agent_researcher&quot;&gt;📰 Multi-Agent AI Researcher&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_coding_agent_o3-mini&quot;&gt;💻 Multimodal AI Coding Agent Team with o3-mini and Gemini&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_meeting_agent&quot;&gt;📑 AI Meeting Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_chess_agent&quot;&gt;♜ AI Chess Agent Game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_real_estate_agent&quot;&gt;🏠 AI Real Estate Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/local_news_agent_openai_swarm&quot;&gt;🌐 Local News Agent OpenAI Swarm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/xai_finance_agent&quot;&gt;📊 AI Finance Agent with xAI Grok&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_3dpygame_r1&quot;&gt;🎮 AI 3D PyGame Visualizer with DeepSeek R1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_reasoning_agent&quot;&gt;🧠 AI Reasoning Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/multimodal_ai_agent&quot;&gt;🧬 Multimodal AI Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RAG (Retrieval Augmented Generation)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/autonomous_rag&quot;&gt;🔍 Autonomous RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/agentic_rag&quot;&gt;🔗 Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/gemini_agentic_rag&quot;&gt;🤔 Agentic RAG with Gemini Flash Thinking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/deepseek_local_rag_agent&quot;&gt;🐋 Deepseek Local RAG Reasoning Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/llama3.1_local_rag&quot;&gt;🔄 Llama3.1 Local RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/rag-as-a-service&quot;&gt;🧩 RAG-as-a-Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/local_rag_agent&quot;&gt;🦙 Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/hybrid_search_rag&quot;&gt;👀 RAG App with Hybrid Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/local_hybrid_search_rag&quot;&gt;🖥️ Local RAG App with Hybrid Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/rag_database_routing&quot;&gt;📠 RAG Agent with Database Routing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/corrective_rag&quot;&gt;🔄 Corrective RAG Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MCP AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/mcp_ai_agents/github_mcp_agent&quot;&gt;🐙 MCP GitHub Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;LLM Apps with Memory&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory&quot;&gt;💾 AI Arxiv Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_apps_with_memory_tutorials/llm_app_personalized_memory&quot;&gt;📝 LLM App with Personalized Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_apps_with_memory_tutorials/ai_travel_agent_memory&quot;&gt;🛩️ AI Travel Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_apps_with_memory_tutorials/local_chatgpt_with_memory&quot;&gt;🗄️ Local ChatGPT with Memory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Chat with X&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_github&quot;&gt;💬 Chat with GitHub Repo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_gmail&quot;&gt;📨 Chat with Gmail&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_pdf&quot;&gt;📄 Chat with PDF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_research_papers&quot;&gt;📚 Chat with Research Papers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_substack&quot;&gt;📝 Chat with Substack Newsletter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/chat_with_X_tutorials/chat_with_youtube_videos&quot;&gt;📽️ Chat with YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;LLM Finetuning&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/llm_finetuning_tutorials/llama3.2_finetuning&quot;&gt;🌐 Llama3.2 Finetuning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Tools and Frameworks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/gemini_multimodal_chatbot&quot;&gt;🧪 Gemini Multimodal Chatbot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/mixture_of_agents&quot;&gt;🔄 Mixture of Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/multillm_chat_playground&quot;&gt;🌐 MultiLLM Chat Playground&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/llm_router_app&quot;&gt;🔗 LLM Router App&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/local_chatgpt_clone&quot;&gt;💬 Local ChatGPT Clone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/web_scrapping_ai_agent&quot;&gt;🌍 Web Scraping AI Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/web_search_ai_assistant&quot;&gt;🔍 Web Search AI Assistant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/advanced_tools_frameworks/cursor_ai_experiments&quot;&gt;🧪 Cursor AI Experiments&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd awesome-llm-apps/chat_with_X_tutorials/chat_with_gmail
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow the project-specific instructions&lt;/strong&gt; in each project&#39;s &lt;code&gt;README.md&lt;/code&gt; file to set up and run the app.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🤝 Contributing to Open Source&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new &lt;a href=&quot;https://github.com/Shubhamsaboo/awesome-llm-apps/issues&quot;&gt;GitHub Issue&lt;/a&gt; or submit a pull request. Make sure to follow the existing project structure and include a detailed &lt;code&gt;README.md&lt;/code&gt; for each new app.&lt;/p&gt; 
&lt;h3&gt;Thank You, Community, for the Support! 🙏&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;amp;Date&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;amp;type=Date&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🌟 &lt;strong&gt;Don’t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Investment Research for Everyone, Everywhere.&lt;/p&gt;&lt;hr&gt;&lt;br&gt; 
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt; 
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href=&quot;https://x.com/openbb_finance&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://discord.com/invite/xPHTuHCmuV&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/831165782750789672&quot; alt=&quot;Discord Shield&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB&quot;&gt;&lt;img src=&quot;https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode&quot; alt=&quot;Open in Dev Containers&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt; &lt;img src=&quot;https://github.com/codespaces/badge.svg?sanitize=true&quot; height=&quot;20&quot;&gt; &lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt; &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&quot; alt=&quot;Open In Colab&quot;&gt; &lt;/a&gt; &lt;a href=&quot;https://pypi.org/project/openbb/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is free and fully open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Sign up to the &lt;a href=&quot;https://my.openbb.co/login&quot;&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;If you are looking for our &lt;strong&gt;FREE&lt;/strong&gt; AI-powered Research and Analytics Workspace, you can find it here: &lt;a href=&quot;https://pro.openbb.co&quot;&gt;pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href=&quot;https://pro.openbb.co&quot;&gt; 
 &lt;div align=&quot;center&quot;&gt; 
  &lt;img src=&quot;https://openbb.co/api/image?src=https%253A%252F%252Fopenbb-cms.directus.app%252Fassets%252Ff431ed60-5e46-439a-a9f7-4b06e72d0720.png&amp;amp;width=2400&amp;amp;height=1552&amp;amp;fit=cover&amp;amp;position=center&amp;amp;background%5B%5D=0&amp;amp;background%5B%5D=0&amp;amp;background%5B%5D=0&amp;amp;background%5B%5D=0&amp;amp;quality=100&amp;amp;compressionLevel=9&amp;amp;loop=0&amp;amp;delay=100&amp;amp;crop=null&quot; alt=&quot;Logo&quot; width=&quot;600&quot;&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;We also have an open source AI financial analyst agent that can access all of the data within OpenBB, and that repo can be found &lt;a href=&quot;https://github.com/OpenBB-finance/openbb-agents&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed=&quot;closed&quot;&gt; 
 &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href=&quot;https://pypi.org/project/openbb/&quot;&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href=&quot;https://docs.openbb.co/platform/installation&quot;&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href=&quot;https://docs.openbb.co/cli/installation&quot;&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href=&quot;https://docs.openbb.co/platform/developer_guide/contributing&quot;&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn&#39;t exist already &lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/issues&quot;&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D&quot;&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D&quot;&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D&quot;&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href=&quot;https://openbb.co/discord&quot;&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href=&quot;https://openbb.co/links&quot;&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href=&quot;https://openbb.co/links&quot;&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href=&quot;https://openbb.co/open&quot;&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark&quot;&gt;&lt;img src=&quot;https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark&quot; alt=&quot;Star History Chart&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn&#39;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt; &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>hacksider/Deep-Live-Cam</title>
      <link>https://github.com/hacksider/Deep-Live-Cam</link>
      <description>&lt;p&gt;real time face swap and one-click video deepfake with only a single image&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&quot;center&quot;&gt;Deep-Live-Cam&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; Real-time face swap and video deepfake with a single click and only a single image. &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://trendshift.io/repositories/11395&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/11395&quot; alt=&quot;hacksider%2FDeep-Live-Cam | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif&quot; alt=&quot;Demo GIF&quot; width=&quot;800&quot;&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.&lt;/p&gt; 
&lt;p&gt;We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ethical Use: Users are expected to use this software responsibly and legally. If using a real person&#39;s face, obtain their consent and clearly label any output as a deepfake when sharing online.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.&lt;/p&gt; 
&lt;p&gt;Users are expected to use this software responsibly and legally. If using a real person&#39;s face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.&lt;/p&gt; 
&lt;h2&gt;Quick Start - Pre-built (Windows / Nvidia)&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://hacksider.gumroad.com/l/vccdmm&quot;&gt; &lt;img src=&quot;https://github.com/user-attachments/assets/7d993b32-e3e8-4cd3-bbfb-a549152ebdd5&quot; width=&quot;285&quot; height=&quot;77&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href=&quot;https://hacksider.gumroad.com/l/vccdmm&quot;&gt; &lt;h5&gt;This is the fastest build you can get if you have a discrete NVIDIA GPU.&lt;/h5&gt; &lt;h6&gt;These Pre-builts are perfect for non-technical users or those who don&#39;t have time to, or can&#39;t manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually. This will be 60 days ahead on the open source version.&lt;/h6&gt; &lt;h2&gt;TLDR; Live Deepfake in just 3 Clicks&lt;/h2&gt; &lt;p&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6&quot; alt=&quot;easysteps&quot;&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Select a face&lt;/li&gt; 
  &lt;li&gt;Select which camera to use&lt;/li&gt; 
  &lt;li&gt;Press live!&lt;/li&gt; 
 &lt;/ol&gt; &lt;h2&gt;Features &amp;amp; Uses - Everything is in real-time&lt;/h2&gt; &lt;h3&gt;Mouth Mask&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Retain your original mouth for accurate movement using Mouth Mask&lt;/strong&gt;&lt;/p&gt; &lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif&quot; alt=&quot;resizable-gif&quot;&gt; &lt;/p&gt; &lt;h3&gt;Face Mapping&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Use different faces on multiple subjects simultaneously&lt;/strong&gt;&lt;/p&gt; &lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif&quot; alt=&quot;face_mapping_source&quot;&gt; &lt;/p&gt; &lt;h3&gt;Your Movie, Your Face&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Watch movies with any face in real-time&lt;/strong&gt;&lt;/p&gt; &lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif&quot; alt=&quot;movie&quot;&gt; &lt;/p&gt; &lt;h3&gt;Live Show&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Run Live shows and performances&lt;/strong&gt;&lt;/p&gt; &lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif&quot; alt=&quot;show&quot;&gt; &lt;/p&gt; &lt;h3&gt;Memes&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Create Your Most Viral Meme Yet&lt;/strong&gt;&lt;/p&gt; &lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif&quot; alt=&quot;show&quot; width=&quot;450&quot;&gt; &lt;br&gt; &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt; &lt;/p&gt; &lt;h3&gt;Omegle&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Surprise people on Omegle&lt;/strong&gt;&lt;/p&gt; &lt;p align=&quot;center&quot;&gt; 
  &lt;video src=&quot;https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0&quot; width=&quot;450&quot; controls&gt;&lt;/video&gt; &lt;/p&gt; &lt;h2&gt;Installation (Manual)&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the prebuilt version.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;
&lt;details&gt;
 &lt;a href=&quot;https://hacksider.gumroad.com/l/vccdmm&quot;&gt; &lt;summary&gt;Click to see the process&lt;/summary&gt; &lt;h3&gt;Installation&lt;/h3&gt; &lt;p&gt;This is more likely to work on your computer but will be slower as it utilizes the CPU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1. Set up Your Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python (3.10 recommended)&lt;/li&gt; 
   &lt;li&gt;pip&lt;/li&gt; 
   &lt;li&gt;git&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=OlNWCpFdVMA&quot;&gt;ffmpeg&lt;/a&gt; - &lt;code&gt;iex (irm ffmpeg.tc.ht)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://visualstudio.microsoft.com/visual-cpp-build-tools/&quot;&gt;Visual Studio 2022 Runtimes (Windows)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;strong&gt;2. Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Download the Models&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth&quot;&gt;GFPGANv1.4&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=&quot;https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx&quot;&gt;inswapper_128_fp16.onnx&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Place these files in the &quot;&lt;strong&gt;models&lt;/strong&gt;&quot; folder.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4. Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We highly recommend using a &lt;code&gt;venv&lt;/code&gt; to avoid issues.&lt;/p&gt; 
 &lt;p&gt;For Windows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) requires specific setup:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Install Python 3.10 (specific version is important)
brew install python@3.10

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.10
python3.10 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;** In case something goes wrong and you need to reinstall the virtual environment **&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Run:&lt;/strong&gt; If you don&#39;t have a GPU, you can run Deep-Live-Cam using &lt;code&gt;python run.py&lt;/code&gt;. Note that initial execution will download models (~300MB).&lt;/p&gt; 
 &lt;h3&gt;GPU Acceleration&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;CUDA Execution Provider (Nvidia)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href=&quot;https://developer.nvidia.com/cuda-11-8-0-download-archive&quot;&gt;CUDA Toolkit 11.8.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.16.3
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start=&quot;3&quot;&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python run.py --execution-provider cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Silicon)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) specific installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Make sure you&#39;ve completed the macOS setup above using Python 3.10.&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start=&quot;3&quot;&gt; 
  &lt;li&gt;Usage (important: specify Python 3.10):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python3.10 run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important Notes for macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You &lt;strong&gt;must&lt;/strong&gt; use Python 3.10, not newer versions like 3.11 or 3.13&lt;/li&gt; 
  &lt;li&gt;Always run with &lt;code&gt;python3.10&lt;/code&gt; command not just &lt;code&gt;python&lt;/code&gt; if you have multiple Python versions installed&lt;/li&gt; 
  &lt;li&gt;If you get error about &lt;code&gt;_tkinter&lt;/code&gt; missing, reinstall the tkinter package: &lt;code&gt;brew reinstall python-tk@3.10&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;If you get model loading errors, check that your models are in the correct folder&lt;/li&gt; 
  &lt;li&gt;If you encounter conflicts with other Python versions, consider uninstalling them: &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;# List all installed Python versions
brew list | grep python

# Uninstall conflicting versions if needed
brew uninstall --ignore-dependencies python@3.11 python@3.13

# Keep only Python 3.10
brew cleanup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Legacy)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start=&quot;2&quot;&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;DirectML Execution Provider (Windows)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.15.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start=&quot;2&quot;&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python run.py --execution-provider directml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;OpenVINO™ Execution Provider (Intel)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.15.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start=&quot;2&quot;&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;python run.py --execution-provider openvino
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Image/Video Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a source face image and a target image/video.&lt;/li&gt; 
 &lt;li&gt;Click &quot;Start&quot;.&lt;/li&gt; 
 &lt;li&gt;The output will be saved in a directory named after the target video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Webcam Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select a source face image.&lt;/li&gt; 
 &lt;li&gt;Click &quot;Live&quot;.&lt;/li&gt; 
 &lt;li&gt;Wait for the preview to appear (10-30 seconds).&lt;/li&gt; 
 &lt;li&gt;Use a screen capture tool like OBS to stream.&lt;/li&gt; 
 &lt;li&gt;To change the face, select a new source image.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tips and Tricks&lt;/h2&gt; 
&lt;p&gt;Check out these helpful guides to get the most out of Deep-Live-Cam:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://deeplivecam.net/index.php/blog/tips-and-tricks/unlocking-the-secrets-to-the-perfect-deepfake-image&quot;&gt;Unlocking the Secrets to the Perfect Deepfake Image&lt;/a&gt; - Learn how to create the best deepfake with full head coverage&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://deeplivecam.net/index.php/blog/tips-and-tricks/video-call-with-deeplivecam&quot;&gt;Video Call with DeepLiveCam&lt;/a&gt; - Make your meetings livelier by using DeepLiveCam with OBS and meeting software&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://deeplivecam.net/index.php/blog/tips-and-tricks/have-a-special-guest&quot;&gt;Have a Special Guest!&lt;/a&gt; - Tutorial on how to use face mapping to add special guests to your stream&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://deeplivecam.net/index.php/blog/tips-and-tricks/watch-deepfake-movies-in-realtime&quot;&gt;Watch Deepfake Movies in Realtime&lt;/a&gt; - See yourself star in any video without processing the video&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://deeplivecam.net/index.php/blog/tips-and-tricks/better-quality-without-sacrificing-speed&quot;&gt;Better Quality without Sacrificing Speed&lt;/a&gt; - Tips for achieving better results without impacting performance&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://deeplivecam.net/index.php/blog/tips-and-tricks/instant-vtuber&quot;&gt;Instant Vtuber!&lt;/a&gt; - Create a new persona/vtuber easily using Metahuman Creator&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Visit our &lt;a href=&quot;https://deeplivecam.net/index.php/blog/tips-and-tricks&quot;&gt;official blog&lt;/a&gt; for more tips and tutorials.&lt;/p&gt; 
&lt;h2&gt;Command Line Arguments (Unmaintained)&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program&#39;s version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.&lt;/p&gt; 
&lt;h2&gt;Press&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We are always open to criticism and are ready to improve, that&#39;s why we didn&#39;t cherry-pick anything.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/&quot;&gt;&lt;em&gt;&quot;Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger&quot;&lt;/em&gt;&lt;/a&gt; - Ars Technica&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/&quot;&gt;&lt;em&gt;&quot;Thanks Deep Live Cam, shapeshifters are among us now&quot;&lt;/em&gt;&lt;/a&gt; - Dataconomy&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story&quot;&gt;&lt;em&gt;&quot;This free AI tool lets you become anyone during video-calls&quot;&lt;/em&gt;&lt;/a&gt; - NewsBytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying&quot;&gt;&lt;em&gt;&quot;OK, this viral AI live stream software is truly terrifying&quot;&lt;/em&gt;&lt;/a&gt; - Creative Bloq&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/&quot;&gt;&lt;em&gt;&quot;Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo&quot;&lt;/em&gt;&lt;/a&gt; - PetaPixel&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.techeblog.com/deep-live-cam-ai-transform-face/&quot;&gt;&lt;em&gt;&quot;Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included&quot;&lt;/em&gt;&lt;/a&gt; - TechEBlog&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/&quot;&gt;&lt;em&gt;&quot;An AI tool that &quot;makes you look like anyone&quot; during a video call is going viral online&quot;&lt;/em&gt;&lt;/a&gt; - Telegrafi&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts&quot;&gt;&lt;em&gt;&quot;This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts&quot;&lt;/em&gt;&lt;/a&gt; - Emerge&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/&quot;&gt;&lt;em&gt;&quot;New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces&quot;&lt;/em&gt;&lt;/a&gt; - Digital Music News&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/&quot;&gt;&lt;em&gt;&quot;This real-time webcam deepfake tool raises alarms about the future of identity theft&quot;&lt;/em&gt;&lt;/a&gt; - DIYPhotography&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?time_continue=1074&amp;amp;v=py4Tc-Y8BcY&quot;&gt;&lt;em&gt;&quot;That&#39;s Crazy, Oh God. That&#39;s Fucking Freaky Dude... That&#39;s So Wild Dude&quot;&lt;/em&gt;&lt;/a&gt; - SomeOrdinaryGamers&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;amp;t=2686&quot;&gt;&lt;em&gt;&quot;Alright look look look, now look chat, we can do any face we want to look like chat&quot;&lt;/em&gt;&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://ffmpeg.org/&quot;&gt;ffmpeg&lt;/a&gt;: for making video-related operations easy&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/deepinsight&quot;&gt;deepinsight&lt;/a&gt;: for their &lt;a href=&quot;https://github.com/deepinsight/insightface&quot;&gt;insightface&lt;/a&gt; project which provided a well-made library and models. Please be reminded that the &lt;a href=&quot;https://github.com/deepinsight/insightface?tab=readme-ov-file#license&quot;&gt;use of the model is for non-commercial research purposes only&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/havok2-htwo&quot;&gt;havok2-htwo&lt;/a&gt;: for sharing the code for webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/GosuDRM&quot;&gt;GosuDRM&lt;/a&gt;: for the open version of roop&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/pereiraroland26&quot;&gt;pereiraroland26&lt;/a&gt;: Multiple faces support&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/vic4key&quot;&gt;vic4key&lt;/a&gt;: For supporting/contributing to this project&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/kier007&quot;&gt;kier007&lt;/a&gt;: for improving the user experience&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/qitianai&quot;&gt;qitianai&lt;/a&gt;: for multi-lingual support&lt;/li&gt; 
 &lt;li&gt;and &lt;a href=&quot;https://github.com/hacksider/Deep-Live-Cam/graphs/contributors&quot;&gt;all developers&lt;/a&gt; behind libraries used in this project.&lt;/li&gt; 
 &lt;li&gt;Footnote: Please be informed that the base author of the code is &lt;a href=&quot;https://github.com/s0md3v/roop&quot;&gt;s0md3v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All the wonderful users who helped make this project go viral by starring the repo ❤️&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/hacksider/Deep-Live-Cam/stargazers&quot;&gt;&lt;img src=&quot;https://reporoster.com/stars/hacksider/Deep-Live-Cam&quot; alt=&quot;Stargazers&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true&quot; alt=&quot;Alt&quot; title=&quot;Repobeats analytics image&quot;&gt;&lt;/p&gt; 
&lt;h2&gt;Stars to the Moon 🚀&lt;/h2&gt; 
&lt;a href=&quot;https://star-history.com/#hacksider/deep-live-cam&amp;amp;Date&quot;&gt; 
 &lt;picture&gt; 
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&amp;amp;theme=dark&quot;&gt; 
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&quot;&gt; 
  &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&quot;&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/TensorRT-LLM</title>
      <link>https://github.com/NVIDIA/TensorRT-LLM</link>
      <description>&lt;p&gt;TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines.&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;h1&gt;TensorRT-LLM&lt;/h1&gt; 
 &lt;h4&gt; A TensorRT Toolbox for Optimized Large Language Model Inference&lt;/h4&gt; 
 &lt;p&gt;&lt;a href=&quot;https://nvidia.github.io/TensorRT-LLM/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-latest-brightgreen.svg?style=flat&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.python.org/downloads/release/python-3123/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/python-3.12-green&quot; alt=&quot;python&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.python.org/downloads/release/python-31012/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/python-3.10-green&quot; alt=&quot;python&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://developer.nvidia.com/cuda-downloads&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/cuda-12.8.0-green&quot; alt=&quot;cuda&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://developer.nvidia.com/tensorrt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/TRT-10.8.0-green&quot; alt=&quot;trt&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/tensorrt_llm/version.py&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/release-0.19.0.dev-green&quot; alt=&quot;version&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202-blue&quot; alt=&quot;license&quot;&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/architecture/overview.md&quot;&gt;Architecture&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/performance/perf-overview.md&quot;&gt;Performance&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/examples/&quot;&gt;Examples&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/&quot;&gt;Documentation&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&quot;https://docs.google.com/presentation/d/1gycPmtdh7uUcH6laOvW65Dbp9F1McUkGDIcAyjicBZs/edit?usp=sharing&quot;&gt;Roadmap&lt;/a&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;div align=&quot;left&quot;&gt; 
  &lt;h2&gt;Latest News&lt;/h2&gt; 
  &lt;ul&gt; 
   &lt;li&gt;[2025/02/28] Spotlight🌟🌟🌟 NAVER Place Optimizes SLM-Based Vertical Services with NVIDIA TensorRT-LLM &lt;a href=&quot;https://developer.nvidia.com/blog/spotlight-naver-place-optimizes-slm-based-vertical-services-with-nvidia-tensorrt-llm/&quot;&gt;➡️ link&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;div align=&quot;center&quot;&gt; 
   &lt;img src=&quot;https://developer-blogs.nvidia.com/wp-content/uploads/2025/02/naver-place-app-graphic.jpg&quot; width=&quot;50%&quot;&gt; 
   &lt;div align=&quot;left&quot;&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;[2025/02/25] 🌟 DeepSeek-R1 performance now optimized for Blackwell &lt;a href=&quot;https://huggingface.co/nvidia/DeepSeek-R1-FP4&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/02/20] Stay ahead of the curve 📈 Leverage the most performant &amp;amp; capable platform for inference. 🚀Explore the complete guide to achieve great accuracy, high throughput, and low latency at the lowest cost for your business ➡️ &lt;a href=&quot;https://www.nvidia.com/en-us/solutions/ai/inference/balancing-cost-latency-and-performance-ebook/?ncid=so-twit-348956&amp;amp;linkId=100000341423615&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/02/18] Unlock #LLM inference with auto-scaling on @AWS EKS ✨ ✅ Set up EFA networking &amp;amp; EFS storage with NVLink-connected H100 GPUs on P5.48xlarge ✅ Deploy multi-node Triton Inference Server + TRT-LLM to scale LLaMa 3.1 405B models ✅ Use LeaderWorkerSet &amp;amp; Prometheus metrics for autoscaling and orchestration &lt;a href=&quot;https://aws.amazon.com/blogs/hpc/scaling-your-llm-inference-workloads-multi-node-deployment-with-tensorrt-llm-and-triton-on-amazon-eks/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/02/12] 🦸⚡ Automating GPU Kernel Generation with DeepSeek-R1 and Inference Time Scaling &lt;a href=&quot;https://developer.nvidia.com/blog/automating-gpu-kernel-generation-with-deepseek-r1-and-inference-time-scaling/?ncid=so-twit-997075&amp;amp;linkId=100000338909937&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/02/12] 🌟 How Scaling Laws Drive Smarter, More Powerful AI &lt;a href=&quot;https://blogs.nvidia.com/blog/ai-scaling-laws/?ncid=so-link-889273&amp;amp;linkId=100000338837832&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/01/25] 🌟 Nvidia moves AI focus to inference cost, efficiency 🌟 &lt;a href=&quot;https://www.fierceelectronics.com/ai/nvidia-moves-ai-focus-inference-cost-efficiency?linkId=100000332985606&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/01/24] 🏎️🏎️🏎️ Optimize AI Inference Performance with NVIDIA Full-Stack Solutions &lt;a href=&quot;https://developer.nvidia.com/blog/optimize-ai-inference-performance-with-nvidia-full-stack-solutions/?ncid=so-twit-400810&amp;amp;linkId=100000332621049&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/01/23] 🚀🚀🚀 Fast, Low-Cost Inference Offers Key to Profitable AI &lt;a href=&quot;https://blogs.nvidia.com/blog/ai-inference-platform/?ncid=so-twit-693236-vt04&amp;amp;linkId=100000332307804&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/01/16] 🐍 Introducing New KV Cache Reuse Optimizations in NVIDIA TensorRT-LLM &lt;a href=&quot;https://developer.nvidia.com/blog/introducing-new-kv-cache-reuse-optimizations-in-nvidia-tensorrt-llm/?ncid=so-twit-363876&amp;amp;linkId=100000330323229&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/01/14] 📣 Bing&#39;s Transition to LLM/SLM Models: Optimizing Search with TensorRT-LLM &lt;a href=&quot;https://blogs.bing.com/search-quality-insights/December-2024/Bing-s-Transition-to-LLM-SLM-Models-Optimizing-Search-with-TensorRT-LLM&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;[2025/01/04] ⚡Boost Llama 3.3 70B Inference Throughput 3x with NVIDIA TensorRT-LLM Speculative Decoding &lt;a href=&quot;https://developer.nvidia.com/blog/boost-llama-3-3-70b-inference-throughput-3x-with-nvidia-tensorrt-llm-speculative-decoding/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;details close&gt; 
     &lt;summary&gt;Previous News&lt;/summary&gt; 
     &lt;ul&gt; 
      &lt;li&gt; &lt;p&gt;[2024/12/10] ⚡ Llama 3.3 70B from AI at Meta is accelerated by TensorRT-LLM. 🌟 State-of-the-art model on par with Llama 3.1 405B for reasoning, math, instruction following and tool use. Explore the preview &lt;a href=&quot;https://build.nvidia.com/meta/llama-3_3-70b-instruct&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/12/03] 🌟 Boost your AI inference throughput by up to 3.6x. We now support speculative decoding and tripling token throughput with our NVIDIA TensorRT-LLM. Perfect for your generative AI apps. ⚡Learn how in this technical deep dive &lt;a href=&quot;https://nvda.ws/3ZCZTzD&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/12/02] Working on deploying ONNX models for performance-critical applications? Try our NVIDIA Nsight Deep Learning Designer ⚡ A user-friendly GUI and tight integration with NVIDIA TensorRT that offers: ✅ Intuitive visualization of ONNX model graphs ✅ Quick tweaking of model architecture and parameters ✅ Detailed performance profiling with either ORT or TensorRT ✅ Easy building of TensorRT engines &lt;a href=&quot;https://developer.nvidia.com/nsight-dl-designer?ncid=so-link-485689&amp;amp;linkId=100000315016072&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/11/26] 📣 Introducing TensorRT-LLM for Jetson AGX Orin, making it even easier to deploy on Jetson AGX Orin with initial support in JetPack 6.1 via the v0.12.0-jetson branch of the TensorRT-LLM repo. ✅ Pre-compiled TensorRT-LLM wheels &amp;amp; containers for easy integration ✅ Comprehensive guides &amp;amp; docs to get you started &lt;a href=&quot;https://forums.developer.nvidia.com/t/tensorrt-llm-for-jetson/313227?linkId=100000312718869&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/11/21] NVIDIA TensorRT-LLM Multiblock Attention Boosts Throughput by More Than 3x for Long Sequence Lengths on NVIDIA HGX H200 &lt;a href=&quot;https://developer.nvidia.com/blog/nvidia-tensorrt-llm-multiblock-attention-boosts-throughput-by-more-than-3x-for-long-sequence-lengths-on-nvidia-hgx-h200/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/11/19] Llama 3.2 Full-Stack Optimizations Unlock High Performance on NVIDIA GPUs &lt;a href=&quot;https://developer.nvidia.com/blog/llama-3-2-full-stack-optimizations-unlock-high-performance-on-nvidia-gpus/?ncid=so-link-721194&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/11/09] 🚀🚀🚀 3x Faster AllReduce with NVSwitch and TensorRT-LLM MultiShot &lt;a href=&quot;https://developer.nvidia.com/blog/3x-faster-allreduce-with-nvswitch-and-tensorrt-llm-multishot/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/11/09] ✨ NVIDIA advances the AI ecosystem with the AI model of LG AI Research 🙌 &lt;a href=&quot;https://blogs.nvidia.co.kr/blog/nvidia-lg-ai-research/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/11/02] 🌟🌟🌟 NVIDIA and LlamaIndex Developer Contest 🙌 Enter for a chance to win prizes including an NVIDIA® GeForce RTX™ 4080 SUPER GPU, DLI credits, and more🙌 &lt;a href=&quot;https://developer.nvidia.com/llamaindex-developer-contest&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/10/28] 🏎️🏎️🏎️ NVIDIA GH200 Superchip Accelerates Inference by 2x in Multiturn Interactions with Llama Models &lt;a href=&quot;https://developer.nvidia.com/blog/nvidia-gh200-superchip-accelerates-inference-by-2x-in-multiturn-interactions-with-llama-models/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/10/22] New 📝 Step-by-step instructions on how to ✅ Optimize LLMs with NVIDIA TensorRT-LLM, ✅ Deploy the optimized models with Triton Inference Server, ✅ Autoscale LLMs deployment in a Kubernetes environment. 🙌 Technical Deep Dive: &lt;a href=&quot;https://nvda.ws/3YgI8UT&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/10/07] 🚀🚀🚀Optimizing Microsoft Bing Visual Search with NVIDIA Accelerated Libraries &lt;a href=&quot;https://developer.nvidia.com/blog/optimizing-microsoft-bing-visual-search-with-nvidia-accelerated-libraries/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/09/29] 🌟 AI at Meta PyTorch + TensorRT v2.4 🌟 ⚡TensorRT 10.1 ⚡PyTorch 2.4 ⚡CUDA 12.4 ⚡Python 3.12 &lt;a href=&quot;https://github.com/pytorch/TensorRT/releases/tag/v2.4.0&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/09/17] ✨ NVIDIA TensorRT-LLM Meetup &lt;a href=&quot;https://drive.google.com/file/d/1RR8GqC-QbuaKuHj82rZcXb3MS20SWo6F/view?usp=share_link&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/09/17] ✨ Accelerating LLM Inference at Databricks with TensorRT-LLM &lt;a href=&quot;https://drive.google.com/file/d/1NeSmrLaWRJAY1rxD9lJmzpB9rzr38j8j/view?usp=sharing&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/09/17] ✨ TensorRT-LLM @ Baseten &lt;a href=&quot;https://drive.google.com/file/d/1Y7L2jqW-aRmt31mCdqhwvGMmCSOzBUjG/view?usp=share_link&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/09/04] 🏎️🏎️🏎️ Best Practices for Tuning TensorRT-LLM for Optimal Serving with BentoML &lt;a href=&quot;https://www.bentoml.com/blog/tuning-tensor-rt-llm-for-optimal-serving-with-bentoml&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/08/20] 🏎️SDXL with #TensorRT Model Optimizer ⏱️⚡ 🏁 cache diffusion 🏁 quantization aware training 🏁 QLoRA 🏁 #Python 3.12 &lt;a href=&quot;https://developer.nvidia.com/blog/nvidia-tensorrt-model-optimizer-v0-15-boosts-inference-performance-and-expands-model-support/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/08/13] 🐍 DIY Code Completion with #Mamba ⚡ #TensorRT #LLM for speed 🤖 NIM for ease ☁️ deploy anywhere &lt;a href=&quot;https://developer.nvidia.com/blog/revolutionizing-code-completion-with-codestral-mamba-the-next-gen-coding-llm/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/08/06] 🗫 Multilingual Challenge Accepted 🗫 🤖 #TensorRT #LLM boosts low-resource languages like Hebrew, Indonesian and Vietnamese ⚡&lt;a href=&quot;https://developer.nvidia.com/blog/accelerating-hebrew-llm-performance-with-nvidia-tensorrt-llm/?linkId=100000278659647&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/07/30] Introducing🍊 @SliceXAI ELM Turbo 🤖 train ELM once ⚡ #TensorRT #LLM optimize ☁️ deploy anywhere &lt;a href=&quot;https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/07/23] 👀 @AIatMeta Llama 3.1 405B trained on 16K NVIDIA H100s - inference is #TensorRT #LLM optimized ⚡ 🦙 400 tok/s - per node 🦙 37 tok/s - per user 🦙 1 node inference &lt;a href=&quot;https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/07/09] Checklist to maximize multi-language performance of @meta #Llama3 with #TensorRT #LLM inference: ✅ MultiLingual ✅ NIM ✅ LoRA tuned adaptors&lt;a href=&quot;https://developer.nvidia.com/blog/deploy-multilingual-llms-with-nvidia-nim/&quot;&gt;➡️ Tech blog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/07/02] Let the @MistralAI MoE tokens fly 📈 🚀 #Mixtral 8x7B with NVIDIA #TensorRT #LLM on #H100. &lt;a href=&quot;https://developer.nvidia.com/blog/achieving-high-mixtral-8x7b-performance-with-nvidia-h100-tensor-core-gpus-and-tensorrt-llm?ncid=so-twit-928467&quot;&gt;➡️ Tech blog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/06/24] Enhanced with NVIDIA #TensorRT #LLM, @upstage.ai’s solar-10.7B-instruct is ready to power your developer projects through our API catalog 🏎️. ✨&lt;a href=&quot;https://build.nvidia.com/upstage/solar-10_7b-instruct?snippet_tab=Try&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/06/18] CYMI: 🤩 Stable Diffusion 3 dropped last week 🎊 🏎️ Speed up your SD3 with #TensorRT INT8 Quantization&lt;a href=&quot;https://build.nvidia.com/upstage/solar-10_7b-instruct?snippet_tab=Try&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/06/18] 🧰Deploying ComfyUI with TensorRT? Here’s your setup guide &lt;a href=&quot;https://github.com/comfyanonymous/ComfyUI_TensorRT&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/06/11] ✨#TensorRT Weight-Stripped Engines ✨ Technical Deep Dive for serious coders ✅+99% compression ✅1 set of weights → ** GPUs ✅0 performance loss ✅** models…LLM, CNN, etc.&lt;a href=&quot;https://developer.nvidia.com/blog/maximum-performance-and-minimum-footprint-for-ai-apps-with-nvidia-tensorrt-weight-stripped-engines/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/06/04] ✨ #TensorRT and GeForce #RTX unlock ComfyUI SD superhero powers 🦸⚡ 🎥 Demo: &lt;a href=&quot;https://youtu.be/64QEVfbPHyg&quot;&gt;➡️ link&lt;/a&gt; 📗 DIY notebook: &lt;a href=&quot;https://console.brev.dev/launchable/deploy?userID=2x2sil999&amp;amp;orgID=ktj33l4xj&amp;amp;name=ComfyUI_TensorRT&amp;amp;instance=L4%40g2-standard-4%3Anvidia-l4%3A1&amp;amp;diskStorage=500&amp;amp;cloudID=GCP&amp;amp;baseImage=docker.io%2Fpytorch%2Fpytorch%3A2.2.0-cuda12.1-cudnn8-runtime&amp;amp;ports=ComfUI%3A8188&amp;amp;file=https%3A%2F%2Fgithub.com%2Fbrevdev%2Fnotebooks%2Fblob%2Fmain%2Ftensorrt-comfyui.ipynb&amp;amp;launchableID=env-2hQX3n7ae5mq3NjNZ32DfAG0tJf&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/05/28] ✨#TensorRT weight stripping for ResNet-50 ✨ ✅+99% compression ✅1 set of weights → ** GPUs\ ✅0 performance loss ✅** models…LLM, CNN, etc 👀 📚 DIY &lt;a href=&quot;https://console.brev.dev/launchable/deploy?userID=2x2sil999&amp;amp;orgID=ktj33l4xj&amp;amp;launchableID=env-2h6bym7h5GFNho3vpWQQeUYMwTM&amp;amp;instance=L4%40g6.xlarge&amp;amp;diskStorage=500&amp;amp;cloudID=devplane-brev-1&amp;amp;baseImage=nvcr.io%2Fnvidia%2Ftensorrt%3A24.05-py3&amp;amp;file=https%3A%2F%2Fgithub.com%2FNVIDIA%2FTensorRT%2Fblob%2Frelease%2F10.0%2Fsamples%2Fpython%2Fsample_weight_stripping%2Fnotebooks%2Fweight_stripping.ipynb&amp;amp;name=tensorrt_weight_stripping_resnet50&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/05/21] ✨@modal_labs has the codes for serverless @AIatMeta Llama 3 on #TensorRT #LLM ✨👀 📚 Marvelous Modal Manual: Serverless TensorRT-LLM (LLaMA 3 8B) | Modal Docs &lt;a href=&quot;https://modal.com/docs/examples/trtllm_llama&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/05/08] NVIDIA TensorRT Model Optimizer -- the newest member of the #TensorRT ecosystem is a library of post-training and training-in-the-loop model optimization techniques ✅quantization ✅sparsity ✅QAT &lt;a href=&quot;https://developer.nvidia.com/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/&quot;&gt;➡️ blog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/05/07] 🦙🦙🦙 24,000 tokens per second 🛫Meta Llama 3 takes off with #TensorRT #LLM 📚&lt;a href=&quot;https://blogs.nvidia.com/blog/meta-llama3-inference-acceleration/&quot;&gt;➡️ link&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/02/06] &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/blogs/quantization-in-TRT-LLM.md&quot;&gt;🚀 Speed up inference with SOTA quantization techniques in TRT-LLM&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2024/01/30] &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/blogs/XQA-kernel.md&quot;&gt; New XQA-kernel provides 2.4x more Llama-70B throughput within the same latency budget&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2023/12/04] &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/blogs/Falcon180B-H200.md&quot;&gt;Falcon-180B on a single H200 GPU with INT4 AWQ, and 6.7x faster Llama-70B over A100&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2023/11/27] &lt;a href=&quot;https://aws.amazon.com/blogs/machine-learning/boost-inference-performance-for-llms-with-new-amazon-sagemaker-containers/&quot;&gt;SageMaker LMI now supports TensorRT-LLM - improves throughput by 60%, compared to previous version&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2023/11/13] &lt;a href=&quot;https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/docs/source/blogs/H200launch.md&quot;&gt;H200 achieves nearly 12,000 tok/sec on Llama2-13B&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2023/10/22] &lt;a href=&quot;https://github.com/NVIDIA/trt-llm-rag-windows#readme&quot;&gt;🚀 RAG on Windows using TensorRT-LLM and LlamaIndex 🦙&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2023/10/19] Getting Started Guide - &lt;a href=&quot;https://developer.nvidia.com/blog/optimizing-inference-on-llms-with-tensorrt-llm-now-publicly-available/&quot;&gt;Optimizing Inference on Large Language Models with NVIDIA TensorRT-LLM, Now Publicly Available &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;[2023/10/17] &lt;a href=&quot;https://blogs.nvidia.com/blog/2023/10/17/tensorrt-llm-windows-stable-diffusion-rtx/&quot;&gt;Large Language Models up to 4x Faster on RTX With TensorRT-LLM for Windows &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;/ul&gt; 
    &lt;/details&gt; 
    &lt;h2&gt;TensorRT-LLM Overview&lt;/h2&gt; 
    &lt;p&gt;TensorRT-LLM is a library for optimizing Large Language Model (LLM) inference. It provides state-of-the-art optimizations, including custom attention kernels, inflight batching, paged KV caching, quantization (FP8, INT4 &lt;a href=&quot;https://arxiv.org/abs/2306.00978&quot;&gt;AWQ&lt;/a&gt;, INT8 &lt;a href=&quot;https://arxiv.org/abs/2211.10438&quot;&gt;SmoothQuant&lt;/a&gt;, ++) and much more, to perform inference efficiently on NVIDIA GPUs&lt;/p&gt; 
    &lt;p&gt;TensorRT-LLM provides a Python API to build LLMs into optimized &lt;a href=&quot;https://developer.nvidia.com/tensorrt&quot;&gt;TensorRT&lt;/a&gt; engines. It contains runtimes in Python (bindings) and C++ to execute those TensorRT engines. It also includes a &lt;a href=&quot;https://github.com/triton-inference-server/tensorrtllm_backend&quot;&gt;backend&lt;/a&gt; for integration with the &lt;a href=&quot;https://developer.nvidia.com/nvidia-triton-inference-server&quot;&gt;NVIDIA Triton Inference Server&lt;/a&gt;. Models built with TensorRT-LLM can be executed on a wide range of configurations from a single GPU to multiple nodes with multiple GPUs (using &lt;a href=&quot;https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/features/parallelisms.html#tensor-parallelism&quot;&gt;Tensor Parallelism&lt;/a&gt; and/or &lt;a href=&quot;https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/features/parallelisms.html#pipeline-parallelism&quot;&gt;Pipeline Parallelism&lt;/a&gt;).&lt;/p&gt; 
    &lt;p&gt;TensorRT-LLM comes with several popular models pre-defined. They can easily be modified and extended to fit custom needs via a PyTorch-like Python API. Refer to the &lt;a href=&quot;https://nvidia.github.io/TensorRT-LLM/reference/support-matrix.html&quot;&gt;Support Matrix&lt;/a&gt; for a list of supported models.&lt;/p&gt; 
    &lt;p&gt;TensorRT-LLM is built on top of the &lt;a href=&quot;https://developer.nvidia.com/tensorrt&quot;&gt;TensorRT&lt;/a&gt; Deep Learning Inference library. It leverages much of TensorRT&#39;s deep learning optimizations and adds LLM-specific optimizations on top, as described above. TensorRT is an ahead-of-time compiler; it builds &quot;&lt;a href=&quot;https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html#ecosystem&quot;&gt;Engines&lt;/a&gt;&quot; which are optimized representations of the compiled model containing the entire execution graph. These engines are optimized for a specific GPU architecture, and can be validated, benchmarked, and serialized for later deployment in a production environment.&lt;/p&gt; 
    &lt;h2&gt;Getting Started&lt;/h2&gt; 
    &lt;p&gt;To get started with TensorRT-LLM, visit our documentation:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://nvidia.github.io/TensorRT-LLM/quick-start-guide.html&quot;&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://nvidia.github.io/TensorRT-LLM/release-notes.html&quot;&gt;Release Notes&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://nvidia.github.io/TensorRT-LLM/installation/linux.html&quot;&gt;Installation Guide for Linux&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://nvidia.github.io/TensorRT-LLM/installation/grace-hopper.html&quot;&gt;Installation Guide for Grace Hopper&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://nvidia.github.io/TensorRT-LLM/reference/support-matrix.html&quot;&gt;Supported Hardware, Models, and other Software&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;h2&gt;Community&lt;/h2&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://huggingface.co/TheFloat16&quot;&gt;Model zoo&lt;/a&gt; (generated by TRT-LLM rel 0.9 a9356d4b7610330e89c1010f342a9ac644215c52)&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt;
  &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>lastmile-ai/mcp-agent</title>
      <link>https://github.com/lastmile-ai/mcp-agent</link>
      <description>&lt;p&gt;Build effective agents using Model Context Protocol and simple workflow patterns&lt;/p&gt;&lt;hr&gt;&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;https://github.com/user-attachments/assets/6f4e40c4-dc88-47b6-b965-5856b69416d2&quot; alt=&quot;Logo&quot; width=&quot;300&quot;&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;em&gt;Build effective agents with Model Context Protocol using simple, composable patterns.&lt;/em&gt; &lt;/p&gt;
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://github.com/lastmile-ai/mcp-agent/tree/main/examples&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://www.anthropic.com/research/building-effective-agents&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;Building Effective Agents&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&quot;https://modelcontextprotocol.io/introduction&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;MCP&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a href=&quot;https://pypi.org/project/mcp-agent/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/mcp-agent?color=%2334D058&amp;amp;label=pypi&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/lastmile-ai/mcp-agent/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-raw/lastmile-ai/mcp-agent&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://lmai.link/discord/mcp-agent&quot;&gt;&lt;img src=&quot;https://shields.io/discord/1089284610329952357&quot; alt=&quot;discord&quot;&gt;&lt;/a&gt; &lt;img alt=&quot;Pepy Total Downloads&quot; src=&quot;https://img.shields.io/pepy/dt/mcp-agent?label=pypi%20%7C%20downloads&quot;&gt; &lt;a href=&quot;https://github.com/lastmile-ai/mcp-agent/raw/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/l/mcp-agent&quot;&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;mcp-agent&lt;/code&gt;&lt;/strong&gt; is a simple, composable framework to build agents using &lt;a href=&quot;https://modelcontextprotocol.io/introduction&quot;&gt;Model Context Protocol&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Inspiration&lt;/strong&gt;: Anthropic announced 2 foundational updates for AI application developers:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.anthropic.com/news/model-context-protocol&quot;&gt;Model Context Protocol&lt;/a&gt; - a standardized interface to let any software be accessible to AI assistants via MCP servers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.anthropic.com/research/building-effective-agents&quot;&gt;Building Effective Agents&lt;/a&gt; - a seminal writeup on simple, composable patterns for building production-ready AI agents.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;mcp-agent&lt;/code&gt; puts these two foundational pieces into an AI application framework:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;It handles the pesky business of managing the lifecycle of MCP server connections so you don&#39;t have to.&lt;/li&gt; 
 &lt;li&gt;It implements every pattern described in Building Effective Agents, and does so in a &lt;em&gt;composable&lt;/em&gt; way, allowing you to chain these patterns together.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bonus&lt;/strong&gt;: It implements &lt;a href=&quot;https://github.com/openai/swarm&quot;&gt;OpenAI&#39;s Swarm&lt;/a&gt; pattern for multi-agent orchestration, but in a model-agnostic way.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Altogether, this is the simplest and easiest way to build robust agent applications. Much like MCP, this project is in early development. We welcome all kinds of &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/CONTRIBUTING.md&quot;&gt;contributions&lt;/a&gt;, feedback and your help in growing this to become a new standard.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;We recommend using &lt;a href=&quot;https://docs.astral.sh/uv/&quot;&gt;uv&lt;/a&gt; to manage your Python projects:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;uv add &quot;mcp-agent&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;pip install mcp-agent
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Quickstart&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples&quot;&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; directory has several example applications to get started with. To run an example, clone this repo, then:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;cd examples/mcp_basic_agent # Or any other example
cp mcp_agent.secrets.yaml.example mcp_agent.secrets.yaml # Update API keys
uv run main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Here is a basic &quot;finder&quot; agent that uses the fetch and filesystem servers to look up a file, read a blog and write a tweet. &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/mcp_basic_agent/&quot;&gt;Example link&lt;/a&gt;:&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;finder_agent.py&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import asyncio
import os

from mcp_agent.app import MCPApp
from mcp_agent.agents.agent import Agent
from mcp_agent.workflows.llm.augmented_llm_openai import OpenAIAugmentedLLM

app = MCPApp(name=&quot;hello_world_agent&quot;)

async def example_usage():
    async with app.run() as mcp_agent_app:
        logger = mcp_agent_app.logger
        # This agent can read the filesystem or fetch URLs
        finder_agent = Agent(
            name=&quot;finder&quot;,
            instruction=&quot;&quot;&quot;You can read local files or fetch URLs.
                Return the requested information when asked.&quot;&quot;&quot;,
            server_names=[&quot;fetch&quot;, &quot;filesystem&quot;], # MCP servers this Agent can use
        )

        async with finder_agent:
            # Automatically initializes the MCP servers and adds their tools for LLM use
            tools = await finder_agent.list_tools()
            logger.info(f&quot;Tools available:&quot;, data=tools)

            # Attach an OpenAI LLM to the agent (defaults to GPT-4o)
            llm = await finder_agent.attach_llm(OpenAIAugmentedLLM)

            # This will perform a file lookup and read using the filesystem server
            result = await llm.generate_str(
                message=&quot;Show me what&#39;s in README.md verbatim&quot;
            )
            logger.info(f&quot;README.md contents: {result}&quot;)

            # Uses the fetch server to fetch the content from URL
            result = await llm.generate_str(
                message=&quot;Print the first two paragraphs from https://www.anthropic.com/research/building-effective-agents&quot;
            )
            logger.info(f&quot;Blog intro: {result}&quot;)

            # Multi-turn interactions by default
            result = await llm.generate_str(&quot;Summarize that in a 128-char tweet&quot;)
            logger.info(f&quot;Tweet: {result}&quot;)

if __name__ == &quot;__main__&quot;:
    asyncio.run(example_usage())

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;mcp_agent.config.yaml&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;execution_engine: asyncio
logger:
  transports: [console]  # You can use [file, console] for both
  level: debug
  path: &quot;logs/mcp-agent.jsonl&quot;  # Used for file transport
  # For dynamic log filenames:
  # path_settings:
  #   path_pattern: &quot;logs/mcp-agent-{unique_id}.jsonl&quot;
  #   unique_id: &quot;timestamp&quot;  # Or &quot;session_id&quot;
  #   timestamp_format: &quot;%Y%m%d_%H%M%S&quot;

mcp:
  servers:
    fetch:
      command: &quot;uvx&quot;
      args: [&quot;mcp-server-fetch&quot;]
    filesystem:
      command: &quot;npx&quot;
      args:
        [
          &quot;-y&quot;,
          &quot;@modelcontextprotocol/server-filesystem&quot;,
          &quot;&amp;lt;add_your_directories&amp;gt;&quot;,
        ]

openai:
  # Secrets (API keys, etc.) are stored in an mcp_agent.secrets.yaml file which can be gitignored
  default_model: gpt-4o
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Agent output&lt;/summary&gt; 
 &lt;img width=&quot;2398&quot; alt=&quot;Image&quot; src=&quot;https://github.com/user-attachments/assets/eaa60fdf-bcc6-460b-926e-6fa8534e9089&quot;&gt; 
&lt;/details&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#why-use-mcp-agent&quot;&gt;Why use mcp-agent?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#examples&quot;&gt;Example Applications&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#claude-desktop&quot;&gt;Claude Desktop&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#streamlit&quot;&gt;Streamlit&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#gmail-agent&quot;&gt;Gmail Agent&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#simple-rag-chatbot&quot;&gt;RAG&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#marimo&quot;&gt;Marimo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#python&quot;&gt;Python&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#swarm&quot;&gt;Swarm (CLI)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#core-components&quot;&gt;Core Concepts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#workflows&quot;&gt;Workflows Patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#augmentedllm&quot;&gt;Augmented LLM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#parallel&quot;&gt;Parallel&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#router&quot;&gt;Router&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#intentclassifier&quot;&gt;Intent-Classifier&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#orchestrator-workers&quot;&gt;Orchestrator-Workers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#evaluator-optimizer&quot;&gt;Evaluator-Optimizer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#swarm-1&quot;&gt;OpenAI Swarm&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#advanced&quot;&gt;Advanced&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#composability&quot;&gt;Composing multiple workflows&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#signaling-and-human-input&quot;&gt;Signaling and Human input&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#app-config&quot;&gt;App Config&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#mcp-server-management&quot;&gt;MCP Server Management&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#roadmap&quot;&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#faqs&quot;&gt;FAQs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why use &lt;code&gt;mcp-agent&lt;/code&gt;?&lt;/h2&gt; 
&lt;p&gt;There are too many AI frameworks out there already. But &lt;code&gt;mcp-agent&lt;/code&gt; is the only one that is purpose-built for a shared protocol - &lt;a href=&quot;https://modelcontextprotocol.io/introduction&quot;&gt;MCP&lt;/a&gt;. It is also the most lightweight, and is closer to an agent pattern library than a framework.&lt;/p&gt; 
&lt;p&gt;As &lt;a href=&quot;https://github.com/punkpeye/awesome-mcp-servers&quot;&gt;more services become MCP-aware&lt;/a&gt;, you can use mcp-agent to build robust and controllable AI agents that can leverage those services out-of-the-box.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Before we go into the core concepts of mcp-agent, let&#39;s show what you can build with it.&lt;/p&gt; 
&lt;p&gt;In short, you can build any kind of AI application with mcp-agent: multi-agent collaborative workflows, human-in-the-loop workflows, RAG pipelines and more.&lt;/p&gt; 
&lt;h3&gt;Claude Desktop&lt;/h3&gt; 
&lt;p&gt;You can integrate mcp-agent apps into MCP clients like Claude Desktop.&lt;/p&gt; 
&lt;h4&gt;mcp-agent server&lt;/h4&gt; 
&lt;p&gt;This app wraps an mcp-agent application inside an MCP server, and exposes that server to Claude Desktop. The app exposes agents and workflows that Claude Desktop can invoke to service of the user&#39;s request.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/7807cffd-dba7-4f0c-9c70-9482fd7e0699&quot;&gt;https://github.com/user-attachments/assets/7807cffd-dba7-4f0c-9c70-9482fd7e0699&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This demo shows a multi-agent evaluation task where each agent evaluates aspects of an input poem, and then an aggregator summarizes their findings into a final response.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Details&lt;/strong&gt;: Starting from a user&#39;s request over text, the application:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;dynamically defines agents to do the job&lt;/li&gt; 
 &lt;li&gt;uses the appropriate workflow to orchestrate those agents (in this case the Parallel workflow)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/mcp_agent_server&quot;&gt;examples/mcp_agent_server&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Huge thanks to &lt;a href=&quot;https://github.com/StreetLamb&quot;&gt;Jerron Lim (@StreetLamb)&lt;/a&gt; for developing and contributing this example!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Streamlit&lt;/h3&gt; 
&lt;p&gt;You can deploy mcp-agent apps using Streamlit.&lt;/p&gt; 
&lt;h4&gt;Gmail agent&lt;/h4&gt; 
&lt;p&gt;This app is able to perform read and write actions on gmail using text prompts -- i.e. read, delete, send emails, mark as read/unread, etc. It uses an MCP server for Gmail.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/54899cac-de24-4102-bd7e-4b2022c956e3&quot;&gt;https://github.com/user-attachments/assets/54899cac-de24-4102-bd7e-4b2022c956e3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&quot;https://github.com/jasonsum/gmail-mcp-server/raw/add-mcp-agent-streamlit/streamlit_app.py&quot;&gt;gmail-mcp-server&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Huge thanks to &lt;a href=&quot;https://github.com/jasonsum&quot;&gt;Jason Summer (@jasonsum)&lt;/a&gt; for developing and contributing this example!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Simple RAG Chatbot&lt;/h4&gt; 
&lt;p&gt;This app uses a Qdrant vector database (via an MCP server) to do Q&amp;amp;A over a corpus of text.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/f4dcd227-cae9-4a59-aa9e-0eceeb4acaf4&quot;&gt;https://github.com/user-attachments/assets/f4dcd227-cae9-4a59-aa9e-0eceeb4acaf4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/streamlit_mcp_rag_agent/&quot;&gt;examples/streamlit_mcp_rag_agent&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Huge thanks to &lt;a href=&quot;https://github.com/StreetLamb&quot;&gt;Jerron Lim (@StreetLamb)&lt;/a&gt; for developing and contributing this example!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Marimo&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/marimo-team/marimo&quot;&gt;Marimo&lt;/a&gt; is a reactive Python notebook that replaces Jupyter and Streamlit. Here&#39;s the &quot;file finder&quot; agent from &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#quickstart&quot;&gt;Quickstart&lt;/a&gt; implemented in Marimo:&lt;/p&gt; 
&lt;img src=&quot;https://github.com/user-attachments/assets/139a95a5-e3ac-4ea7-9c8f-bad6577e8597&quot; width=&quot;400&quot;&gt; 
&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/marimo_mcp_basic_agent/&quot;&gt;examples/marimo_mcp_basic_agent&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Huge thanks to &lt;a href=&quot;https://github.com/akshayka&quot;&gt;Akshay Agrawal (@akshayka)&lt;/a&gt; for developing and contributing this example!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;p&gt;You can write mcp-agent apps as Python scripts or Jupyter notebooks.&lt;/p&gt; 
&lt;h4&gt;Swarm&lt;/h4&gt; 
&lt;p&gt;This example demonstrates a multi-agent setup for handling different customer service requests in an airline context using the Swarm workflow pattern. The agents can triage requests, handle flight modifications, cancellations, and lost baggage cases.&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/b314d75d-7945-4de6-965b-7f21eb14a8bd&quot;&gt;https://github.com/user-attachments/assets/b314d75d-7945-4de6-965b-7f21eb14a8bd&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Link to code&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflow_swarm/&quot;&gt;examples/workflow_swarm&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Core Components&lt;/h2&gt; 
&lt;p&gt;The following are the building blocks of the mcp-agent framework:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/app.py&quot;&gt;MCPApp&lt;/a&gt;&lt;/strong&gt;: global state and app configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP server management&lt;/strong&gt;: &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/gen_client.py&quot;&gt;&lt;code&gt;gen_client&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/mcp_connection_manager.py&quot;&gt;&lt;code&gt;MCPConnectionManager&lt;/code&gt;&lt;/a&gt; to easily connect to MCP servers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/agents/agent.py&quot;&gt;Agent&lt;/a&gt;&lt;/strong&gt;: An Agent is an entity that has access to a set of MCP servers and exposes them to an LLM as tool calls. It has a name and purpose (instruction).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/llm/augmented_llm.py&quot;&gt;AugmentedLLM&lt;/a&gt;&lt;/strong&gt;: An LLM that is enhanced with tools provided from a collection of MCP servers. Every Workflow pattern described below is an &lt;code&gt;AugmentedLLM&lt;/code&gt; itself, allowing you to compose and chain them together.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Everything in the framework is a derivative of these core capabilities.&lt;/p&gt; 
&lt;h2&gt;Workflows&lt;/h2&gt; 
&lt;p&gt;mcp-agent provides implementations for every pattern in Anthropic’s &lt;a href=&quot;https://www.anthropic.com/research/building-effective-agents&quot;&gt;Building Effective Agents&lt;/a&gt;, as well as the OpenAI &lt;a href=&quot;https://github.com/openai/swarm&quot;&gt;Swarm&lt;/a&gt; pattern. Each pattern is model-agnostic, and exposed as an &lt;code&gt;AugmentedLLM&lt;/code&gt;, making everything very composable.&lt;/p&gt; 
&lt;h3&gt;AugmentedLLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/llm/augmented_llm.py&quot;&gt;AugmentedLLM&lt;/a&gt; is an LLM that has access to MCP servers and functions via Agents.&lt;/p&gt; 
&lt;p&gt;LLM providers implement the AugmentedLLM interface to expose 3 functions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;generate&lt;/code&gt;: Generate message(s) given a prompt, possibly over multiple iterations and making tool calls as needed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;generate_str&lt;/code&gt;: Calls &lt;code&gt;generate&lt;/code&gt; and returns result as a string output.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;generate_structured&lt;/code&gt;: Uses &lt;a href=&quot;https://github.com/instructor-ai/instructor&quot;&gt;Instructor&lt;/a&gt; to return the generated result as a Pydantic model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, &lt;code&gt;AugmentedLLM&lt;/code&gt; has memory, to keep track of long or short-term history.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from mcp_agent.agents.agent import Agent
from mcp_agent.workflows.llm.augmented_llm_anthropic import AnthropicAugmentedLLM

finder_agent = Agent(
    name=&quot;finder&quot;,
    instruction=&quot;You are an agent with filesystem + fetch access. Return the requested file or URL contents.&quot;,
    server_names=[&quot;fetch&quot;, &quot;filesystem&quot;],
)

async with finder_agent:
   llm = await finder_agent.attach_llm(AnthropicAugmentedLLM)

   result = await llm.generate_str(
      message=&quot;Print the first 2 paragraphs of https://www.anthropic.com/research/building-effective-agents&quot;,
      # Can override model, tokens and other defaults
   )
   logger.info(f&quot;Result: {result}&quot;)

   # Multi-turn conversation
   result = await llm.generate_str(
      message=&quot;Summarize those paragraphs in a 128 character tweet&quot;,
   )
   logger.info(f&quot;Result: {result}&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/parallel/parallel_llm.py&quot;&gt;Parallel&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&amp;amp;w=3840&amp;amp;q=75&quot; alt=&quot;Parallel workflow (Image credit: Anthropic)&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Fan-out tasks to multiple sub-agents and fan-in the results. Each subtask is an AugmentedLLM, as is the overall Parallel workflow, meaning each subtask can optionally be a more complex workflow itself.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflow_parallel/main.py&quot;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;proofreader = Agent(name=&quot;proofreader&quot;, instruction=&quot;Review grammar...&quot;)
fact_checker = Agent(name=&quot;fact_checker&quot;, instruction=&quot;Check factual consistency...&quot;)
style_enforcer = Agent(name=&quot;style_enforcer&quot;, instruction=&quot;Enforce style guidelines...&quot;)

grader = Agent(name=&quot;grader&quot;, instruction=&quot;Combine feedback into a structured report.&quot;)

parallel = ParallelLLM(
    fan_in_agent=grader,
    fan_out_agents=[proofreader, fact_checker, style_enforcer],
    llm_factory=OpenAIAugmentedLLM,
)

result = await parallel.generate_str(&quot;Student short story submission: ...&quot;, RequestParams(model=&quot;gpt4-o&quot;))
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/router/&quot;&gt;Router&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&amp;amp;w=3840&amp;amp;q=75&quot; alt=&quot;Router workflow (Image credit: Anthropic)&quot;&gt;&lt;/p&gt; 
&lt;p&gt;Given an input, route to the &lt;code&gt;top_k&lt;/code&gt; most relevant categories. A category can be an Agent, an MCP server or a regular function.&lt;/p&gt; 
&lt;p&gt;mcp-agent provides several router implementations, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/router/router_embedding.py&quot;&gt;&lt;code&gt;EmbeddingRouter&lt;/code&gt;&lt;/a&gt;: uses embedding models for classification&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/router/router_llm.py&quot;&gt;&lt;code&gt;LLMRouter&lt;/code&gt;&lt;/a&gt;: uses LLMs for classification&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflow_router/main.py&quot;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;def print_hello_world:
     print(&quot;Hello, world!&quot;)

finder_agent = Agent(name=&quot;finder&quot;, server_names=[&quot;fetch&quot;, &quot;filesystem&quot;])
writer_agent = Agent(name=&quot;writer&quot;, server_names=[&quot;filesystem&quot;])

llm = OpenAIAugmentedLLM()
router = LLMRouter(
    llm=llm,
    agents=[finder_agent, writer_agent],
    functions=[print_hello_world],
)

results = await router.route( # Also available: route_to_agent, route_to_server
    request=&quot;Find and print the contents of README.md verbatim&quot;,
    top_k=1
)
chosen_agent = results[0].result
async with chosen_agent:
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/intent_classifier/&quot;&gt;IntentClassifier&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;A close sibling of Router, the Intent Classifier pattern identifies the &lt;code&gt;top_k&lt;/code&gt; Intents that most closely match a given input. Just like a Router, mcp-agent provides both an &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/intent_classifier/intent_classifier_embedding.py&quot;&gt;embedding&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/intent_classifier/intent_classifier_llm.py&quot;&gt;LLM-based&lt;/a&gt; intent classifier.&lt;/p&gt; 
&lt;h3&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/evaluator_optimizer/evaluator_optimizer.py&quot;&gt;Evaluator-Optimizer&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&amp;amp;w=3840&amp;amp;q=75&quot; alt=&quot;Evaluator-optimizer workflow (Image credit: Anthropic)&quot;&gt;&lt;/p&gt; 
&lt;p&gt;One LLM (the “optimizer”) refines a response, another (the “evaluator”) critiques it until a response exceeds a quality criteria.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflow_evaluator_optimizer/main.py&quot;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;optimizer = Agent(name=&quot;cover_letter_writer&quot;, server_names=[&quot;fetch&quot;], instruction=&quot;Generate a cover letter ...&quot;)
evaluator = Agent(name=&quot;critiquer&quot;, instruction=&quot;Evaluate clarity, specificity, relevance...&quot;)

llm = EvaluatorOptimizerLLM(
    optimizer=optimizer,
    evaluator=evaluator,
    llm_factory=OpenAIAugmentedLLM,
    min_rating=QualityRating.EXCELLENT, # Keep iterating until the minimum quality bar is reached
)

result = await eo_llm.generate_str(&quot;Write a job cover letter for an AI framework developer role at LastMile AI.&quot;)
print(&quot;Final refined cover letter:&quot;, result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/orchestrator/orchestrator.py&quot;&gt;Orchestrator-workers&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&amp;amp;w=3840&amp;amp;q=75&quot; alt=&quot;Orchestrator workflow (Image credit: Anthropic)&quot;&gt;&lt;/p&gt; 
&lt;p&gt;A higher-level LLM generates a plan, then assigns them to sub-agents, and synthesizes the results. The Orchestrator workflow automatically parallelizes steps that can be done in parallel, and blocks on dependencies.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflow_orchestrator_worker/main.py&quot;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;finder_agent = Agent(name=&quot;finder&quot;, server_names=[&quot;fetch&quot;, &quot;filesystem&quot;])
writer_agent = Agent(name=&quot;writer&quot;, server_names=[&quot;filesystem&quot;])
proofreader = Agent(name=&quot;proofreader&quot;, ...)
fact_checker = Agent(name=&quot;fact_checker&quot;, ...)
style_enforcer = Agent(name=&quot;style_enforcer&quot;, instructions=&quot;Use APA style guide from ...&quot;, server_names=[&quot;fetch&quot;])

orchestrator = Orchestrator(
    llm_factory=AnthropicAugmentedLLM,
    available_agents=[finder_agent, writer_agent, proofreader, fact_checker, style_enforcer],
)

task = &quot;Load short_story.md, evaluate it, produce a graded_report.md with multiple feedback aspects.&quot;
result = await orchestrator.generate_str(task, RequestParams(model=&quot;gpt-4o&quot;))
print(result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/workflows/swarm/swarm.py&quot;&gt;Swarm&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAI has an experimental multi-agent pattern called &lt;a href=&quot;https://github.com/openai/swarm&quot;&gt;Swarm&lt;/a&gt;, which we provide a model-agnostic reference implementation for in mcp-agent.&lt;/p&gt; 
&lt;img src=&quot;https://github.com/openai/swarm/raw/main/assets/swarm_diagram.png?raw=true&quot; width=&quot;500&quot;&gt; 
&lt;p&gt;The mcp-agent Swarm pattern works seamlessly with MCP servers, and is exposed as an &lt;code&gt;AugmentedLLM&lt;/code&gt;, allowing for composability with other patterns above.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflow_swarm/main.py&quot;&gt;Link to full example&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;triage_agent = SwarmAgent(...)
flight_mod_agent = SwarmAgent(...)
lost_baggage_agent = SwarmAgent(...)

# The triage agent decides whether to route to flight_mod_agent or lost_baggage_agent
swarm = AnthropicSwarm(agent=triage_agent, context_variables={...})

test_input = &quot;My bag was not delivered!&quot;
result = await swarm.generate_str(test_input)
print(&quot;Result:&quot;, result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Advanced&lt;/h2&gt; 
&lt;h3&gt;Composability&lt;/h3&gt; 
&lt;p&gt;An example of composability is using an &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#evaluator-optimizer&quot;&gt;Evaluator-Optimizer&lt;/a&gt; workflow as the planner LLM inside the &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/#orchestrator-workers&quot;&gt;Orchestrator&lt;/a&gt; workflow. Generating a high-quality plan to execute is important for robust behavior, and an evaluator-optimizer can help ensure that.&lt;/p&gt; 
&lt;p&gt;Doing so is seamless in mcp-agent, because each workflow is implemented as an &lt;code&gt;AugmentedLLM&lt;/code&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;optimizer = Agent(name=&quot;plan_optimizer&quot;, server_names=[...], instruction=&quot;Generate a plan given an objective ...&quot;)
evaluator = Agent(name=&quot;plan_evaluator&quot;, instruction=&quot;Evaluate logic, ordering and precision of plan......&quot;)

planner_llm = EvaluatorOptimizerLLM(
    optimizer=optimizer,
    evaluator=evaluator,
    llm_factory=OpenAIAugmentedLLM,
    min_rating=QualityRating.EXCELLENT,
)

orchestrator = Orchestrator(
    llm_factory=AnthropicAugmentedLLM,
    available_agents=[finder_agent, writer_agent, proofreader, fact_checker, style_enforcer],
    planner=planner_llm # It&#39;s that simple
)

...
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Signaling and Human Input&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Signaling&lt;/strong&gt;: The framework can pause/resume tasks. The agent or LLM might “signal” that it needs user input, so the workflow awaits. A developer may signal during a workflow to seek approval or review before continuing with a workflow.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Human Input&lt;/strong&gt;: If an Agent has a &lt;code&gt;human_input_callback&lt;/code&gt;, the LLM can call a &lt;code&gt;__human_input__&lt;/code&gt; tool to request user input mid-workflow.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;p&gt;The &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/workflow_swarm/main.py&quot;&gt;Swarm example&lt;/a&gt; shows this in action.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from mcp_agent.human_input.handler import console_input_callback

lost_baggage = SwarmAgent(
    name=&quot;Lost baggage traversal&quot;,
    instruction=lambda context_variables: f&quot;&quot;&quot;
        {
        FLY_AIR_AGENT_PROMPT.format(
            customer_context=context_variables.get(&quot;customer_context&quot;, &quot;None&quot;),
            flight_context=context_variables.get(&quot;flight_context&quot;, &quot;None&quot;),
        )
    }\n Lost baggage policy: policies/lost_baggage_policy.md&quot;&quot;&quot;,
    functions=[
        escalate_to_agent,
        initiate_baggage_search,
        transfer_to_triage,
        case_resolved,
    ],
    server_names=[&quot;fetch&quot;, &quot;filesystem&quot;],
    human_input_callback=console_input_callback, # Request input from the console
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;App Config&lt;/h3&gt; 
&lt;p&gt;Create an &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/schema/mcp-agent.config.schema.json&quot;&gt;&lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;&lt;/a&gt; and a gitignored &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/mcp_basic_agent/mcp_agent.secrets.yaml.example&quot;&gt;&lt;code&gt;mcp_agent.secrets.yaml&lt;/code&gt;&lt;/a&gt; to define MCP app configuration. This controls logging, execution, LLM provider APIs, and MCP server configuration.&lt;/p&gt; 
&lt;h3&gt;MCP server management&lt;/h3&gt; 
&lt;p&gt;mcp-agent makes it trivial to connect to MCP servers. Create an &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/schema/mcp-agent.config.schema.json&quot;&gt;&lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;&lt;/a&gt; to define server configuration under the &lt;code&gt;mcp&lt;/code&gt; section:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;mcp:
  servers:
    fetch:
      command: &quot;uvx&quot;
      args: [&quot;mcp-server-fetch&quot;]
      description: &quot;Fetch content at URLs from the world wide web&quot;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/gen_client.py&quot;&gt;&lt;code&gt;gen_client&lt;/code&gt;&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;Manage the lifecycle of an MCP server within an async context manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from mcp_agent.mcp.gen_client import gen_client

async with gen_client(&quot;fetch&quot;) as fetch_client:
    # Fetch server is initialized and ready to use
    result = await fetch_client.list_tools()

# Fetch server is automatically disconnected/shutdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The gen_client function makes it easy to spin up connections to MCP servers.&lt;/p&gt; 
&lt;h4&gt;Persistent server connections&lt;/h4&gt; 
&lt;p&gt;In many cases, you want an MCP server to stay online for persistent use (e.g. in a multi-step tool use workflow). For persistent connections, use:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/(src/mcp_agent/mcp/gen_client.py)&quot;&gt;&lt;code&gt;connect&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/gen_client.py&quot;&gt;&lt;code&gt;disconnect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from mcp_agent.mcp.gen_client import connect, disconnect

fetch_client = None
try:
     fetch_client = connect(&quot;fetch&quot;)
     result = await fetch_client.list_tools()
finally:
     disconnect(&quot;fetch&quot;)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/mcp_connection_manager.py&quot;&gt;&lt;code&gt;MCPConnectionManager&lt;/code&gt;&lt;/a&gt; For even more fine-grained control over server connections, you can use the MCPConnectionManager.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from mcp_agent.context import get_current_context
from mcp_agent.mcp.mcp_connection_manager import MCPConnectionManager

context = get_current_context()
connection_manager = MCPConnectionManager(context.server_registry)

async with connection_manager:
fetch_client = await connection_manager.get_server(&quot;fetch&quot;) # Initializes fetch server
result = fetch_client.list_tool()
fetch_client2 = await connection_manager.get_server(&quot;fetch&quot;) # Reuses same server connection

# All servers managed by connection manager are automatically disconnected/shut down
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;MCP Server Aggregator&lt;/h4&gt; 
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/mcp/mcp_aggregator.py&quot;&gt;&lt;code&gt;MCPAggregator&lt;/code&gt;&lt;/a&gt; acts as a &quot;server-of-servers&quot;. It provides a single MCP server interface for interacting with multiple MCP servers. This allows you to expose tools from multiple servers to LLM applications.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from mcp_agent.mcp.mcp_aggregator import MCPAggregator

aggregator = await MCPAggregator.create(server_names=[&quot;fetch&quot;, &quot;filesystem&quot;])

async with aggregator:
   # combined list of tools exposed by &#39;fetch&#39; and &#39;filesystem&#39; servers
   tools = await aggregator.list_tools()

   # namespacing -- invokes the &#39;fetch&#39; server to call the &#39;fetch&#39; tool
   fetch_result = await aggregator.call_tool(name=&quot;fetch-fetch&quot;, arguments={&quot;url&quot;: &quot;https://www.anthropic.com/research/building-effective-agents&quot;})

   # no namespacing -- first server in the aggregator exposing that tool wins
   read_file_result = await aggregator.call_tool(name=&quot;read_file&quot;, arguments={})
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome any and all kinds of contributions. Please see the &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/CONTRIBUTING.md&quot;&gt;CONTRIBUTING guidelines&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Special Mentions&lt;/h3&gt; 
&lt;p&gt;There have already been incredible community contributors who are driving this project forward:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/evalstate&quot;&gt;Shaun Smith (@evalstate)&lt;/a&gt; -- who has been leading the charge on countless complex improvements, both to &lt;code&gt;mcp-agent&lt;/code&gt; and generally to the MCP ecosystem.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/StreetLamb&quot;&gt;Jerron Lim (@StreetLamb)&lt;/a&gt; -- who has contributed countless hours and excellent examples, and great ideas to the project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://github.com/jasonsum&quot;&gt;Jason Summer (@jasonsum)&lt;/a&gt; -- for identifying several issues and adapting his Gmail MCP server to work with mcp-agent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;We will be adding a detailed roadmap (ideally driven by your feedback). The current set of priorities include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Durable Execution&lt;/strong&gt; -- allow workflows to pause/resume and serialize state so they can be replayed or be paused indefinitely. We are working on integrating &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/src/mcp_agent/executor/temporal.py&quot;&gt;Temporal&lt;/a&gt; for this purpose.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt; -- adding support for long-term memory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Streaming&lt;/strong&gt; -- Support streaming listeners for iterative progress&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Additional MCP capabilities&lt;/strong&gt; -- Expand beyond tool calls to support: 
  &lt;ul&gt; 
   &lt;li&gt;Resources&lt;/li&gt; 
   &lt;li&gt;Prompts&lt;/li&gt; 
   &lt;li&gt;Notifications&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQs&lt;/h2&gt; 
&lt;h3&gt;What are the core benefits of using mcp-agent?&lt;/h3&gt; 
&lt;p&gt;mcp-agent provides a streamlined approach to building AI agents using capabilities exposed by &lt;strong&gt;MCP&lt;/strong&gt; (Model Context Protocol) servers.&lt;/p&gt; 
&lt;p&gt;MCP is quite low-level, and this framework handles the mechanics of connecting to servers, working with LLMs, handling external signals (like human input) and supporting persistent state via durable execution. That lets you, the developer, focus on the core business logic of your AI application.&lt;/p&gt; 
&lt;p&gt;Core benefits:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🤝 &lt;strong&gt;Interoperability&lt;/strong&gt;: ensures that any tool exposed by any number of MCP servers can seamlessly plug in to your agents.&lt;/li&gt; 
 &lt;li&gt;⛓️ &lt;strong&gt;Composability &amp;amp; Cutstomizability&lt;/strong&gt;: Implements well-defined workflows, but in a composable way that enables compound workflows, and allows full customization across model provider, logging, orchestrator, etc.&lt;/li&gt; 
 &lt;li&gt;💻 &lt;strong&gt;Programmatic control flow&lt;/strong&gt;: Keeps things simple as developers just write code instead of thinking in graphs, nodes and edges. For branching logic, you write &lt;code&gt;if&lt;/code&gt; statements. For cycles, use &lt;code&gt;while&lt;/code&gt; loops.&lt;/li&gt; 
 &lt;li&gt;🖐️ &lt;strong&gt;Human Input &amp;amp; Signals&lt;/strong&gt;: Supports pausing workflows for external signals, such as human input, which are exposed as tool calls an Agent can make.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Do you need an MCP client to use mcp-agent?&lt;/h3&gt; 
&lt;p&gt;No, you can use mcp-agent anywhere, since it handles MCPClient creation for you. This allows you to leverage MCP servers outside of MCP hosts like Claude Desktop.&lt;/p&gt; 
&lt;p&gt;Here&#39;s all the ways you can set up your mcp-agent application:&lt;/p&gt; 
&lt;h4&gt;MCP-Agent Server&lt;/h4&gt; 
&lt;p&gt;You can expose mcp-agent applications as MCP servers themselves (see &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/mcp_agent_server&quot;&gt;example&lt;/a&gt;), allowing MCP clients to interface with sophisticated AI workflows using the standard tools API of MCP servers. This is effectively a server-of-servers.&lt;/p&gt; 
&lt;h4&gt;MCP Client or Host&lt;/h4&gt; 
&lt;p&gt;You can embed mcp-agent in an MCP client directly to manage the orchestration across multiple MCP servers.&lt;/p&gt; 
&lt;h4&gt;Standalone&lt;/h4&gt; 
&lt;p&gt;You can use mcp-agent applications in a standalone fashion (i.e. they aren&#39;t part of an MCP client). The &lt;a href=&quot;https://raw.githubusercontent.com/lastmile-ai/mcp-agent/main/examples/&quot;&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; are all standalone applications.&lt;/p&gt; 
&lt;h3&gt;Tell me a fun fact&lt;/h3&gt; 
&lt;p&gt;I debated naming this project &lt;em&gt;silsila&lt;/em&gt; (سلسلہ), which means chain of events in Urdu. mcp-agent is more matter-of-fact, but there&#39;s still an easter egg in the project paying homage to silsila.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>yetone/avante.nvim</title>
      <link>https://github.com/yetone/avante.nvim</link>
      <description>&lt;p&gt;Use your Neovim like using Cursor AI IDE!&lt;/p&gt;&lt;hr&gt;&lt;div align=&quot;center&quot;&gt; 
 &lt;img alt=&quot;logo&quot; width=&quot;120&quot; src=&quot;https://github.com/user-attachments/assets/2e2f2a58-2b28-4d11-afd1-87b65612b2de&quot;&gt; 
 &lt;h1&gt;avante.nvim&lt;/h1&gt; 
&lt;/div&gt; 
&lt;div align=&quot;center&quot;&gt; 
 &lt;a href=&quot;https://neovim.io/&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/static/v1?style=flat-square&amp;amp;label=Neovim&amp;amp;message=v0.10%2b&amp;amp;logo=neovim&amp;amp;labelColor=282828&amp;amp;logoColor=8faa80&amp;amp;color=414b32&quot; alt=&quot;Neovim: v0.10+&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://github.com/yetone/avante.nvim/actions/workflows/lua.yaml&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/yetone/avante.nvim/lua.yaml?style=flat-square&amp;amp;logo=lua&amp;amp;logoColor=c7c7c7&amp;amp;label=Lua+CI&amp;amp;labelColor=1E40AF&amp;amp;color=347D39&amp;amp;event=push&quot; alt=&quot;Lua CI status&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://github.com/yetone/avante.nvim/actions/workflows/rust.yaml&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/yetone/avante.nvim/rust.yaml?style=flat-square&amp;amp;logo=rust&amp;amp;logoColor=ffffff&amp;amp;label=Rust+CI&amp;amp;labelColor=BC826A&amp;amp;color=347D39&amp;amp;event=push&quot; alt=&quot;Rust CI status&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://github.com/yetone/avante.nvim/actions/workflows/python.yaml&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/yetone/avante.nvim/python.yaml?style=flat-square&amp;amp;logo=python&amp;amp;logoColor=ffffff&amp;amp;label=Python+CI&amp;amp;labelColor=3672A5&amp;amp;color=347D39&amp;amp;event=push&quot; alt=&quot;Python CI status&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://discord.gg/QfnEFEdSjz&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https://img.shields.io/discord/1302530866362323016?style=flat-square&amp;amp;logo=discord&amp;amp;label=Discord&amp;amp;logoColor=ffffff&amp;amp;labelColor=7376CF&amp;amp;color=268165&quot; alt=&quot;Discord&quot;&gt; &lt;/a&gt; 
 &lt;a href=&quot;https://dotfyle.com/plugins/yetone/avante.nvim&quot;&gt; &lt;img src=&quot;https://dotfyle.com/plugins/yetone/avante.nvim/shield?style=flat-square&quot;&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;avante.nvim&lt;/strong&gt; is a Neovim plugin designed to emulate the behaviour of the &lt;a href=&quot;https://www.cursor.com&quot;&gt;Cursor&lt;/a&gt; AI IDE. It provides users with AI-driven code suggestions and the ability to apply these recommendations directly to their source files with minimal effort.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;🥰 This project is undergoing rapid iterations, and many exciting features will be added successively. Stay tuned!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/510e6270-b6cf-459d-9a2f-15b397d1fe53&quot;&gt;https://github.com/user-attachments/assets/510e6270-b6cf-459d-9a2f-15b397d1fe53&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://github.com/user-attachments/assets/86140bfd-08b4-483d-a887-1b701d9e37dd&quot;&gt;https://github.com/user-attachments/assets/86140bfd-08b4-483d-a887-1b701d9e37dd&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsorship ❤️&lt;/h2&gt; 
&lt;p&gt;If you like this project, please consider supporting me on Patreon, as it helps me to continue maintaining and improving it:&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://patreon.com/yetone&quot;&gt;Sponsor me&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Powered Code Assistance&lt;/strong&gt;: Interact with AI to ask questions about your current code file and receive intelligent suggestions for improvement or modification.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;One-Click Application&lt;/strong&gt;: Quickly apply the AI&#39;s suggested changes to your source code with a single command, streamlining the editing process and saving time.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;For building binary if you wish to build from source, then &lt;code&gt;cargo&lt;/code&gt; is required. Otherwise &lt;code&gt;curl&lt;/code&gt; and &lt;code&gt;tar&lt;/code&gt; will be used to get prebuilt binary from GitHub.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;a href=&quot;https://github.com/folke/lazy.nvim&quot;&gt;lazy.nvim&lt;/a&gt; (recommended)&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;{
  &quot;yetone/avante.nvim&quot;,
  event = &quot;VeryLazy&quot;,
  version = false, -- Never set this value to &quot;*&quot;! Never!
  opts = {
    -- add any opts here
    -- for example
    provider = &quot;openai&quot;,
    openai = {
      endpoint = &quot;https://api.openai.com/v1&quot;,
      model = &quot;gpt-4o&quot;, -- your desired model (or use gpt-4o, etc.)
      timeout = 30000, -- Timeout in milliseconds, increase this for reasoning models
      temperature = 0,
      max_tokens = 8192, -- Increase this to include reasoning tokens (for reasoning models)
      --reasoning_effort = &quot;medium&quot;, -- low|medium|high, only used for reasoning models
    },
  },
  -- if you want to build from source then do `make BUILD_FROM_SOURCE=true`
  build = &quot;make&quot;,
  -- build = &quot;powershell -ExecutionPolicy Bypass -File Build.ps1 -BuildFromSource false&quot; -- for windows
  dependencies = {
    &quot;nvim-treesitter/nvim-treesitter&quot;,
    &quot;stevearc/dressing.nvim&quot;,
    &quot;nvim-lua/plenary.nvim&quot;,
    &quot;MunifTanjim/nui.nvim&quot;,
    --- The below dependencies are optional,
    &quot;echasnovski/mini.pick&quot;, -- for file_selector provider mini.pick
    &quot;nvim-telescope/telescope.nvim&quot;, -- for file_selector provider telescope
    &quot;hrsh7th/nvim-cmp&quot;, -- autocompletion for avante commands and mentions
    &quot;ibhagwan/fzf-lua&quot;, -- for file_selector provider fzf
    &quot;nvim-tree/nvim-web-devicons&quot;, -- or echasnovski/mini.icons
    &quot;zbirenbaum/copilot.lua&quot;, -- for providers=&#39;copilot&#39;
    {
      -- support for image pasting
      &quot;HakonHarnes/img-clip.nvim&quot;,
      event = &quot;VeryLazy&quot;,
      opts = {
        -- recommended settings
        default = {
          embed_image_as_base64 = false,
          prompt_for_file_name = false,
          drag_and_drop = {
            insert_mode = true,
          },
          -- required for Windows users
          use_absolute_path = true,
        },
      },
    },
    {
      -- Make sure to set this up properly if you have lazy=true
      &#39;MeanderingProgrammer/render-markdown.nvim&#39;,
      opts = {
        file_types = { &quot;markdown&quot;, &quot;Avante&quot; },
      },
      ft = { &quot;markdown&quot;, &quot;Avante&quot; },
    },
  },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;vim-plug&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-vim&quot;&gt;
&quot; Deps
Plug &#39;nvim-treesitter/nvim-treesitter&#39;
Plug &#39;stevearc/dressing.nvim&#39;
Plug &#39;nvim-lua/plenary.nvim&#39;
Plug &#39;MunifTanjim/nui.nvim&#39;
Plug &#39;MeanderingProgrammer/render-markdown.nvim&#39;

&quot; Optional deps
Plug &#39;hrsh7th/nvim-cmp&#39;
Plug &#39;nvim-tree/nvim-web-devicons&#39; &quot;or Plug &#39;echasnovski/mini.icons&#39;
Plug &#39;HakonHarnes/img-clip.nvim&#39;
Plug &#39;zbirenbaum/copilot.lua&#39;

&quot; Yay, pass source=true if you want to build from source
Plug &#39;yetone/avante.nvim&#39;, { &#39;branch&#39;: &#39;main&#39;, &#39;do&#39;: &#39;make&#39; }
autocmd! User avante.nvim lua &amp;lt;&amp;lt; EOF
require(&#39;avante&#39;).setup()
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;a href=&quot;https://github.com/echasnovski/mini.deps&quot;&gt;mini.deps&lt;/a&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;local add, later, now = MiniDeps.add, MiniDeps.later, MiniDeps.now

add({
  source = &#39;yetone/avante.nvim&#39;,
  monitor = &#39;main&#39;,
  depends = {
    &#39;nvim-treesitter/nvim-treesitter&#39;,
    &#39;stevearc/dressing.nvim&#39;,
    &#39;nvim-lua/plenary.nvim&#39;,
    &#39;MunifTanjim/nui.nvim&#39;,
    &#39;echasnovski/mini.icons&#39;
  },
  hooks = { post_checkout = function() vim.cmd(&#39;make&#39;) end }
})
--- optional
add({ source = &#39;hrsh7th/nvim-cmp&#39; })
add({ source = &#39;zbirenbaum/copilot.lua&#39; })
add({ source = &#39;HakonHarnes/img-clip.nvim&#39; })
add({ source = &#39;MeanderingProgrammer/render-markdown.nvim&#39; })

later(function() require(&#39;render-markdown&#39;).setup({...}) end)
later(function()
  require(&#39;img-clip&#39;).setup({...}) -- config img-clip
  require(&quot;copilot&quot;).setup({...}) -- setup copilot to your liking
  require(&quot;avante&quot;).setup({...}) -- config for avante.nvim
end)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;a href=&quot;https://github.com/wbthomason/packer.nvim&quot;&gt;Packer&lt;/a&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-vim&quot;&gt;
  -- Required plugins
  use &#39;nvim-treesitter/nvim-treesitter&#39;
  use &#39;stevearc/dressing.nvim&#39;
  use &#39;nvim-lua/plenary.nvim&#39;
  use &#39;MunifTanjim/nui.nvim&#39;
  use &#39;MeanderingProgrammer/render-markdown.nvim&#39;

  -- Optional dependencies
  use &#39;hrsh7th/nvim-cmp&#39;
  use &#39;nvim-tree/nvim-web-devicons&#39; -- or use &#39;echasnovski/mini.icons&#39;
  use &#39;HakonHarnes/img-clip.nvim&#39;
  use &#39;zbirenbaum/copilot.lua&#39;

  -- Avante.nvim with build process
  use {
    &#39;yetone/avante.nvim&#39;,
    branch = &#39;main&#39;,
    run = &#39;make&#39;,
    config = function()
      require(&#39;avante&#39;).setup()
    end
  }
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;a href=&quot;https://github.com/nix-community/home-manager&quot;&gt;Home Manager&lt;/a&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-nix&quot;&gt;programs.neovim = {
  plugins = [
    {
      plugin = pkgs.vimPlugins.avante-nvim;
      type = &quot;lua&quot;;
      config = &#39;&#39;
              require(&quot;avante_lib&quot;).load()
              require(&quot;avante&quot;).setup()
      &#39;&#39; # or builtins.readFile ./plugins/avante.lua;
    }
  ];
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;a href=&quot;https://nix-community.github.io/nixvim/plugins/avante/index.html&quot;&gt;Nixvim&lt;/a&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-nix&quot;&gt;  plugins.avante.enable = true;
  plugins.avante.settings = {
    # setup options here
  };
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Lua&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;-- deps:
require(&#39;cmp&#39;).setup ({
  -- use recommended settings from above
})
require(&#39;img-clip&#39;).setup ({
  -- use recommended settings from above
})
require(&#39;copilot&#39;).setup ({
  -- use recommended settings from above
})
require(&#39;render-markdown&#39;).setup ({
  -- use recommended settings from above
})
require(&#39;avante&#39;).setup ({
  -- Your config here!
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;avante.nvim&lt;/code&gt; is currently only compatible with Neovim 0.10.1 or later. Please ensure that your Neovim version meets these requirements before proceeding.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;When loading the plugin synchronously, we recommend &lt;code&gt;require&lt;/code&gt;ing it sometime after your colorscheme.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Recommended &lt;strong&gt;Neovim&lt;/strong&gt; options:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;-- views can only be fully collapsed with the global statusline
vim.opt.laststatus = 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Any rendering plugins that support markdown should work with Avante as long as you add the supported filetype &lt;code&gt;Avante&lt;/code&gt;. See &lt;a href=&quot;https://github.com/yetone/avante.nvim/issues/175&quot;&gt;https://github.com/yetone/avante.nvim/issues/175&lt;/a&gt; and &lt;a href=&quot;https://github.com/yetone/avante.nvim/issues/175#issuecomment-2313749363&quot;&gt;this comment&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Default setup configuration&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/yetone/avante.nvim/main/lua/avante/config.lua&quot;&gt;config.lua#L9&lt;/a&gt; for the full config&lt;/em&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Default configuration&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;{
  ---@alias Provider &quot;claude&quot; | &quot;openai&quot; | &quot;azure&quot; | &quot;gemini&quot; | &quot;cohere&quot; | &quot;copilot&quot; | string
  provider = &quot;claude&quot;, -- The provider used in Aider mode or in the planning phase of Cursor Planning Mode
  -- WARNING: Since auto-suggestions are a high-frequency operation and therefore expensive,
  -- currently designating it as `copilot` provider is dangerous because: https://github.com/yetone/avante.nvim/issues/1048
  -- Of course, you can reduce the request frequency by increasing `suggestion.debounce`.
  auto_suggestions_provider = &quot;claude&quot;,
  cursor_applying_provider = nil, -- The provider used in the applying phase of Cursor Planning Mode, defaults to nil, when nil uses Config.provider as the provider for the applying phase
  claude = {
    endpoint = &quot;https://api.anthropic.com&quot;,
    model = &quot;claude-3-5-sonnet-20241022&quot;,
    temperature = 0,
    max_tokens = 4096,
  },
  ---Specify the special dual_boost mode
  ---1. enabled: Whether to enable dual_boost mode. Default to false.
  ---2. first_provider: The first provider to generate response. Default to &quot;openai&quot;.
  ---3. second_provider: The second provider to generate response. Default to &quot;claude&quot;.
  ---4. prompt: The prompt to generate response based on the two reference outputs.
  ---5. timeout: Timeout in milliseconds. Default to 60000.
  ---How it works:
  --- When dual_boost is enabled, avante will generate two responses from the first_provider and second_provider respectively. Then use the response from the first_provider as provider1_output and the response from the second_provider as provider2_output. Finally, avante will generate a response based on the prompt and the two reference outputs, with the default Provider as normal.
  ---Note: This is an experimental feature and may not work as expected.
  dual_boost = {
    enabled = false,
    first_provider = &quot;openai&quot;,
    second_provider = &quot;claude&quot;,
    prompt = &quot;Based on the two reference outputs below, generate a response that incorporates elements from both but reflects your own judgment and unique perspective. Do not provide any explanation, just give the response directly. Reference Output 1: [{{provider1_output}}], Reference Output 2: [{{provider2_output}}]&quot;,
    timeout = 60000, -- Timeout in milliseconds
  },
  behaviour = {
    auto_suggestions = false, -- Experimental stage
    auto_set_highlight_group = true,
    auto_set_keymaps = true,
    auto_apply_diff_after_generation = false,
    support_paste_from_clipboard = false,
    minimize_diff = true, -- Whether to remove unchanged lines when applying a code block
    enable_token_counting = true, -- Whether to enable token counting. Default to true.
    enable_cursor_planning_mode = false, -- Whether to enable Cursor Planning Mode. Default to false.
    enable_claude_text_editor_tool_mode = false, -- Whether to enable Claude Text Editor Tool Mode.
  },
  mappings = {
    --- @class AvanteConflictMappings
    diff = {
      ours = &quot;co&quot;,
      theirs = &quot;ct&quot;,
      all_theirs = &quot;ca&quot;,
      both = &quot;cb&quot;,
      cursor = &quot;cc&quot;,
      next = &quot;]x&quot;,
      prev = &quot;[x&quot;,
    },
    suggestion = {
      accept = &quot;&amp;lt;M-l&amp;gt;&quot;,
      next = &quot;&amp;lt;M-]&amp;gt;&quot;,
      prev = &quot;&amp;lt;M-[&amp;gt;&quot;,
      dismiss = &quot;&amp;lt;C-]&amp;gt;&quot;,
    },
    jump = {
      next = &quot;]]&quot;,
      prev = &quot;[[&quot;,
    },
    submit = {
      normal = &quot;&amp;lt;CR&amp;gt;&quot;,
      insert = &quot;&amp;lt;C-s&amp;gt;&quot;,
    },
    cancel = {
      normal = { &quot;&amp;lt;C-c&amp;gt;&quot;, &quot;&amp;lt;Esc&amp;gt;&quot;, &quot;q&quot; },
      insert = { &quot;&amp;lt;C-c&amp;gt;&quot; },
    },
    sidebar = {
      apply_all = &quot;A&quot;,
      apply_cursor = &quot;a&quot;,
      retry_user_request = &quot;r&quot;,
      edit_user_request = &quot;e&quot;,
      switch_windows = &quot;&amp;lt;Tab&amp;gt;&quot;,
      reverse_switch_windows = &quot;&amp;lt;S-Tab&amp;gt;&quot;,
      remove_file = &quot;d&quot;,
      add_file = &quot;@&quot;,
      close = { &quot;&amp;lt;Esc&amp;gt;&quot;, &quot;q&quot; },
      close_from_input = nil, -- e.g., { normal = &quot;&amp;lt;Esc&amp;gt;&quot;, insert = &quot;&amp;lt;C-d&amp;gt;&quot; }
    },
  },
  hints = { enabled = true },
  windows = {
    ---@type &quot;right&quot; | &quot;left&quot; | &quot;top&quot; | &quot;bottom&quot;
    position = &quot;right&quot;, -- the position of the sidebar
    wrap = true, -- similar to vim.o.wrap
    width = 30, -- default % based on available width
    sidebar_header = {
      enabled = true, -- true, false to enable/disable the header
      align = &quot;center&quot;, -- left, center, right for title
      rounded = true,
    },
    input = {
      prefix = &quot;&amp;gt; &quot;,
      height = 8, -- Height of the input window in vertical layout
    },
    edit = {
      border = &quot;rounded&quot;,
      start_insert = true, -- Start insert mode when opening the edit window
    },
    ask = {
      floating = false, -- Open the &#39;AvanteAsk&#39; prompt in a floating window
      start_insert = true, -- Start insert mode when opening the ask window
      border = &quot;rounded&quot;,
      ---@type &quot;ours&quot; | &quot;theirs&quot;
      focus_on_apply = &quot;ours&quot;, -- which diff to focus after applying
    },
  },
  highlights = {
    ---@type AvanteConflictHighlights
    diff = {
      current = &quot;DiffText&quot;,
      incoming = &quot;DiffAdd&quot;,
    },
  },
  --- @class AvanteConflictUserConfig
  diff = {
    autojump = true,
    ---@type string | fun(): any
    list_opener = &quot;copen&quot;,
    --- Override the &#39;timeoutlen&#39; setting while hovering over a diff (see :help timeoutlen).
    --- Helps to avoid entering operator-pending mode with diff mappings starting with `c`.
    --- Disable by setting to -1.
    override_timeoutlen = 500,
  },
  suggestion = {
    debounce = 600,
    throttle = 600,
  },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Blink.cmp users&lt;/h2&gt; 
&lt;p&gt;For blink cmp users (nvim-cmp alternative) view below instruction for configuration This is achieved by emulating nvim-cmp using blink.compat or you can use &lt;a href=&quot;https://github.com/Kaiser-Yang/blink-cmp-avante&quot;&gt;Kaiser-Yang/blink-cmp-avante&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Lua&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;      file_selector = {
        --- @alias FileSelectorProvider &quot;native&quot; | &quot;fzf&quot; | &quot;mini.pick&quot; | &quot;snacks&quot; | &quot;telescope&quot; | string | fun(params: avante.file_selector.IParams|nil): nil
        provider = &quot;fzf&quot;,
        -- Options override for custom providers
        provider_opts = {},
      }
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To create a customized file_selector, you can specify a customized function to launch a picker to select items and pass the selected items to the &lt;code&gt;handler&lt;/code&gt; callback.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;      file_selector = {
        ---@param params avante.file_selector.IParams
        provider = function(params)
          local filepaths = params.filepaths ---@type string[]
          local title = params.title ---@type string
          local handler = params.handler ---@type fun(selected_filepaths: string[]|nil): nil

          -- Launch your customized picker with the items built from `filepaths`, then in the `on_confirm` callback,
          -- pass the selected items (convert back to file paths) to the `handler` function.

          local items = __your_items_formatter__(filepaths)
          __your_picker__({
            items = items,
            on_cancel = function()
              handler(nil)
            end,
            on_confirm = function(selected_items)
              local selected_filepaths = {}
              for _, item in ipairs(selected_items) do
                table.insert(selected_filepaths, item.filepath)
              end
              handler(selected_filepaths)
            end
          })
        end,
        ---below is optional
        provider_opts = {
          ---@param params avante.file_selector.opts.IGetFilepathsParams
          get_filepaths = function(params)
            local cwd = params.cwd ---@type string
            local selected_filepaths = params.selected_filepaths ---@type string[]
            local cmd = string.format(&quot;fd --base-directory &#39;%s&#39; --hidden&quot;, vim.fn.fnameescape(cwd))
            local output = vim.fn.system(cmd)
            local filepaths = vim.split(output, &quot;\n&quot;, { trimempty = true })
            return vim
              .iter(filepaths)
              :filter(function(filepath)
                return not vim.tbl_contains(selected_filepaths, filepath)
              end)
              :totable()
          end
        }
        end
      }
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Choose a selector other that native, the default as that currently has an issue For lazyvim users copy the full config for blink.cmp from the website or extend the options&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;      compat = {
        &quot;avante_commands&quot;,
        &quot;avante_mentions&quot;,
        &quot;avante_files&quot;,
      }
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For other users just add a custom provider&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;      default = {
        ...
        &quot;avante_commands&quot;,
        &quot;avante_mentions&quot;,
        &quot;avante_files&quot;,
      }
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;      providers = {
        avante_commands = {
          name = &quot;avante_commands&quot;,
          module = &quot;blink.compat.source&quot;,
          score_offset = 90, -- show at a higher priority than lsp
          opts = {},
        },
        avante_files = {
          name = &quot;avante_files&quot;,
          module = &quot;blink.compat.source&quot;,
          score_offset = 100, -- show at a higher priority than lsp
          opts = {},
        },
        avante_mentions = {
          name = &quot;avante_mentions&quot;,
          module = &quot;blink.compat.source&quot;,
          score_offset = 1000, -- show at a higher priority than lsp
          opts = {},
        }
        ...
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Given its early stage, &lt;code&gt;avante.nvim&lt;/code&gt; currently supports the following basic functionalities:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;Avante will only support Claude, and OpenAI (and its variants including azure)out-of-the-box due to its high code quality generation. For all OpenAI-compatible providers, see &lt;a href=&quot;https://github.com/yetone/avante.nvim/wiki/Custom-providers&quot;&gt;wiki&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;&lt;del&gt;Due to the poor performance of other models, avante.nvim only recommends using the claude-3.5-sonnet model.&lt;/del&gt; &amp;gt; &lt;del&gt;All features can only be guaranteed to work properly on the claude-3.5-sonnet model.&lt;/del&gt; &amp;gt; &lt;del&gt;We do not accept changes to the code or prompts to accommodate other models. Otherwise, it will greatly increase our maintenance costs.&lt;/del&gt; &amp;gt; &lt;del&gt;We hope everyone can understand. Thank you!&lt;/del&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;Since avante.nvim now supports &lt;a href=&quot;https://raw.githubusercontent.com/yetone/avante.nvim/main/cursor-planning-mode.md&quot;&gt;cursor planning mode&lt;/a&gt;, the above statement is no longer valid! avante.nvim now supports most models! If you encounter issues with normal usage, please try enabling &lt;a href=&quot;https://raw.githubusercontent.com/yetone/avante.nvim/main/cursor-planning-mode.md&quot;&gt;cursor planning mode&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;For most consistency between neovim session, it is recommended to set the environment variables in your shell file. By default, &lt;code&gt;Avante&lt;/code&gt; will prompt you at startup to input the API key for the provider you have selected.&lt;/p&gt; 
 &lt;p&gt;For Claude:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;export ANTHROPIC_API_KEY=your-api-key
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For OpenAI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;export OPENAI_API_KEY=your-api-key
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Azure OpenAI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;export AZURE_OPENAI_API_KEY=your-api-key
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Amazon Bedrock:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;export BEDROCK_KEYS=aws_access_key_id,aws_secret_access_key,aws_region[,aws_session_token]

&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Note: The aws_session_token is optional and only needed when using temporary AWS credentials&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open a code file in Neovim.&lt;/li&gt; 
 &lt;li&gt;Use the &lt;code&gt;:AvanteAsk&lt;/code&gt; command to query the AI about the code.&lt;/li&gt; 
 &lt;li&gt;Review the AI&#39;s suggestions.&lt;/li&gt; 
 &lt;li&gt;Apply the recommended changes directly to your code with a simple command or key binding.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The plugin is still under active development, and both its functionality and interface are subject to significant changes. Expect some rough edges and instability as the project evolves.&lt;/p&gt; 
&lt;h2&gt;Key Bindings&lt;/h2&gt; 
&lt;p&gt;The following key bindings are available for use with &lt;code&gt;avante.nvim&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key Binding&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;Leader&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;show sidebar&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;Leader&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;kbd&gt;t&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;toggle sidebar visibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;Leader&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;kbd&gt;r&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;refresh sidebar&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;Leader&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;kbd&gt;f&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;switch sidebar focus&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;Leader&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;kbd&gt;?&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;select model&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;Leader&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;kbd&gt;e&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;edit selected blocks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;Leader&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;kbd&gt;S&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;stop current AI request&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;c&lt;/kbd&gt;&lt;kbd&gt;o&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;choose ours&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;c&lt;/kbd&gt;&lt;kbd&gt;t&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;choose theirs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;c&lt;/kbd&gt;&lt;kbd&gt;a&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;choose all theirs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;c&lt;/kbd&gt;&lt;kbd&gt;0&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;choose none&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;c&lt;/kbd&gt;&lt;kbd&gt;b&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;choose both&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;c&lt;/kbd&gt;&lt;kbd&gt;c&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;choose cursor&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;]&lt;/kbd&gt;&lt;kbd&gt;x&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;move to previous conflict&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;[&lt;/kbd&gt;&lt;kbd&gt;x&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;move to next conflict&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;[&lt;/kbd&gt;&lt;kbd&gt;[&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;jump to previous codeblocks (results window)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;kbd&gt;]&lt;/kbd&gt;&lt;kbd&gt;]&lt;/kbd&gt;&lt;/td&gt; 
   &lt;td&gt;jump to next codeblocks (results windows)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;If you are using &lt;code&gt;lazy.nvim&lt;/code&gt;, then all keymap here will be safely set, meaning if &lt;code&gt;&amp;lt;leader&amp;gt;aa&lt;/code&gt; is already binded, then avante.nvim won&#39;t bind this mapping. In this case, user will be responsible for setting up their own. See &lt;a href=&quot;https://github.com/yetone/avante.nvim/wiki#keymaps-and-api-i-guess&quot;&gt;notes on keymaps&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Neotree shortcut&lt;/h3&gt; 
&lt;p&gt;In the neotree sidebar, you can also add a new keyboard shortcut to quickly add &lt;code&gt;file/folder&lt;/code&gt; to &lt;code&gt;Avante Selected Files&lt;/code&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Neotree configuration&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;return {
  {
    &#39;nvim-neo-tree/neo-tree.nvim&#39;,
    config = function()
      require(&#39;neo-tree&#39;).setup({
        filesystem = {
          commands = {
            avante_add_files = function(state)
              local node = state.tree:get_node()
              local filepath = node:get_id()
              local relative_path = require(&#39;avante.utils&#39;).relative_path(filepath)

              local sidebar = require(&#39;avante&#39;).get()

              local open = sidebar:is_open()
              -- ensure avante sidebar is open
              if not open then
                require(&#39;avante.api&#39;).ask()
                sidebar = require(&#39;avante&#39;).get()
              end

              sidebar.file_selector:add_selected_file(relative_path)

              -- remove neo tree buffer
              if not open then
                sidebar.file_selector:remove_selected_file(&#39;neo-tree filesystem [1]&#39;)
              end
            end,
          },
          window = {
            mappings = {
              [&#39;oa&#39;] = &#39;avante_add_files&#39;,
            },
          },
        },
      })
    end,
  },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Commands&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteAsk [question] [position]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ask AI about your code. Optional &lt;code&gt;position&lt;/code&gt; set window position and &lt;code&gt;ask&lt;/code&gt; enable/disable direct asking mode&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteAsk position=right Refactor this code here&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteBuild&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build dependencies for the project&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteChat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Start a chat session with AI about your codebase. Default is &lt;code&gt;ask&lt;/code&gt;=false&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteClear&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Clear the chat history&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteEdit&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Edit the selected code blocks&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteFocus&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Switch focus to/from the sidebar&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteRefresh&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Refresh all Avante windows&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteStop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Stop the current AI request&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteSwitchProvider&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Switch AI provider (e.g. openai)&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteShowRepoMap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show repo map for project&#39;s structure&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteToggle&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Toggle the Avante sidebar&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;:AvanteModels&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show model list&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Highlight Groups&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Highlight Group&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteTitle&lt;/td&gt; 
   &lt;td&gt;Title&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteReversedTitle&lt;/td&gt; 
   &lt;td&gt;Used for rounded border&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteSubtitle&lt;/td&gt; 
   &lt;td&gt;Selected code title&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteReversedSubtitle&lt;/td&gt; 
   &lt;td&gt;Used for rounded border&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteThirdTitle&lt;/td&gt; 
   &lt;td&gt;Prompt title&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteReversedThirdTitle&lt;/td&gt; 
   &lt;td&gt;Used for rounded border&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteConflictCurrent&lt;/td&gt; 
   &lt;td&gt;Current conflict highlight&lt;/td&gt; 
   &lt;td&gt;Default to &lt;code&gt;Config.highlights.diff.current&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteConflictIncoming&lt;/td&gt; 
   &lt;td&gt;Incoming conflict highlight&lt;/td&gt; 
   &lt;td&gt;Default to &lt;code&gt;Config.highlights.diff.incoming&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteConflictCurrentLabel&lt;/td&gt; 
   &lt;td&gt;Current conflict label highlight&lt;/td&gt; 
   &lt;td&gt;Default to shade of &lt;code&gt;AvanteConflictCurrent&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteConflictIncomingLabel&lt;/td&gt; 
   &lt;td&gt;Incoming conflict label highlight&lt;/td&gt; 
   &lt;td&gt;Default to shade of &lt;code&gt;AvanteConflictIncoming&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvantePopupHint&lt;/td&gt; 
   &lt;td&gt;Usage hints in popup menus&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AvanteInlineHint&lt;/td&gt; 
   &lt;td&gt;The end-of-line hint displayed in visual mode&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;a href=&quot;https://raw.githubusercontent.com/yetone/avante.nvim/main/lua/avante/highlights.lua&quot;&gt;highlights.lua&lt;/a&gt; for more information&lt;/p&gt; 
&lt;h2&gt;Ollama&lt;/h2&gt; 
&lt;p&gt;ollama is a first-class provider for avante.nvim. You can use it by setting &lt;code&gt;provider = &quot;ollama&quot;&lt;/code&gt; in the configuration, and set the &lt;code&gt;model&lt;/code&gt; field in &lt;code&gt;ollama&lt;/code&gt; to the model you want to use. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;provider = &quot;ollama&quot;,
ollama = {
  model = &quot;qwq:32b&quot;,
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you use ollama, the code planning effect may not be ideal, so it is strongly recommended that you enable &lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/cursor-planning-mode.md&quot;&gt;cursor-planning-mode&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Custom providers&lt;/h2&gt; 
&lt;p&gt;Avante provides a set of default providers, but users can also create their own providers.&lt;/p&gt; 
&lt;p&gt;For more information, see &lt;a href=&quot;https://github.com/yetone/avante.nvim/wiki/Custom-providers&quot;&gt;Custom Providers&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Cursor planning mode&lt;/h2&gt; 
&lt;p&gt;Because avante.nvim has always used Aider’s method for planning applying, but its prompts are very picky with models and require ones like claude-3.5-sonnet or gpt-4o to work properly.&lt;/p&gt; 
&lt;p&gt;Therefore, I have adopted Cursor’s method to implement planning applying. For details on the implementation, please refer to &lt;a href=&quot;https://raw.githubusercontent.com/yetone/avante.nvim/main/cursor-planning-mode.md&quot;&gt;cursor-planning-mode.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;RAG Service&lt;/h2&gt; 
&lt;p&gt;Avante provides a RAG service, which is a tool for obtaining the required context for the AI to generate the codes. By default, it is not enabled. You can enable it this way:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;rag_service = {
  enabled = false, -- Enables the RAG service
  host_mount = os.getenv(&quot;HOME&quot;), -- Host mount path for the rag service
  provider = &quot;openai&quot;, -- The provider to use for RAG service (e.g. openai or ollama)
  llm_model = &quot;&quot;, -- The LLM model to use for RAG service
  embed_model = &quot;&quot;, -- The embedding model to use for RAG service
  endpoint = &quot;https://api.openai.com/v1&quot;, -- The API endpoint for RAG service
},
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your rag_service provider is &lt;code&gt;openai&lt;/code&gt;, then you need to set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variable!&lt;/p&gt; 
&lt;p&gt;If your rag_service provider is &lt;code&gt;ollama&lt;/code&gt;, you need to set the endpoint to &lt;code&gt;http://localhost:11434&lt;/code&gt; (note there is no &lt;code&gt;/v1&lt;/code&gt; at the end) or any address of your own ollama server.&lt;/p&gt; 
&lt;p&gt;If your rag_service provider is &lt;code&gt;ollama&lt;/code&gt;, when &lt;code&gt;llm_model&lt;/code&gt; is empty, it defaults to &lt;code&gt;llama3&lt;/code&gt;, and when &lt;code&gt;embed_model&lt;/code&gt; is empty, it defaults to &lt;code&gt;nomic-embed-text&lt;/code&gt;. Please make sure these models are available in your ollama server.&lt;/p&gt; 
&lt;p&gt;Additionally, RAG Service also depends on Docker! (For macOS users, OrbStack is recommended as a Docker alternative).&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;host_mount&lt;/code&gt; is the path that will be mounted to the container, and the default is the home directory. The mount is required for the RAG service to access the files in the host machine. It is up to the user to decide if you want to mount the whole &lt;code&gt;/&lt;/code&gt; directory, just the project directory, or the home directory. If you plan using avante and RAG event for projects stored outside your home directory, you will need to set the &lt;code&gt;host_mount&lt;/code&gt; to the root directory of your file system.&lt;/p&gt; 
&lt;p&gt;The mount will be read only.&lt;/p&gt; 
&lt;p&gt;After changing the rag_service configuration, you need to manually delete the rag_service container to ensure the new configuration is used: &lt;code&gt;docker rm -fv avante-rag-service&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Web Search Engines&lt;/h2&gt; 
&lt;p&gt;Avante&#39;s tools include some web search engines, currently support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href=&quot;https://tavily.com/&quot;&gt;Tavily&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://serpapi.com/&quot;&gt;SerpApi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://www.searchapi.io/&quot;&gt;SearchAPI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Google&#39;s &lt;a href=&quot;https://developers.google.com/custom-search/v1/overview&quot;&gt;Programmable Search Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://help.kagi.com/kagi/api/search.html&quot;&gt;Kagi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href=&quot;https://api-dashboard.search.brave.com/app/documentation/web-search/get-started&quot;&gt;Brave Search&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The default is Tavily, and can be changed through configuring &lt;code&gt;Config.web_search_engine.provider&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;web_search_engine = {
  provider = &quot;tavily&quot;, -- tavily, serpapi, searchapi, google or kagi
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Environment variables required for providers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tavily: &lt;code&gt;TAVILY_API_KEY&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;SerpApi: &lt;code&gt;SERPAPI_API_KEY&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;SearchAPI: &lt;code&gt;SEARCHAPI_API_KEY&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Google: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;GOOGLE_SEARCH_API_KEY&lt;/code&gt; as the &lt;a href=&quot;https://developers.google.com/custom-search/v1/overview&quot;&gt;API key&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;GOOGLE_SEARCH_ENGINE_ID&lt;/code&gt; as the &lt;a href=&quot;https://programmablesearchengine.google.com&quot;&gt;search engine&lt;/a&gt; ID&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Kagi: &lt;code&gt;KAGI_API_KEY&lt;/code&gt; as the &lt;a href=&quot;https://kagi.com/settings?p=api&quot;&gt;API Token&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Brave Search: &lt;code&gt;BRAVE_API_KEY&lt;/code&gt; as the &lt;a href=&quot;https://api-dashboard.search.brave.com/app/keys&quot;&gt;API key&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disable Tools&lt;/h2&gt; 
&lt;p&gt;Avante enables tools by default, but some LLM models do not support tools. You can disable tools by setting &lt;code&gt;disable_tools = true&lt;/code&gt; for the provider. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;{
  claude = {
    endpoint = &quot;https://api.anthropic.com&quot;,
    model = &quot;claude-3-5-sonnet-20241022&quot;,
    timeout = 30000, -- Timeout in milliseconds
    temperature = 0,
    max_tokens = 4096,
    disable_tools = true, -- disable tools!
  },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In case you want to ban some tools to avoid its usage (like Claude 3.7 overusing the python tool) you can disable just specific tools&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;{
  disabled_tools = { &quot;python&quot; },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tool list&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;rag_search, python, git_diff, git_commit, list_files, search_files, search_keyword, read_file_toplevel_symbols, read_file, create_file, rename_file, delete_file, create_dir, rename_dir, delete_dir, bash, web_search, fetch&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Custom Tools&lt;/h2&gt; 
&lt;p&gt;Avante allows you to define custom tools that can be used by the AI during code generation and analysis. These tools can execute shell commands, run scripts, or perform any custom logic you need.&lt;/p&gt; 
&lt;h3&gt;Example: Go Test Runner&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Here&#39;s an example of a custom tool that runs Go unit tests:&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;{
  custom_tools = {
    {
      name = &quot;run_go_tests&quot;,  -- Unique name for the tool
      description = &quot;Run Go unit tests and return results&quot;,  -- Description shown to AI
      command = &quot;go test -v ./...&quot;,  -- Shell command to execute
      param = {  -- Input parameters (optional)
        type = &quot;table&quot;,
        fields = {
          {
            name = &quot;target&quot;,
            description = &quot;Package or directory to test (e.g. &#39;./pkg/...&#39; or &#39;./internal/pkg&#39;)&quot;,
            type = &quot;string&quot;,
            optional = true,
          },
        },
      },
      returns = {  -- Expected return values
        {
          name = &quot;result&quot;,
          description = &quot;Result of the fetch&quot;,
          type = &quot;string&quot;,
        },
        {
          name = &quot;error&quot;,
          description = &quot;Error message if the fetch was not successful&quot;,
          type = &quot;string&quot;,
          optional = true,
        },
      },
      func = function(params, on_log, on_complete)  -- Custom function to execute
        local target = params.target or &quot;./...&quot;
        return vim.fn.system(string.format(&quot;go test -v %s&quot;, target))
      end,
    },
  },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;MCP&lt;/h2&gt; 
&lt;p&gt;Now you can integrate MCP functionality for Avante through &lt;code&gt;mcphub.nvim&lt;/code&gt;. For detailed documentation, please refer to &lt;a href=&quot;https://github.com/ravitemer/mcphub.nvim#avante-integration&quot;&gt;mcphub.nvim&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Claude Text Editor Tool Mode&lt;/h2&gt; 
&lt;p&gt;Avante leverages &lt;a href=&quot;https://docs.anthropic.com/en/docs/build-with-claude/tool-use/text-editor-tool&quot;&gt;Claude Text Editor Tool&lt;/a&gt; to provide a more elegant code editing experience. You can now enable this feature by setting &lt;code&gt;enable_claude_text_editor_tool_mode&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; in the &lt;code&gt;behaviour&lt;/code&gt; configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;{
  behaviour = {
    enable_claude_text_editor_tool_mode = true,
  },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To enable &lt;strong&gt;Claude Text Editor Tool Mode&lt;/strong&gt;, you must use the &lt;code&gt;claude-3-5-sonnet-*&lt;/code&gt; or &lt;code&gt;claude-3-7-sonnet-*&lt;/code&gt; model with the &lt;code&gt;claude&lt;/code&gt; provider! This feature is not supported by any other models!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Custom prompts&lt;/h2&gt; 
&lt;p&gt;By default, &lt;code&gt;avante.nvim&lt;/code&gt; provides three different modes to interact with: &lt;code&gt;planning&lt;/code&gt;, &lt;code&gt;editing&lt;/code&gt;, and &lt;code&gt;suggesting&lt;/code&gt;, followed with three different prompts per mode.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;planning&lt;/code&gt;: Used with &lt;code&gt;require(&quot;avante&quot;).toggle()&lt;/code&gt; on sidebar&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;editing&lt;/code&gt;: Used with &lt;code&gt;require(&quot;avante&quot;).edit()&lt;/code&gt; on selection codeblock&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;suggesting&lt;/code&gt;: Used with &lt;code&gt;require(&quot;avante&quot;).get_suggestion():suggest()&lt;/code&gt; on Tab flow.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cursor-planning&lt;/code&gt;: Used with &lt;code&gt;require(&quot;avante&quot;).toggle()&lt;/code&gt; on Tab flow, but only when cursor planning mode is enabled.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Users can customize the system prompts via &lt;code&gt;Config.system_prompt&lt;/code&gt;. We recommend calling this in a custom Autocmds depending on your need:&lt;/p&gt; 
&lt;pre&gt;&lt;code class=&quot;language-lua&quot;&gt;vim.api.nvim_create_autocmd(&quot;User&quot;, {
  pattern = &quot;ToggleMyPrompt&quot;,
  callback = function() require(&quot;avante.config&quot;).override({system_prompt = &quot;MY CUSTOM SYSTEM PROMPT&quot;}) end,
})

vim.keymap.set(&quot;n&quot;, &quot;&amp;lt;leader&amp;gt;am&quot;, function() vim.api.nvim_exec_autocmds(&quot;User&quot;, { pattern = &quot;ToggleMyPrompt&quot; }) end, { desc = &quot;avante: toggle my prompt&quot; })
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If one wish to custom prompts for each mode, &lt;code&gt;avante.nvim&lt;/code&gt; will check for project root based on the given buffer whether it contains the following patterns: &lt;code&gt;*.{mode}.avanterules&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The rules for root hierarchy:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;lsp workspace folders&lt;/li&gt; 
 &lt;li&gt;lsp root_dir&lt;/li&gt; 
 &lt;li&gt;root pattern of filename of the current buffer&lt;/li&gt; 
 &lt;li&gt;root pattern of cwd&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Example folder structure for custom prompt&lt;/summary&gt; 
 &lt;p&gt;If you have the following structure:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;.
├── .git/
├── typescript.planning.avanterules
├── snippets.editing.avanterules
├── suggesting.avanterules
└── src/

&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;typescript.planning.avanterules&lt;/code&gt; will be used for &lt;code&gt;planning&lt;/code&gt; mode&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;snippets.editing.avanterules&lt;/code&gt; will be used for &lt;code&gt;editing&lt;/code&gt; mode&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;suggesting.avanterules&lt;/code&gt; will be used for &lt;code&gt;suggesting&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!important]&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;*.avanterules&lt;/code&gt; is a jinja template file, in which will be rendered using &lt;a href=&quot;https://github.com/mitsuhiko/minijinja&quot;&gt;minijinja&lt;/a&gt;. See &lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/lua/avante/templates&quot;&gt;templates&lt;/a&gt; for example on how to extend current templates.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;TODOs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Chat with current file&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Apply diff patch&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Chat with the selected block&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Slash commands&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Edit the selected block&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Smart Tab (Cursor Flow)&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Chat with project (You can use &lt;code&gt;@codebase&lt;/code&gt; to chat with the whole project)&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Chat with selected files&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; Tool use&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; checked disabled&gt; MCP&lt;/li&gt; 
 &lt;li&gt;&lt;input type=&quot;checkbox&quot; disabled&gt; Better codebase indexing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced AI Interactions&lt;/strong&gt;: Improve the depth of AI analysis and recommendations for more complex coding scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LSP + Tree-sitter + LLM Integration&lt;/strong&gt;: Integrate with LSP and Tree-sitter and LLM to provide more accurate and powerful code suggestions and analysis.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions to avante.nvim are welcome! If you&#39;re interested in helping out, please feel free to submit pull requests or open issues. Before contributing, ensure that your code has been thoroughly tested.&lt;/p&gt; 
&lt;p&gt;See &lt;a href=&quot;https://github.com/yetone/avante.nvim/wiki&quot;&gt;wiki&lt;/a&gt; for more recipes and tricks.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;We would like to express our heartfelt gratitude to the contributors of the following open-source projects, whose code has provided invaluable inspiration and reference for the development of avante.nvim:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Nvim Plugin&lt;/th&gt; 
   &lt;th&gt;License&lt;/th&gt; 
   &lt;th&gt;Functionality&lt;/th&gt; 
   &lt;th&gt;Location&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/akinsho/git-conflict.nvim&quot;&gt;git-conflict.nvim&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;No License&lt;/td&gt; 
   &lt;td&gt;Diff comparison functionality&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/lua/avante/diff.lua&quot;&gt;lua/avante/diff.lua&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/jackMort/ChatGPT.nvim&quot;&gt;ChatGPT.nvim&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Apache 2.0 License&lt;/td&gt; 
   &lt;td&gt;Calculation of tokens count&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/lua/avante/utils/tokens.lua&quot;&gt;lua/avante/utils/tokens.lua&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/HakonHarnes/img-clip.nvim&quot;&gt;img-clip.nvim&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MIT License&lt;/td&gt; 
   &lt;td&gt;Clipboard image support&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/lua/avante/clipboard.lua&quot;&gt;lua/avante/clipboard.lua&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/zbirenbaum/copilot.lua&quot;&gt;copilot.lua&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MIT License&lt;/td&gt; 
   &lt;td&gt;Copilot support&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/lua/avante/providers/copilot.lua&quot;&gt;lua/avante/providers/copilot.lua&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/HiPhish/jinja.vim&quot;&gt;jinja.vim&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MIT License&lt;/td&gt; 
   &lt;td&gt;Template filetype support&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/syntax/jinja.vim&quot;&gt;syntax/jinja.vim&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/olimorris/codecompanion.nvim&quot;&gt;codecompanion.nvim&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MIT License&lt;/td&gt; 
   &lt;td&gt;Secrets logic support&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/lua/avante/providers/init.lua&quot;&gt;lua/avante/providers/init.lua&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/paul-gauthier/aider&quot;&gt;aider&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Apache 2.0 License&lt;/td&gt; 
   &lt;td&gt;Planning mode user prompt&lt;/td&gt; 
   &lt;td&gt;&lt;a href=&quot;https://github.com/yetone/avante.nvim/raw/main/lua/avante/templates/planning.avanterules&quot;&gt;lua/avante/templates/planning.avanterules&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The high quality and ingenuity of these projects&#39; source code have been immensely beneficial throughout our development process. We extend our sincere thanks and respect to the authors and contributors of these projects. It is the selfless dedication of the open-source community that drives projects like avante.nvim forward.&lt;/p&gt; 
&lt;h2&gt;Business Sponsors&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align=&quot;center&quot;&gt; &lt;a href=&quot;https://www.meshy.ai/&quot; target=&quot;_blank&quot;&gt; &lt;img height=&quot;80&quot; src=&quot;https://github.com/user-attachments/assets/1abd8ede-bd98-4e6e-8ee0-5a661b40344a&quot; alt=&quot;Meshy AI&quot;&gt;&lt;br&gt; &lt;strong&gt;Meshy AI&lt;/strong&gt; 
     &lt;div&gt;
      &amp;nbsp;
     &lt;/div&gt; 
     &lt;div&gt;
      The #1 AI 3D Model Generator for Creators
     &lt;/div&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align=&quot;center&quot;&gt; &lt;a href=&quot;https://babeltower.pro/models/claude-3-7-sonnet&quot; target=&quot;_blank&quot;&gt; &lt;img height=&quot;80&quot; src=&quot;https://github.com/user-attachments/assets/7b7bd75e-1fd2-48cc-a71a-cff206e4fbd7&quot; alt=&quot;BabelTower API&quot;&gt;&lt;br&gt; &lt;strong&gt;BabelTower API&lt;/strong&gt; 
     &lt;div&gt;
      &amp;nbsp;
     &lt;/div&gt; 
     &lt;div&gt;
      No account needed, use any model instantly
     &lt;/div&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;avante.nvim is licensed under the Apache 2.0 License. For more details, please refer to the &lt;a href=&quot;https://raw.githubusercontent.com/yetone/avante.nvim/main/LICENSE&quot;&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;p align=&quot;center&quot;&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://star-history.com/#yetone/avante.nvim&amp;amp;Date&quot;&gt; 
  &lt;picture&gt; 
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=yetone/avante.nvim&amp;amp;type=Date&amp;amp;theme=dark&quot;&gt; 
   &lt;img alt=&quot;NebulaGraph Data Intelligence Suite(ngdi)&quot; src=&quot;https://api.star-history.com/svg?repos=yetone/avante.nvim&amp;amp;type=Date&quot;&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
